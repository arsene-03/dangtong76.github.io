[
  {
    "permalink": "//",
    "layout": "default",
    "title": "당통의 블로그",
    "content": "# 당통의 블로그\n\n\n\n",
    "dir": "/",
    "name": "README.md",
    "path": "README.md",
    "url": "/"
  },
  {
    "layout": "default",
    "title": "Learning Kubernetes",
    "content": "# Learning Kubernetes\n\n[toc]\n\n## 3. 도커 기본 다지기\n\n### 3.1 도커 설치하기\n\n#### 3.1.1 Ubuntu 설치\n\n```{bash}\nsudo apt-get update\nsudo apt-get install docker.io\nsudo ln -sf /usr/bin/docker.io /usr/local/bin/docker\n```\n\n> 우분투 패키지 메니저는 apt-get , apt-cache, apt 가 있습니다. 모두 동일한 명령어라고 보면 되지만, apt 를 쓸경우 일단 글자수가 적고, 출력 Output 에 색상이 추가되어 좀더 예쁘게 보입니다.\n\n#### 3.1.2 CentOS 6\n\n```{bash}\nsudo yum install http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm\nsudo yum install docker-io\n```\n\n#### 3.1.3 CentOS 7\n\n```{bash}\nsudo yum install docker\nsudo service docker start\nsudo chkconfig docker on # 부팅시에 자동 스타트업\n```\n\n#### 3.1.4 Mac 및 Windows 에 설치\n\n아래 URL 에서 다운받아 설치 하면 됩니다.\n\nMAC 의 경우 Hyperkit, Windows 의 경우 Hyper-V 를 가상화 레이어로 사용 합니다.\n\nDocker Desktop for Mac : https://hub.docker.com/editions/community/docker-ce-desktop-mac/\n\nDocker Desktop for Windows : https://hub.docker.com/editions/community/docker-ce-desktop-windows/\n\n### 3.2 도커 기본 명령어\n\n도커 파일 내에서 사용 가능한 명령어\n\n| 명령 | 설명 | 명령 | 설명 |\n| -------------- | -------------------- | --------------- | -------------------------- |\n| **FROM** | 베이스 이미지 지정 | **VOLUME** | 볼륨 마운트 |\n| **RUN** | 명령실행 | **USER** | 사용자 지정 |\n| **CMD** | 컨테이너 실행 명령 | **WORKDIR** | 작업 디렉토리 |\n| **LABEL** | 라벨 설정 | **ONBUILD** | Dockerfile 내의 변수 |\n| **EXPOSE** | 포트 익스포트 | **STOPSIGNAL** | 빌드 완료 후 실행되는 명령 |\n| **ENV** | 환경변수 | **HEALTHCHECK** | 시스템 콜 시그널 설정 |\n| **ADD** | 파일/디렉토리 추가 | **SHELL** | 기본 쉘 설정 |\n| **CPOY** | 파일 복사 | | |\n| **ENTRYPOINT** | 컨테이너 실행 명령사 | | |\n\n#### 3.2.1 도커 hub 사용을 위한 계정생성\n\n```{bash}\nsudo docker login\n```\n\n> [docker hub](https://hub.docker.com/) (hub.docker.dom) 에 가입 후 명령어를 실행 해야 로그인이 가능 합니다.\n\n#### 3.2.2 도커 이미지 검색\n\nsearch 명령으로 nginx 를 검색해 봅니다.\n\n```{bash}\nsudo docker search nginx\n```\n\n![docker_k8s_search](/kubernetes/img/docker_k8s_search.png)\n\n#### 3.2.3 도커 이미지 다운로드\n\nnodejs 이미지를 설치해봅니다. 최신 안정버전인 12.14 버전을 설치 합니다.\n\n```{bash}\nsudo docker pull nodejs:latest # 최신버전 다운로드\nsudo docker pull nodejs:12.14.0 # 특정버전 다운로드\nsudo docker pull -a nodejs # 모든버전 다운로드\n```\n\n![dcoker-pull](/kubernetes/img/dcoker-pull.png)\n\n#### 3.2.4 도커 이미지 목록 보기\n\n```{bash}\ndocker image list\ndocker image ls\ndocker images\n```\n\n![docker-image-list](/kubernetes/img/docker-image-list.png)\n\n### 3.3 도커 이미지 생성 하기\n\n#### 3.3.1 서비스를 위한 Application 코드 작성\n\nhostname_finder 라는 폴더를 만들고 그 아래 main.go 및 Dockerfiles 2개 파일을 작성 합니다.\n\n먼저 vi 또는 gedit 를 실행해서 아래 파일을 main.go 라는 이름 으로 작성 합니다.\n\n```{go}\npackage main\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"log\"\n\t\"net/http\"\n)\nfunc handler(w http.ResponseWriter, r *http.Request){\n\tname, err := os.Hostname()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tfmt.Fprintln(w,\"hostname:\", name)\n}\nfunc main() {\n fmt.Fprintln(os.Stdout,\"Starting GoApp Server......\")\n\thttp.HandleFunc(\"/\",handler)\n\tlog.Fatal(http.ListenAndServe(\":8080\",nil))\n}\n```\n\n#### 3.3.2 이미지 생성을 위한 Dockerfile 작성\n\n```{dockerfile}\nFROM golang:1.11-alpine AS build\n\nWORKDIR /src/\nCOPY main.go go.* /src/\nRUN CGO_ENABLED=0 go build -o /bin/demo\n\nFROM scratch\nCOPY --from=build /bin/demo /bin/demo\nENTRYPOINT [\"/bin/demo\"]\n```\n\n#### 3.3.3 컨테이너 이미지 생성\n\nhostname_finder 라는 폴더 안에서 아래 명령어를 실행 합니다.\n\n```{bash}\ndocker build -t goapp .\n```\n\n> . 은 현재 디렉토리서 Dockerfile 참조해서 first-container 라는 이미지를 생성 합니다.\n\n[출력]\n\n```{text}\nSending build context to Docker daemon 3.072kB\nStep 1/7 : FROM golang:1.11-alpine AS build\n ---> e116d2efa2ab\nStep 2/7 : WORKDIR /src/\n ---> Using cachedocker\n ---> c3210d8eb11f\nStep 3/7 : COPY main.go go.* /src/\n ---> ef55118ea78c\nStep 4/7 : RUN CGO_ENABLED=0 go build -o /bin/demo\n ---> Running in e557730bf11c\nRemoving intermediate container e557730bf11c\n ---> d55bd9bd3f81\nStep 5/7 : FROM scratch\n --->\nStep 6/7 : COPY --from=build /bin/demo /bin/demo\n ---> bb4b1250a05e\nStep 7/7 : ENTRYPOINT [\"/bin/demo\"]\n ---> Running in 4419d56988aa\nRemoving intermediate container 4419d56988aa\n ---> 36f5c919e3b8\nSuccessfully built 36f5c919e3b8\nSuccessfully tagged goapp:latest\n```\n\n이미지가 생성 되었는지 명령어를 통해 확인 합니다.\n\n```{bash}\ndocker images\n```\n\n[출력]\n\n```{txt}\nREPOSITORY TAG IMAGE ID CREATED SIZE\n<none> <none> d55bd9bd3f81 About a minute ago 325MB\ngoapp latest 36f5c919e3b8 About a minute ago 6.51MB\n<none> <none> 1c688e9c7e3c 3 days ago 325MB\n<none> <none> 9b60c66a5b82 3 days ago 6.51MB\n<none> <none> 7fc44021a96f 3 days ago 325MB\n<none> <none> 2caa0c2ac791 3 days ago 325MB\n<none> <none> c46d81105b65 3 days ago 6.51MB\n<none> <none> 2d78705fb4ae 3 days ago 312MB\n```\n\n### 3.4 도커 컨테이너 시작 및 서비스 확인\n\n#### 3.4.1 도커 컨테이너 시작\n\n```{bash}\ndocker run --name goapp-project -p 8080:8080 -d goapp\ndocker run -it --name goapp-project -p 8080:8080 -d goapp /bin/bash\n```\n\n> --name : 실행한 도커 컨테이너의 이름 지정\n>\n> -p : 포트 맵핑 정보 localhost 와 컨테이너 포트를 맵핑 합니다.\n>\n> -d : Docker 컨테이너를 백그라운드로 수행하고 컨테이너 ID를 출력 합니다.\n>\n> -i : STDIN 계속 interactive 모드로 유지\n\n#### 3.4.2 도커 컨테이스 서비스 확인\n\ncurl 명령어를 통해 정상적인 서비스 수행 여부를 확인 합니다.\n\n```{bash}\ncurl localhost:8080\n```\n\n[출력]\n\n```{txt}\nhostname: 96fc3a5eb914\n```\n\n#### 3.4.3 도커 프로세서 확인\n\n```{bash}\ndocker ps\n```\n\n**[출력]**\n\n```{txt}\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\n96fc3a5eb914 goapp \"/bin/demo\" 43 seconds ago Up 42 seconds 0.0.0.0:8080->8080/tcp goapp-project\n```\n\n#### 3.4.4 프로세서 상세 정보 출력\n\n```{bash}\ndocker inspect goapp-project\n```\n\n[출력]\n\n```{txt}\n[\n {\n \"Id\": \"96fc3a5eb914c58ed83e088681d53a46188edeaab061ff2de0b9852e9dd276c9\",\n \"Created\": \"2020-01-10T04:32:12.269012485Z\",\n \"Path\": \"/bin/demo\",\n \"Args\": [],\n \"State\": {\n \"Status\": \"running\",\n \"Running\": true,\n \"Paused\": false,\n \"Restarting\": false,\n \"OOMKilled\": false,\n \"Dead\": false,\n \"Pid\": 31285,\n \"ExitCode\": 0,\n \"Error\": \"\",\n \"StartedAt\": \"2020-01-10T04:32:12.902395362Z\",\n \"FinishedAt\": \"0001-01-01T00:00:00Z\"\n },\n \"Image\": \"sha256:36f5c919e3b88f1c991eda67d96e62fe02b763182e44f19fb78b2fc055165f3d\",\n \"ResolvConfPath\": \"/var/lib/docker/containers/96fc3a5eb914c58ed83e088681d53a46188edeaab061ff2de0b9852e9dd276c9/resolv.conf\",\n \"HostnamePath\": \"/var/lib/docker/containers/96fc3a5eb914c58ed83e088681d53a46188edeaab061ff2de0b9852e9dd276c9/hostname\",\n \"HostsPath\": \"/var/lib/docker/containers/96fc3a5eb914c58ed83e088681d53a46188edeaab061ff2de0b9852e9dd276c9/hosts\",\n \"LogPath\": \"/var/lib/docker/containers/96fc3a5eb914c58ed83e088681d53a46188edeaab061ff2de0b9852e9dd276c9/96fc3a5eb914c58ed83e088681d53a46188edeaab061ff2de0b9852e9dd276c9-json.log\",\n```\n\n#### 3.4.5 Docker 컨테이너 접속\n\n```{bash}\n# docker 컨테이너 접속\ndocker exec -it goapp-project bash\n\n# docker 외부에서 컨테이너에 명령수행 (ls 명령 수행)\ndocker exec goapp-project ls\n```\n\n> -i 또는 --interactive : STDIN을 오픈한 상태로 인터랙티브 모드상태\n>\n> -t 또는 --tty : terminal 모드\n>\n> container 이름이 보이지 않고 ID 만 기본적으로 보입니다. 컨테이너 이름을 출력하려면 아래 명령어를 수행 하면 됩니다.\n>\n> docker ps --format \"{{.Names}}\"\n\n#### 3.4.6 도커 인스턴스 중단 및 삭제\n\n```{bash}\ndocker stop goapp-project\ndocker rm goapp-project\n```\n\n### 3.5. 도커 이미지를 도커 허브에 업로드\n\n#### 3.5.1 도커 허브양식에 맞게 tag 수정하기\n\n```{bash}\ndocker tag goapp dangtong/goapp\n```\n\n[출력]\n\n```{text}\nREPOSITORY TAG IMAGE ID CREATED SIZE\ndangtong/goapp latest 12e9a84d9e23 3 days ago 6.51MB\ngoapp latest 12e9a84d9e23 3 days ago 6.51MB\n```\n\n> dangtong/firstapp 과 first-container 의 image ID 가 같은 것을 확인 할 수 있습니다.\n>\n> 사실 하나의 이미지를 서로 다른 TAGID 로 공유 하는 것입니다. 디스크 공간이 늘어나지 않습니다.\n\n#### 3.5.2 도커 허브에 이미지 업로드 하기\n\n```{bash}\ndocker login --username dangtong\ndocker push dangtong/goapp\n```\n\n[출력]\n\n```{text}\nThe push refers to repository [docker.io/dangtong/goapp]\ncc282a374c26: Pushed\nlatest: digest: sha256:b18b5ff03599893a7361feda054ebe26de61a71f019dc8725bb33d87f2115968 size: 528\n```\n\n도커 허브에 로그인 하게 되면 아래와 같이 goapp 이미지가 업로드 된것을 확인 할 수 있습니다. 이제 인터넷만 연결 되면 어디서는 자신이 만든 이미지로 컨테이너를 실행 할 수 있습니다.\n\n![image-20200110124234902](/kubernetes/img/image-20200110124234902.png)\n\n#### 3.5.3 도커 허브의 이미지로 컨테이너 실행\n\ndocker hub 에 있는 이미지를 로딩하여 컨테이너 생성\n\n```{bash}\ndocker run --name goapp-project -p 8080:8080 -d dangtong/goapp\n```\n\n```{bash}\ndocker ps\n```\n\n[출력]\n\n```{txt}\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\n0938068f8709 dangtong/goapp \"/bin/demo\" 5 seconds ago Up 4 seconds 0.0.0.0:8080->8080/tcp goapp-project\n```\n\n현재 서비스에 접속하여 확인\n\n```{bash}\ncurl http://localhost:8080\n```\n\n```{txt}\nhostname: 0938068f8709\n```\n\n### [Exercise #1]\n\n1. 서버 호스트명을 출력하는 node.js 프로그램을 만드세요\n\n2. 해당 소스로 node 버전 7 기반으로 서비스 하는 Docker file을 만들고 이미지를 build 하세요\n\n3. tag 명령을 이용해서 docker hub 에 올릴수 있도록 이름을 바꾸세요\n\n4. docker login 후에 docker hub 에 업로드하여 실제 업로드가 되었는지 확인하세요\n\n이름은 username/nodejs-app 으로 하세요\n\n- node.js 프로그램 (app.js)\n\n```{javascript}\nconst http = require('http');\nconst os = require('os');\n\nconsole.log(\"Learning Kubernetes server starting...\");\n\nvar handler = function(request, response) {\n console.log(\"Received request from \" + request.connection.remoteAddress);\n response.writeHead(200);\n response.end(\"You've hit \" + os.hostname() + \"\\n\");\n};\n\nvar www = http.createServer(handler);\nwww.listen(8080);\n```\n\n- Dcokerfile\n\n```{bash}\n# FROM 으로 BASE 이미지 로드\nFROM node:7\n\n# ADD 명령어로 이미지에 app.js 파일 추가\nADD app.js /app.js\n\n# ENTRYPOINT 명령어로 node 를 실행하고 매개변수로 app.js 를 전달\nENTRYPOINT [\"node\", \"app.js\"]\n```\n\n## 4. 쿠버네티스 간단하게 맛보기\n\n### 4.1 도커 허브 이미지로 컨테이너 생성 및 확인\n\n- 컨테이너 생성 : run/v1 으로 수행 합니다.\n\n ```{bash}\n # POD 및 Replication Controller 생성 (향후 버전에서 deprecated 될 예정)\n $ kubectl run goapp-project --image=dangtong/goapp --port=8080 --generator=run/v1\n # POD 만 생성\n $ kubectl run goapp-project --image=dangtong/goapp --port=8080 --generator=run-pod/v1\n ```\n\n > generator 를 run/v1 으로 수행 할 경우 내부적으로 goapp-project-{random-String} 이라는 컨테이너를 만들면서 goapp-project- 이름의 replication controller 도 생기게 됩니다.\n\n - Generator 의 종류 : **run-pod/v1** 외에 모두 deprecated 될 예정\n\n | Resource | API group | kubectl command |\n | :----------------------------------- | :----------------- | :------------------------------------------------ |\n | Pod | v1 | `kubectl run --generator=run-pod/v1` |\n | ReplicationController _(deprecated)_ | v1 | `kubectl run --generator=run/v1` |\n | Deployment _(deprecated)_ | extensions/v1beta1 | `kubectl run --generator=deployment/v1beta1` |\n | Deployment _(deprecated)_ | apps/v1beta1 | `kubectl run --generator=deployment/apps.v1beta1` |\n | Job _(deprecated)_ | batch/v1 | `kubectl run --generator=job/v1` |\n | CronJob _(deprecated)_ | batch/v2alpha1 | `kubectl run --generator=cronjob/v2alpha1` |\n | CronJob _(deprecated)_ | batch/v1beta1 | `kubectl run --generator=cronjob/v1beta1` |\n\n- 컨테이너 확인\n\n ```{bash}\n $ kubectl get pods\n $ kubectl get rc\n ```\n\n ```{text}\n $ kubectl get pods\n NAME READY STATUS RESTARTS AGE\n goapp-project-bcv5q 1/1 Running 0 2m26s\n\n $ kubectl get rc\n NAME DESIRED CURRENT READY AGE\n goapp-project 1 1 1 8m58s\n ```\n\n > 아래 명령어를 추가적으로 수행해 보세요\n >\n > ```\n > kubectl get pods -o wide\n > kubectl describe pod goapp-project-bcv5q\n > ```\n\n- k8s 서비스 생성\n\n ```{bash}\n $ kubectl expose rc goapp-project --type=LoadBalancer --name goapp-http\n ```\n\n ```{text}\n service/firstapp-http exposed\n ```\n\n- 생성한 서비스 조회\n\n ```{bash}\n $ kubectl get services\n ```\n\n ```{text}\n NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\n goapp-http LoadBalancer 10.96.225.172 <pending> 8080:31585/TCP 104s\n kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 14d\n ```\n\n- 서비스 테스트 (여러번 수행)\n\n ```{bash}\n curl http://10.96.225.172:8080\n ```\n\n [출력]\n\n ```{text}\n hostname: goapp-project-bcv5q\n hostname: goapp-project-bcv5q\n hostname: goapp-project-bcv5q\n hostname: goapp-project-bcv5q\n ```\n\n- replication controller 를 통한 scale-out 수행\n\n ```{bash}\n kubectl scale rc goapp-project --replicas=3\n ```\n\n [출력]\n\n ```{txt}\n replicationcontroller/goapp-project scaled\n ```\n\n- Scale-Out 결과 확인\n\n ```{bash}\n kubectl get pod\n ```\n\n [출력]\n\n ```{txt}\n NAME READY STATUS RESTARTS AGE\n goapp-project-bcv5q 1/1 Running 0 16m\n goapp-project-c8hml 1/1 Running 0 26s\n goapp-project-r7kx5 1/1 Running 0 26s\n ```\n\n- 서비스 테스트 (여러번 수행)\n\n ```{bash}\n curl http://10.96.225.172:8080\n ```\n\n [출력]\n\n ```{txt}\n NAME READY STATUS RESTARTS AGE\n goapp-project-bcv5q 1/1 Running 0 16m\n goapp-project-c8hml 1/1 Running 0 26s\n goapp-project-r7kx5 1/1 Running 0 26s\n ```\n\n- POD 삭제\n\nReplication Controller 를 통해 생성된 POD 는 개별 POD 가 삭제 되지 않습니다. Replication Controller 자체를 삭제 해야 합니다.\n\n```{bash}\nkubectl delete rc goapp-project\n```\n\n## 5. PODS\n\n### 5.1 POD 기본\n\n### 5.1 POD 설정을 yaml 파일로 가져오기\n\n```{bash}\nkubectl get pod goapp-project-bcv5q -o yaml\nkubectl get po goapp-project-bcv5q -o json\n```\n\n크게 **metadata, spec, status** 항목으로 나누어 집니다.\n\n[출력 - yaml]\n\n```{yaml}\napiVersion: v1\nkind: Pod\nmetadata:\n creationTimestamp: \"2020-01-10T07:37:49Z\"\n generateName: goapp-project-\n labels:\n run: goapp-project\n name: goapp-project-bcv5q\n namespace: default\n ownerReferences:\n - apiVersion: v1\n blockOwnerDeletion: true\n controller: true\n kind: ReplicationController\n name: goapp-project\n uid: e223237f-17e2-44f4-aaee-07e8ff4592b2\n resourceVersion: \"3082141\"\n selfLink: /api/v1/namespaces/default/pods/goapp-project-bcv5q\n uid: 72bebcbd-8e6e-4906-9f66-1c3821fa49ec\nspec:\n containers:\n - image: dangtong/goapp\n imagePullPolicy: Always\n name: goapp-project\n ports:\n - containerPort: 8080\n protocol: TCP\n resources: {}\n terminationMessagePath: /dev/termination-log\n terminationMessagePolicy: File\n volumeMounts:\n - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\n name: default-token-qz4fh\n readOnly: true\n dnsPolicy: ClusterFirst\n enableServiceLinks: true\n nodeName: worker01.sas.com\n priority: 0\n restartPolicy: Always\n schedulerName: default-scheduler\n securityContext: {}\n serviceAccount: default\n serviceAccountName: default\n terminationGracePeriodSeconds: 30\n tolerations:\n - effect: NoExecute\n key: node.kubernetes.io/not-ready\n operator: Exists\n tolerationSeconds: 300\n - effect: NoExecute\n key: node.kubernetes.io/unreachable\n operator: Exists\n tolerationSeconds: 300\n volumes:\n - name: default-token-qz4fh\n secret:\n defaultMode: 420\n secretName: default-token-qz4fh\nstatus:\n conditions:\n - lastProbeTime: null\n lastTransitionTime: \"2020-01-10T07:37:49Z\"\n status: \"True\"\n type: Initialized\n - lastProbeTime: null\n lastTransitionTime: \"2020-01-10T07:37:55Z\"\n status: \"True\"\n type: Ready\n - lastProbeTime: null\n lastTransitionTime: \"2020-01-10T07:37:55Z\"\n status: \"True\"\n type: ContainersReady\n - lastProbeTime: null\n lastTransitionTime: \"2020-01-10T07:37:49Z\"\n status: \"True\"\n type: PodScheduled\n containerStatuses:\n - containerID: docker://de3418e51fea7f7a19e7b1d6ff5a4a6f386f337578838e6f1ec0589275ca6f48\n image: dangtong/goapp:latest\n imageID: docker-pullable://dangtong/goapp@sha256:e5872256539152aecd2a8fb1f079e132a6a8f247c7a2295f0946ce2005e36d05\n lastState: {}\n name: goapp-project\n ready: true\n restartCount: 0\n started: true\n state:\n running:\n startedAt: \"2020-01-10T07:37:55Z\"\n hostIP: 192.168.56.103\n phase: Running\n podIP: 10.40.0.2\n podIPs:\n - ip: 10.40.0.2\n qosClass: BestEffort\n startTime: \"2020-01-10T07:37:49Z\"\n```\n\n###5.2 POD 생성을 위한 YAML 파일 만들기\n\n아래와 같이 goapp.yaml 파일을 만듭니다.\n\n```{yaml}\napiVersion: v1\nkind: Pod\nmetadata:\n name: goapp-pod\nspec:\n containers:\n - image: dangtong/goapp\n name: goapp-container\n ports:\n - containerPort: 8080\n protocol: TCP\n```\n\n> ports 정보를 yaml 파일에 기록 하지 않으면 아래 명령어로 향후에 포트를 할당해도 됩니다.\n>\n> ```\n> kubectl port-forward goapp-pod 8080:8080\n> ```\n\n### 5.3 YAML 파일을 이용한 POD 생성 및 확인\n\n```{bash}\n$ kubectl create -f goapp.yaml\n```\n\n[output]\n\n```{txt}\n pod/goapp-pod created\n```\n\n```{bash}\n$ kubectl get pod\n```\n\n[output]\n\n```{txt}\nNAME READY STATUS RESTARTS AGE\ngoapp-pod 1/1 Running 0 12m\ngoapp-project-bcv5q 1/1 Running 0 41m\ngoapp-project-c8hml 1/1 Running 0 25m\ngoapp-project-r7kx5 1/1 Running 0 25m\n```\n\n### 5.4 POD 및 Container 로그 확인\n\n- POD 로그 확인\n\n```{bash}\nkubectl logs goapp-pod\n```\n\n[output]\n\n```{bash}\nStarting GoApp Server......\n```\n\n- Container 로그 확인\n\n```{bash}\nkubectl logs goapp-pod -c goapp-container\n```\n\n[output]\n\n```{bash}\nStarting GoApp Server......\n```\n\n> 현재 1개 POD 내에 Container 가 1이기 때문에 출력 결과는 동일 합니다. POD 내의 Container 가 여러개 일 경우 모든 컨테이너의 표준 출력이 화면에 출력됩니다.\n\n### [Exercise #2]\n\n1. Yaml 파일로 nginx 11.1 버전기반의 이미지를 사용해 nginx-app 이라는 이름의 Pod 를 만드세요(port : 8080)\n2. curl 명령어르 사용해. Nginx 서비스에 접속\n3. nginx Pod 의 정보를 yaml 파일로 출력 하세요\n4. nginx-app Pod 를 삭제 하세요\n\n## 6. Lable\n\n### 6.1 Lable 정보를 추가해서 POD 생성하기\n\n- goapp-with-lable.yaml 이라 파일에 아래 내용을 추가 하여 작성 합니다.\n\n```{yaml}\napiVersion: v1\nkind: Pod\nmetadata:\n name: goapp-pod2\n labels:\n env: prod\nspec:\n containers:\n - image: dangtong/goapp\n name: goapp-container\n ports:\n - containerPort: 8080\n protocol: TCP\n```\n\n- yaml 파일을 이용해 pod 를 생성 합니다.\n\n```{bash}\n$ kubectl create -f ./goapp-with-lable.yaml\n```\n\n[output]\n\n```{txt}\npod/goapp-pod2 created\n```\n\n- 생성된 POD를 조회 합니다.\n\n```{bash}\nkubectl get po --show-labels\n```\n\n[output]\n\n```{txt}\nNAME READY STATUS RESTARTS AGE LABELS\ngoapp-pod 1/1 Running 0 160m <none>\ngoapp-pod2 1/1 Running 0 3m53s env=prod\ngoapp-project-bcv5q 1/1 Running 0 9h run=goapp-project\ngoapp-project-c8hml 1/1 Running 0 9h run=goapp-project\ngoapp-project-r7kx5 1/1 Running 0 9h run=goapp-project\n```\n\n- Lable 태그를 출력 화면에 컬럼을 분리해서 출력\n\n```{bash}\nkubectl get pod -L env\n```\n\n[output]\n\n```{txt}\nNAME READY STATUS RESTARTS AGE ENV\ngoapp-pod 1/1 Running 0 161m\ngoapp-pod2 1/1 Running 0 5m19s prod\ngoapp-project-bcv5q 1/1 Running 0 9h\ngoapp-project-c8hml 1/1 Running 0 9h\ngoapp-project-r7kx5 1/1 Running 0 9h\n```\n\n- Lable을 이용한 필터링 조회\n\n```{bash}\nkubectl get pod -l env=prod\n```\n\n[output]\n\n```{txt}\nNAME READY STATUS RESTARTS AGE\ngoapp-pod2 1/1 Running 0 39h\n```\n\n- Label 추가 하기\n\n```{bash}\nkubectl label pod goapp-pod2 app=\"application\" tier=\"frondEnd\"\n```\n\n- Label 삭제 하기\n\n```{bash}\nkubectl label pod goapp-pod2 app- tier-\n```\n\n### 6.2 Label 셀렉터 사용\n\n- AND 연산\n\n```{bash}\nkubectl get po -l 'app in (application), tier in (frontEnd)'\n```\n\n- OR 연산\n\n```{bash}\nkubectl get po -l 'app in (application,backEnd)'\n\nkubectl get po -l 'app in (application,frontEnd)'\n```\n\n### 6.3 생성된 POD 로 부터 yaml 파일 얻기\n\n```{bash}\nkubectl get pod goapp-pod -o yaml\n```\n\n[output]\n\n```{txt}\napiVersion: v1\nkind: Pod\nmetadata:\n creationTimestamp: \"2020-01-10T08:07:04Z\"\n name: goapp-pod\n namespace: default\n resourceVersion: \"3086366\"\n selfLink: /api/v1/namespaces/default/pods/goapp-pod\n uid: 18cf0ed0-be56-4b54-869c-4473117800b1\nspec:\n containers:\n - image: dangtong/goapp\n imagePullPolicy: Always\n name: goapp-container\n ports:\n - containerPort: 8080\n protocol: TCP\n resources: {}\n terminationMessagePath: /dev/termination-log\n terminationMessagePolicy: File\n volumeMounts:\n - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\n name: default-token-qz4fh\n readOnly: true\n dnsPolicy: ClusterFirst\n enableServiceLinks: true\n nodeName: worker02.sas.com\n priority: 0\n restartPolicy: Always\n schedulerName: default-scheduler\n securityContext: {}\n serviceAccount: default\n serviceAccountName: default\n terminationGracePeriodSeconds: 30\n tolerations:\n - effect: NoExecute\n key: node.kubernetes.io/not-ready\n operator: Exists\n tolerationSeconds: 300\n - effect: NoExecute\n key: node.kubernetes.io/unreachable\n operator: Exists\n tolerationSeconds: 300\n volumes:\n - name: default-token-qz4fh\n secret:\n defaultMode: 420\n secretName: default-token-qz4fh\nstatus:\n conditions:\n - lastProbeTime: null\n lastTransitionTime: \"2020-01-10T08:07:04Z\"\n status: \"True\"\n type: Initialized\n - lastProbeTime: null\n lastTransitionTime: \"2020-01-10T08:07:09Z\"\n status: \"True\"\n type: Ready\n - lastProbeTime: null\n lastTransitionTime: \"2020-01-10T08:07:09Z\"\n status: \"True\"\n type: ContainersReady\n - lastProbeTime: null\n lastTransitionTime: \"2020-01-10T08:07:04Z\"\n status: \"True\"\n type: PodScheduled\n containerStatuses:\n - containerID: docker://d76af359c556c60d3ac1957d7498513f42ace14998c763456190274a3e4a1d5e\n image: dangtong/goapp:latest\n imageID: docker-pullable://dangtong/goapp@sha256:e5872256539152aecd2a8fb1f079e132a6a8f247c7a2295f0946ce2005e36d05\n lastState: {}\n name: goapp-container\n ready: true\n restartCount: 0\n started: true\n state:\n running:\n startedAt: \"2020-01-10T08:07:08Z\"\n hostIP: 10.0.2.5\n phase: Running\n podIP: 10.32.0.4\n podIPs:\n - ip: 10.32.0.4\n qosClass: BestEffort\n startTime: \"2020-01-10T08:07:04Z\"\n```\n\n### 6.4 Lable을 이용한 POD 스케줄링\n\n- 노드목록 조회\n\n```{bash}\nkubectl get nodes\n```\n\n[output]\n\n```{txt}\nNAME STATUS ROLES AGE VERSION\nmaster.sas.com Ready master 16d v1.17.0\nworker01.sas.com Ready <none> 16d v1.17.0\nworker02.sas.com Ready <none> 16d v1.17.0\n```\n\n- 특정 노드에 레이블 부여\n\n```{bash}\nkubectl label node worker02.sas.com memsize=high\n```\n\n- 레이블 조회 필터 사용하여 조회\n\n```{bash}\nkubectl get nodes -l memsize=high\n```\n\n[output]\n\n```{txt}\nNAME STATUS ROLES AGE VERSION\nworker02.sas.com Ready <none> 17d v1.17.0\n```\n\n- 특정 노드에 신규 POD 스케줄링\n\n 아래 내용과 같이 goapp-label-node.yaml 파을을 작성 합니다.\n\n```{yaml}\napiVersion: v1\nkind: Pod\nmetadata:\n name: goapp-pod-memhigh\nspec:\n nodeSelector:\n memsize: \"high\"\n containers:\n - image: dangtong/goapp\n name: goapp-container-memhigh\n```\n\n- YAML 파일을 이용한 POD 스케줄링\n\n```{bash}\nkubectl create -f ./goapp-lable-node.yaml\n```\n\n[output]\n\n```{txt}\npod/goapp-pod-memhigh created\n```\n\n- 생성된 노드 조회\n\n```{bash}\nkubectl get pod -o wide\n```\n\n[output]\n\n```{txt}\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES\ngoapp-pod-memhigh 1/1 Running 0 17s 10.32.0.5 worker02.sas.com <none> <none>\n```\n\n## 7. Annotation\n\n### 7.1 POD 에 Annotation 추가하기\n\n```{bash}\nkubectl annotate pod goapp-pod-memhigh maker=\"dangtong\" team=\"k8s-team\"\n```\n\n[output]\n\n```{txt}\npod/goapp-pod-memhigh annotated\n```\n\n### 7.2 Annotation 확인하기\n\n- YAML 파일을 통해 확인하기\n\n```{bash}\nkubectl get po goapp-pod-memhigh -o yaml\n```\n\n[output]\n\n```{txt}\nkind: Pod\nmetadata:\n annotations:\n maker: dangtong\n team: k8s-team\n creationTimestamp: \"2020-01-12T15:25:05Z\"\n name: goapp-pod-memhigh\n namespace: default\n resourceVersion: \"3562877\"\n selfLink: /api/v1/namespaces/default/pods/goapp-pod-memhigh\n uid: a12c35d7-d0e6-4c01-b607-cccd267e39ec\nspec:\n containers:\n```\n\n- DESCRIBE 를 통해 확인하기\n\n```{bash}\nkubectl describe pod goapp-pod-memhigh\n```\n\n[output]\n\n```{txt}\nName: goapp-pod-memhigh\nNamespace: default\nPriority: 0\nNode: worker02.sas.com/10.0.2.5\nStart Time: Mon, 13 Jan 2020 00:25:05 +0900\nLabels: <none>\nAnnotations: maker: dangtong\n team: k8s-team\nStatus: Running\nIP: 10.32.0.5\n```\n\n### 7.3 Annotation 삭제\n\n```{bash}\nkubectl annotate pod goapp-pod-memhigh maker- team-\n```\n\n### [[Exercise #3]]\n\n- bitnami/apache 이미지로 Pod 를 만들고 tier=FronEnd, app=apache 라벨 정보를 포함하세요\n- Pod 정보를 출력 할때 라벨을 함께 출력 하세요\n- app=apache 라벨틀 가진 Pod 만 조회 하세요\n- 만들어진 Pod에 env=dev 라는 라벨 정보를 추가 하세요\n- created_by=kevin 이라는 Annotation을 추가 하세요\n- apache Pod를 삭제 하세요\n\n## 8. Namespace\n\n### 8.1 네임스페이스 조회\n\n```{bash}\nkubectl get namespace\n```\n\n> kubectl get ns 와 동일함\n\n[output]\n\n```{bash}\nNAME STATUS AGE\ndefault Active 17d\nkube-node-lease Active 17d\nkube-public Active 17d\nkube-system Active 17d\n```\n\n### 8.2 특정 네임스페이스의 POD 조회\n\n```{bash}\nkubectl get pod --namespace kube-system\n# kubectl get po -n kube-system\n```\n\n> kubectl get pod -n kube-system 과 동일함\n\n[output]\n\n```{txt}\ncoredns-6955765f44-glcdc 1/1 Running 0 17d\ncoredns-6955765f44-h7fbb 1/1 Running 0 17d\netcd-master.sas.com 1/1 Running 1 17d\nkube-apiserver-master.sas.com 1/1 Running 1 17d\nkube-controller-manager-master.sas.com 1/1 Running 1 17d\nkube-proxy-gm44f 1/1 Running 1 17d\nkube-proxy-ngqr6 1/1 Running 0 17d\nkube-proxy-wmq7d 1/1 Running 0 17d\nkube-scheduler-master.sas.com 1/1 Running 1 17d\nweave-net-2pm2x 2/2 Running 0 17d\nweave-net-4wksv 2/2 Running 0 17d\nweave-net-7j7mn 2/2 Running 0 17d\n```\n\n###8.3 YAML 파일을 이용한 네임스페이스 생성\n\n- YAML 파일 작성 : first-namespace.yaml 이름으로 파일 작성\n\n```{bash}\napiVersion: v1\nkind: Namespace\nmetadata:\n name: first-namespace\n```\n\n- YAML 파일을 이용한 네이스페이스 생성\n\n```{bash}\nkubectl create -f first-namespace.yaml\n```\n\n[output]\n\n```{txt}\nnamespace/first-namespace created\n```\n\n- 생성된 네임스페이스 확인\n\n```{bash}\nkubectl get namespace\nkubectl get ns\n```\n\n[output]\n\n```{txt}\nNAME STATUS AGE\ndefault Active 17d\nfirst-namespace Active 5s\nkube-node-lease Active 17d\nkube-public Active 17d\nkube-system Active 17d\n```\n\n> kubectl create namespace first-namespace 와 동일 합니다.\n\n### 8.4 특정 네임스페이스에 POD 생성\n\n- first-namespace 에 goapp 생성\n\n```{bash}\nkubectl create -f goapp.yaml -n first-namespace\n```\n\n[output]\n\n```{txt}\npod/goapp-pod created\n```\n\n- 생성된 POD 확인하기\n\n```{bash}\nkubectl get pod -n first-namespace\n```\n\n[output]\n\n```{txt}\nNAME READY STATUS RESTARTS AGE\ngoapp-pod 1/1 Running 0 12h\n```\n\n###8.5 POD 삭제\n\n```{bash}\n'kubectl' delete pod goapp-pod-memhigh\n```\n\n```{bash}\nkubectl delete pod goapp-pod\n```\n\n```{bash}\nkubectl delete pod goapp-pod -n first-namespace\n```\n\n> 현재 네임스페이스 에서 존재 하는 모든 리소스를 삭제하는 명령은 아래와 같습니다.\n>\n> kubectl delete all --all\n>\n> 현재 네임스페이스를 설정하고 조회 하는 명령은 아래와 같습니다.\n>\n> ```shell\n> # 네임스페이스 설정\n> kubectl config set-context --current --namespace=<insert-namespace-name-here>\n> # 확인\n> kubectl config view --minify | grep namespace:\n> ```\n\n### [[Exercise #4]]\n\n1. 쿠버네티스 클러스터에 몇개의 네임스페이가 존재 하나요?\n\n2. my-dev 라는 네임스페이를 생성하고 nginx Pod를 배포 하세요\n\n## 9. kubectl 기본 사용법\n\n### 9.1 단축형 키워드 사용하기\n\n```{bash}\nkubectl get po\t\t\t# PODs\nkubectl get svc\t\t\t# Service\nkubectl get rc\t\t\t# Replication Controller\nkubectl get deploy\t# Deployment\nkubectl get ns\t\t\t# Namespace\nkubectl get no\t\t\t# Node\nkubectl get cm\t\t\t# Configmap\nkubectl get pv\t\t\t# PersistentVolumns\n```\n\n### 9.2 도움말 보기\n\n```{bash}\nkubectl -h\n```\n\n```{txt}\nkubectl controls the Kubernetes cluster manager.\n\n Find more information at: https://kubernetes.io/docs/reference/kubectl/overview/\n\nBasic Commands (Beginner):\n create Create a resource from a file or from stdin.\n expose Take a replication controller, service, deployment or pod and expose it as a new Kubernetes Service\n run Run a particular image on the cluster\n set Set specific features on objects\n\nBasic Commands (Intermediate):\n explain Documentation of resources\n get Display one or many resources\n edit Edit a resource on the server\n delete Delete resources by filenames, stdin, resources and names, or by resources and label selector\n\nDeploy Commands:\n```\n\n```{bash}\nkubectl get -h\n```\n\n```{txt}\nDisplay one or many resources\n\n Prints a table of the most important information about the specified resources. You can filter the list using a label\nselector and the --selector flag. If the desired resource type is namespaced you will only see results in your current\nnamespace unless you pass --all-namespaces.\n\n Uninitialized objects are not shown unless --include-uninitialized is passed.\n\n By specifying the output as 'template' and providing a Go template as the value of the --template flag, you can filter\nthe attributes of the fetched resources.\n\nUse \"kubectl api-resources\" for a complete list of supported resources.\n\nExamples:\n # List all pods in ps output format.\n kubectl get pods\n\n # List all pods in ps output format with more information (such as node name).\n kubectl get pods -o wide\n\n```\n\n### 9.3 리소스 정의에 대한 도움말\n\n```{bash}\nkubectl explain pods\n```\n\n```{txt}\nKIND: Pod\nVERSION: v1\n\nDESCRIPTION:\n Pod is a collection of containers that can run on a host. This resource is\n created by clients and scheduled onto hosts.\n\nFIELDS:\n apiVersion\t<string>\n APIVersion defines the versioned schema of this representation of an\n object. Servers should convert recognized schemas to the latest internal\n value, and may reject unrecognized values. More info:\n https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n kind\t<string>\n Kind is a string value representing the REST resource this object\n represents. Servers may infer this from the endpoint the client submits\n requests to. Cannot be updated. In CamelCase. More info:\n https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n metadata\t<Object>\n Standard object's metadata. More info:\n https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n spec\t<Object>\n Specification of the desired behavior of the pod. More info:\n https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status\n\n status\t<Object>\n Most recently observed status of the pod. This data may not be up to date.\n Populated by the system. Read-only. More info:\n https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status\n```\n\n### 9.4 리소스 감시하기\n\n- Kube-system 네임스페이스에 있는 모든 pod에 대해 모니터링 합니다.\n\n```{bash}\nkubectl get pods --watch -n kube-system\n```\n\n```{txt}\nroot@master:~# k get pods --watch -n kube-system\nNAME READY STATUS RESTARTS AGE\ncoredns-6955765f44-glcdc 1/1 Running 0 19d\ncoredns-6955765f44-h7fbb 1/1 Running 0 19d\netcd-master.sas.com 1/1 Running 1 19d\nkube-apiserver-master.sas.com 1/1 Running 1 19d\nkube-controller-manager-master.sas.com 1/1 Running 1 19d\nkube-proxy-gm44f 1/1 Running 1 19d\nkube-proxy-ngqr6 1/1 Running 0 19d\nkube-proxy-wmq7d 1/1 Running 0 19d\nkube-scheduler-master.sas.com 1/1 Running 1 19d\nweave-net-2pm2x 2/2 Running 0 19d\nweave-net-4wksv 2/2 Running 0 19d\nweave-net-7j7mn 2/2 Running 0 19d\n...\n```\n\n### 9.5 리소스 비교하기\n\n```{bash}\nkubectl diff -f goapp.yaml\n```\n\n### 9.6 kubectx 및 kubens 사용하기\n\n현재 컨텍스트 및 네임스페이스를 확인하고 전환 할때 손쉽게 사용 할수 있는 도구\n\n#### 9.6.1 kubectx 및 kubens 설치\n\n```{bash}\ngit clone https://github.com/ahmetb/kubectx.git ~/.kubectx\nCOMPDIR=$(pkg-config --variable=completionsdir bash-completion)\nln -sf ~/.kubectx/completion/kubens.bash $COMPDIR/kubens\nln -sf ~/.kubectx/completion/kubectx.bash $COMPDIR/kubectx\ncat << FOE >> ~/.bashrc\n\n\n#kubectx and kubens\nexport PATH=~/.kubectx:\\$PATH\nFOE\n```\n\n#### 9.6.2 kubectx 및 kubens 사용\n\n- kubectx 사용\n\n```{bash}\nkubectx\nkubectx <변경하고 싶은 컨텍스트 이름>\n```\n\n- kubens 사용\n\n현재 사용중인 네임스페이스를 조회 합니다. 현재 사용중인 네이스페이스는 하이라이트 됩니다.\n\n```{bash}\nkubens\n```\n\n```{txt}\ndefault\nfirst-namespace\nkube-node-lease\nkube-public\nkube-system\n```\n\nKube-system 네이스페이스로 전환 해봅니다.\n\n```{bash}\nkubens kube-system\n```\n\n```{txt}\nContext \"kubernetes-admin@kubernetes\" modified.\nActive namespace is \"kube-system\".\n```\n\npod 조회 명령을 내리면 아래와 같이 kube-system 네임스페이스의 pod 들이 조회 됩니다.\n\n```{bash}\nkubectl get po\n```\n\n```{bash}\nNAME READY STATUS RESTARTS AGE\ncoredns-6955765f44-glcdc 1/1 Running 0 34d\ncoredns-6955765f44-h7fbb 1/1 Running 0 34d\netcd-master.sas.com 1/1 Running 1 34d\nkube-apiserver-master.sas.com 1/1 Running 1 34d\nkube-controller-manager-master.sas.com 1/1 Running 1 34d\nkube-proxy-gm44f 1/1 Running 1 34d\nkube-proxy-ngqr6 1/1 Running 0 34d\nkube-proxy-wmq7d 1/1 Running 0 34d\nkube-scheduler-master.sas.com 1/1 Running 1 34d\nweave-net-2pm2x 2/2 Running 0 34d\nweave-net-4wksv 2/2 Running 0 34d\nweave-net-7j7mn 2/2 Running 0 34d\n```\n\n### 9.7 kubernetes 컨텍스트 및 네임스페이스 표시하기\n\nkube-ps1을 다운로드 하여 /usr/local/kube-ps1 설치 하고 .bashrc 파일에 아래와 같이 설정 합니다. [링크](https://github.com/jonmosco/kube-ps1)\n\n```{bash}\nsource /usr/local/kube-ps1/kube-ps1.sh\nPS1='[\\u@\\h \\W $(kube_ps1)]\\$ '\n```\n\n```{bash}\n[root@master ~ (⎈ |kubernetes-admin@kubernetes:kube-public)]#\n```\n\n## 10. Liveness probes\n\nliveness prove는 Pod에 지정된 주소에 Health Check 를 수행하고 실패할 경우 Pod를 다시 시작 합니다.\n\n이때 중요한 점은 단순히 다시 시작만 하는 것이 아니라, 리포지토리로 부터 이미지를 다시 받아 Pod 를 다시 시작 합니다.\n\n아래 내용으로.\n\n```{yaml}\napiVersion: v1\nkind: Pod\nmetadata:\n labels:\n test: liveness\n name: liveness-http\nspec:\n containers:\n - name: liveness\n image: k8s.gcr.io/liveness\n args:\n - /server\n livenessProbe:\n httpGet:\n path: /healthz\n port: 8080\n httpHeaders:\n - name: Custom-Header\n value: Awesome\n initialDelaySeconds: 3\n periodSeconds: 3\n```\n\nK8s.gcr.io/liveness 이미지는 liveness 테스트를 위해 만들어진 이미지 입니다. Go 언어로 작성 되었으며, 처음 10초 동안은 정상적인 서비스를 하지만, 10초 후에는 에러를 발생 시킵니다. 자세한 사항은 [URL](https://github.com/kubernetes/kubernetes/blob/master/test/images/agnhost/liveness/server.go) 을 참고 하세요\n\n### 10.1 Pod 생성\n\n```{bash}\nkubectl create -f ./liveness-probe-pod.yaml\n```\n\n###10.2 Pod 확인\n\n```{bash}\nkubectl get pod\n```\n\n아래\n\n```{txt}\nNAME READY STATUS RESTARTS AGE\nliveness-http 1/1 Running 0 5s\n\nNAME READY STATUS RESTARTS AGE\nliveness-http 1/1 Running 1 26s\n\nNAME READY STATUS RESTARTS AGE\nliveness-http 1/1 Running 3 68s\n\nNAME READY STATUS RESTARTS AGE\nliveness-http 0/1 CrashLoopBackOff 3 81s\n\nNAME READY STATUS RESTARTS AGE\nliveness-http 0/1 CrashLoopBackOff 5 2m50s\n```\n\n### 10.3 Pod 로그 이벤트 확인\n\n```{bash}\nkubectl describe pod liveness-http\n```\n\n```{txt}\nName: liveness-http\nNamespace: default\nPriority: 0\nNode: worker02.acorn.com/192.168.56.110\nStart Time: Wed, 01 Apr 2020 05:54:29 +0000\nLabels: test=liveness\nAnnotations: <none>\nStatus: Running\nIP: 10.36.0.1\nIPs:\n IP: 10.36.0.1\nContainers:\n liveness:\n Container ID: docker://0f1ba830b830d5879fe99776cd0db5f3678bf52a11e3ccb1a1e9c65460957817\n Image: k8s.gcr.io/liveness\n Image ID: docker-pullable://k8s.gcr.io/liveness@sha256:1aef943db82cf1370d0504a51061fb082b4d351171b304ad194f6297c0bb726a\n Port: <none>\n Host Port: <none>\n Args:\n /server\n State: Running\n Started: Wed, 01 Apr 2020 06:01:15 +0000\n Last State: Terminated\n Reason: Error\n Exit Code: 2\n Started: Wed, 01 Apr 2020 05:58:16 +0000\n Finished: Wed, 01 Apr 2020 05:58:32 +0000\n Ready: True\n Restart Count: 7\n Liveness: http-get http://:8080/healthz delay=3s timeout=1s period=3s #success=1 #failure=3\n Environment: <none>\n Mounts:\n /var/run/secrets/kubernetes.io/serviceaccount from default-token-zshgs (ro)\nConditions:\n Type Status\n Initialized True\n Ready True\n ContainersReady True\n PodScheduled True\nVolumes:\n default-token-zshgs:\n Type: Secret (a volume populated by a Secret)\n SecretName: default-token-zshgs\n Optional: false\nQoS Class: BestEffort\nNode-Selectors: <none>\nTolerations: node.kubernetes.io/not-ready:NoExecute for 300s\n node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n Type Reason Age From Message\n ---- ------ ---- ---- -------\n Normal Scheduled <unknown> default-scheduler Successfully assigned default/liveness-http to worker02.acorn.com\n Normal Pulled 6m14s (x3 over 6m53s) kubelet, worker02.acorn.com Successfully pulled image \"k8s.gcr.io/liveness\"\n Normal Created 6m14s (x3 over 6m52s) kubelet, worker02.acorn.com Created container liveness\n Normal Started 6m14s (x3 over 6m52s) kubelet, worker02.acorn.com Started container liveness\n Normal Pulling 5m55s (x4 over 6m54s) kubelet, worker02.acorn.com Pulling image \"k8s.gcr.io/liveness\"\n Warning Unhealthy 5m55s (x9 over 6m40s) kubelet, worker02.acorn.com Liveness probe failed: HTTP probe failed with statuscode: 500\n Normal Killing 5m55s (x3 over 6m34s) kubelet, worker02.acorn.com Container liveness failed liveness probe, will be restarted\n Warning BackOff 108s (x17 over 5m36s) kubelet, worker02.acorn.com Back-off restarting failed container\n```\n\n로그이벤트를 보면 Liveness Probe 가 실패해서 컨테이너를 재가동 하는 메시지가 보입니다.\n\n뿐만아니라, 재가동 시에서 Pull image 를 통해 이미지를 다시 가져 와서 재가동 시키는 것을 볼 수 있습니다.\n\n## 11. Replication Controller\n\n### 11.1 Replication Controller 생성\n\n아래와 같이 template를 작성합니다.\n\n```{yaml}\napiVersion: v1\nkind: ReplicationController\nmetadata:\n name: goapp-rc\nspec:\n replicas: 3\n selector:\n app: goapp\n template:\n metadata:\n name: goapp-pod\n labels:\n tier: forntend\n app: goapp\n env: prod\n priority: high\n spec:\n containers:\n - name: goapp-container\n image: dangtong/goapp\n ports:\n - containerPort: 8080\n```\n\n### 11.2 Pod 생성\n\n```{bash}\nkubectl create -f ./rc-goapp.yaml\n```\n\n### 11.3 Pod 생성 확인\n\n```{bash}\nkubectl get po\n\nNAME READY STATUS RESTARTS AGE\ngoapp-rc-9q689 1/1 Running 0 39s\ngoapp-rc-d5rnf 1/1 Running 0 39s\ngoapp-rc-fm7kr 1/1 Running 0 39s\n```\n\n### 11.4 Replication Controller 확인\n\n```{bash}\nkubectl get rc\n\nNAME DESIRED CURRENT READY AGE\ngoapp-rc 3 3 3 58s\n\nkubectl get rc -o wide\n\nNAME DESIRED CURRENT READY AGE CONTAINERS IMAGES SELECTOR\ngoapp-rc 3 3 3 72s goapp-container dangtong/goapp app=goapp\n\n```\n\n### 11.5 특정 Pod 삭제하고 변화 확인하기\n\n아래와 같이 3개의 Pod 중에 하나를 선택해서 삭제 합니다.\n\n```{bash}\nkubectl deleete pod goapp-rc-9q689\n```\n\n```{bash}\nkubectl get pod\n\nNAME READY STATUS \t\t\t\t\t\tRESTARTS AGE\ngoapp-rc-d5rnf 1/1 Running \t\t\t\t\t\t0 2m\ngoapp-rc-fm7kr 1/1 Running \t\t\t\t\t\t0 2m\ngoapp-rc-szv2r 1/1 ContainerCreating \t0 6s\n```\n\n기존 컨테이너를 Terminating 하고 새로운 컨테이너를 생성하는 것을 볼 수 있습니다.\n\n### 11.6 Pod 정보를 라벨과 함께 출력해보기\n\n```{bash}\nkubectl get pod --show-labels\n\nNAME READY STATUS RESTARTS AGE LABELS\ngoapp-rc-d5rnf 1/1 Running 0 7m26s app=goapp\ngoapp-rc-fm7kr 1/1 Running 0 7m26s app=goapp\ngoapp-rc-szv2r 1/1 Running 0 4m51s app=goapp\n```\n\n### 11.7 Pod 라벨을 변경해보기\n\n기존 \"app=nginx\" 라는 label 을 \"app=goapp-exit\" 로 변경 합니다.\n\n```{bash}\nkubectl label pod goapp-rc-szv2r app=goapp-exit --overwrite\n```\n\n아래와 같이 pod 를 조회 해봅니다.\n\n```{bash}\nkubectl get po\n\nNAME READY STATUS RESTARTS AGE\ngoapp-rc-d5rnf 1/1 Running 0 8m49s\ngoapp-rc-fm7kr 1/1 Running 0 8m49s\ngoapp-rc-mmn2b 0/1 ContainerCreating 0 5s\ngoapp-rc-szv2r 1/1 Running 0 6m14s\n```\n\n기존 3개의 Pod 중 하나의 Label을 변경하면 기존 app=goapp 에는 2개의 Pod 만 남기 때문에 Replication Controller 는 **추가적으로 하나의 Pod 를 생성** 합니다.\n\n```{bash}\nNAME READY STATUS RESTARTS AGE LABELS\ngoapp-rc-d5rnf 1/1 Running 0 9m27s app=goapp\ngoapp-rc-fm7kr 1/1 Running 0 9m27s app=goapp\ngoapp-rc-mmn2b 1/1 Running 0 43s app=goapp\ngoapp-rc-szv2r 1/1 Running 0 6m52s app=goapp-exit\n```\n\n### 11.8 Pod Template 변경 해보기\n\n아래와 같이 Pod Template의 spec ➢ spec ➢ containers ➢ image 항목을 dangtong/goapp-v2 로 변경 합니다.\n\n```{bash}\nkubectl edit rc nginx\n```\n\n```{yaml}\n# Please edit the object below. Lines beginning with a '#' will be ignored,\n# and an empty file will abort the edit. If an error occurs while saving this file will be\n# reopened with the relevant failures.\n#\napiVersion: v1\nkind: ReplicationController\nmetadata:\n creationTimestamp: \"2020-04-01T09:32:23Z\"\n generation: 1\n labels:\n app: goapp\n name: goapp-rc\n namespace: default\n resourceVersion: \"405444\"\n selfLink: /api/v1/namespaces/default/replicationcontrollers/goapp-rc\n uid: 17198300-d964-4de6-a160-825a7a9c16bf\nspec:\n replicas: 3\n selector:\n app: goapp\n template:\n metadata:\n creationTimestamp: null\n labels:\n app: goapp\n name: goapp-pod\n spec:\n containers:\n - image: dangtong/goapp-v2 # 이부분을 변경 합닏다.(기존 : dangtong/goapp)\n imagePullPolicy: Always\n name: goapp-container\n ports:\n - containerPort: 80\n protocol: TCP\n resources: {}\n terminationMessagePath: /dev/termination-log\n terminationMessagePolicy: File\n dnsPolicy: ClusterFirst\n restartPolicy: Always\n schedulerName: default-scheduler\n securityContext: {}\n terminationGracePeriodSeconds: 30\nstatus:\n availableReplicas: 3\n fullyLabeledReplicas: 3\n observedGeneration: 1\n readyReplicas: 3\n replicas: 3\n```\n\n저장후 편집기를 종료 합니다.\n\n> 리눅스 편집기에는 다양한 종유가 있습니다. 만약 기본 편집기를 변경하고 싶으면\n>\n> KUBE_EDITOR=\"/bin/nano\" 를 $HOME/.bashrc 파일에 선언 해주면 원하는 편집기를 사용 할수 있습니다.\n\n###11.9 Pod Template 를 적용하기 위해 임의의 Pod 삭제하기\n\n```{bash}\nkubectl get pod\n\ngoapp-rc-mvw57 1/1 Running 0 3h6m 10.36.0.2 worker02.acorn.com\ngoapp-rc-qkrpw 1/1 Running 0 6m26s 10.32.0.2 worker01.acorn.com\ngoapp-rc-x6q4d 1/1 Running 0 3h6m 10.36.0.1 worker02.acorn.com\n```\n\nPod 삭제\n\n```{bash}\nkubectl delete pod goapp-rc-mvw57\n\npod \"goapp-rc-mvw57\" deleted\n```\n\nPod 확인\n\n```{bash}\nkubectl get pod\n\nNAME READY STATUS RESTARTS AGE\ngoapp-rc-bf2xk 0/1 ContainerCreating 0 8s\ngoapp-rc-qkrpw 1/1 Running 0 7m5s\ngoapp-rc-x6q4d 1/1 Running 0 3h7m\n\nkubectl get pod -o wide\n\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES\ngoapp-rc-bf2xk 1/1 Running 0 21s 10.32.0.3 worker01.acorn.com\ngoapp-rc-qkrpw 1/1 Running 0 7m18s 10.32.0.2 worker01.acorn.com\ngoapp-rc-x6q4d 1/1 Running 0 3h7m 10.36.0.1 worker02.acorn.com\n```\n\n접속 해보기\n\n```{bash}\n# dangtong/goapp\ncurl http://10.32.0.2:8080\nhostname: goapp-rc-qkrpw\n\n# dangtong/goapp-v3\ncurl http://10.32.0.3:8080\nhostname: goapp-rc-bf2xk\nversion: goapp-v2\n```\n\n###11.10 Pod 스케일링\n\n- Template 변경을 통한 스케일링\n\n 아래와 같이 goapp-rc 를 edit 명령으로 수정 합니다. (replicas 항목을 3에서 4로 수정)\n\n```{bash}\n정kubectl edit rc goapp-rc\n```\n\n```{yaml}\n# Please edit the object below. Lines beginning with a '#' will be ignored,\n# and an empty file will abort the edit. If an error occurs while saving this file will be\n# reopened with the relevant failures.\n#\napiVersion: v1\nkind: ReplicationController\nmetadata:\n creationTimestamp: \"2020-04-01T09:51:49Z\"\n generation: 3\n labels:\n app: goapp\n name: goapp-rc\n namespace: default\n resourceVersion: \"416408\"\n selfLink: /api/v1/namespaces/default/replicationcontrollers/goapp-rc\n uid: 23f58f51-88ab-4828-9a76-cde8a646fff4\nspec:\n replicas: 4 # 이부분을 변경 합니다. (기존 : 3)\n selector:\n app: goapp\n template:\n metadata:\n creationTimestamp: null\n labels:\n app: goapp\n name: goapp-pod\n spec:\n containers:\n - image: dangtong/goapp-v2\n imagePullPolicy: Always\n name: goapp-container\n ports:\n```\n\n저장 한다음 Pod 및 RC 확인\n\n```{bash}\nkubectl get pod\n\nNAME READY STATUS RESTARTS AGE\ngoapp-rc-bf2xk 1/1 Running 0 19m\ngoapp-rc-mr6kb 0/1 ContainerCreating 0 7s\ngoapp-rc-qkrpw 1/1 Running 0 26m\ngoapp-rc-x6q4d 1/1 Running 0 3h26m\n```\n\n```{bash}\nkubectl get rc\n\nNAME DESIRED CURRENT READY AGE\ngoapp-rc 4 4 4 4h17m\n```\n\n- 명령어를 통한 스케일링\n\n명령어를 이용해서 스케일링을 수행 할 수 있습니다.\n\n```{bash}\nkubectl scale rc goapp-rc --replicas=5\n```\n\n실제로 Pod 가 늘어 났는지 확인해봅니다.\n\n```{bash}\nkubectl get pod\n\nNAME READY STATUS RESTARTS AGE\ngoapp-rc-bf2xk 1/1 Running 0 72m\ngoapp-rc-dlgfc 0/1 ContainerCreating 0 4s\ngoapp-rc-mr6kb 1/1 Running 0 53m\ngoapp-rc-qkrpw 1/1 Running 0 79m\ngoapp-rc-x6q4d 1/1 Running 0 4h19m\n```\n\n###11.11 Replication Controller 삭제\n\nReplication Controller 와 POD 모두 삭제\n\n```{bash}\nkubectl delete rc goapp-rc\n```\n\nReplication Controller 만 삭제. POD 는 그대로 유지 합니다.\n\n```{bash}\nkubectl delete rc goapp-rc --cascade=false\n```\n\n## 12.ReplicaSet\n\n### 12.1 RS 생성\n\nSelector 를 작성 할때 **ForntEnd** 이고 **운영계** 이면서 중요도가 **High** 인 POD 에 대해 RS 를 생성 합니다.\n\n```{yaml}\napiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n name: frontend\n labels:\n app: guestbook\n tier: frontend\nspec:\n replicas: 3\n selector:\n matchLabels:\n tier: frontend\n matchExpressions:\n - {key: env, operator: In, values: [prod]}\n - {key: priority, operator: NotIn, values: [low]}\n template:\n metadata:\n labels:\n tier: frontend\n env: prod\n priority: high\n spec:\n containers:\n - name: php-redis\n image: gcr.io/google_samples/gb-frontend:v3\n```\n\n### 12.2 RS 확인\n\n```{bash}\n$ kubectl get pod -o wide\n\nNAME READY STATUS RESTARTS AGE IP NODE\nfrontend-bstms 1/1 Running 0 53s 10.32.2.7 gke-gke1-default-pool-ad44d907-cq8j\nfrontend-d4znb 1/1 Running 0 53s 10.32.2.9 gke-gke1-default-pool-ad44d907-cq8j\nfrontend-rv9bl 1/1 Running 0 53s 10.32.2.8 gke-gke1-default-pool-ad44d907-cq8j\n```\n\n```{bash}\n$ kubectl get rs -o wide\n\nAME READY STATUS RESTARTS AGE IP NODE\nfrontend-bstms 1/1 Running 0 68s 10.32.2.7 gke-gke1-default-pool-ad44d907-cq8j\nfrontend-d4znb 1/1 Running 0 68s 10.32.2.9 gke-gke1-default-pool-ad44d907-cq8j\nfrontend-rv9bl 1/1 Running 0 68s 10.32.2.8 gke-gke1-default-pool-ad44d907-cq8j\n\n```\n\n```{bash}\n$ kubectl get pod --show-labels\n\nNAME READY STATUS RESTARTS AGE LABELS\nfrontend-bstms 1/1 Running 0 107s env=prod,priority=high,tier=frontend\nfrontend-d4znb 1/1 Running 0 107s env=prod,priority=high,tier=frontend\nfrontend-rv9bl 1/1 Running 0 107s env=prod,priority=high,tier=frontend\n```\n\n### [[Exercise #5]]\n\n1. Nginx Pod 3개로 구성된 Replication Controller를 작성 하세요\n2. Replication Controller 만 삭제 하세요(Pod 는 유지)\n3. 남겨진 Nginx Pod를 관리하는 ReplicaSet 을 작성하된 replica 4개로 구성 하시요\n4. Nginx Pod 를 6개로 Scale Out 하세요\n\n## 13.DeamonSet\n\n### 13.1 데몬셋 생성\n\ngoapp-ds.yaml 이라는 이름으로 아래 파일을 작성 합니다.\n\n```{yaml}\npiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n name: goapp-on-ssd\nspec:\n selector:\n matchLabels:\n app: goapp-pod\n template:\n metadata:\n labels:\n app: goapp-pod\n spec:\n nodeSelector:\n disk: ssd\n containers:\n - name: goapp-container\n image: dangtong/goapp\n```\n\n데몬셋을 생성 합니다.\n\n```{bash}\n$ kubectl create -f ./goapp-ds.yaml\n```\n\nPod 와 데몬셋을 조회 합니다.\n\n```{bash}\n$ kubectl get pod\n\n$ kubectl get ds\n\nNAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE\ngoapp-on-ssd 0 0 0 0 0 disk=ssd <nome>\n```\n\n조회 하면 Pod 도 존재하지 않고 데몬셋 정보를 조회 해도 모두 0 으로 나옵닏다. 노드에 disk=ssd 라벨이 없기 때문입니다.\n\n이제 라벨을 추가 합니다.\n\n```{bash}\n$ kubectl label node worker01.acorn.com disk=ssd\n\n$ kubectl get pod\nNAME READY STATUS RESTARTS AGE\ngoapp-on-ssd-vwvks 1/1 Running 0 7s\n\n$ kubectl label node worker02.acorn.com disk=ssd\n\n$ kubectl get pod\nNAME READY STATUS RESTARTS AGE\ngoapp-on-ssd-nbnwz 1/1 Running 0 7s\ngoapp-on-ssd-vwvks 1/1 Running 0 36s\n\n$ kubectl get ds -o wide\nAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE\ngoapp-on-ssd 2 2 2 2 2 disk=ssd 10m\n```\n\n## 14.Deployment\n\n### 14.1 Deployment 생성\n\n아래와 같이 nginx 를 서비스 하고 replica 가 3개인 Deployment 를 작성합니다.(nginx-deploy.yaml)\n\n```{yaml}\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n name: nginx-deployment\n labels:\n app: nginx\nspec:\n replicas: 3\n selector:\n matchLabels:\n app: nginx\n template:\n metadata:\n labels:\n app: nginx\n spec:\n containers:\n - name: nginx\n image: nginx:1.7.9\n ports:\n - containerPort: 80\n\n```\n\n```{bash}\nkubectl apply -f ./nginx-deploy.yaml\n```\n\n### 14.2 Deployment 확인\n\n```{bash}\nkubectl get pod,rs,deploy\nNAME READY STATUS RESTARTS AGE\npod/nginx-deployment-54f57cf6bf-dpsn4 1/1 Running 0 30s\npod/nginx-deployment-54f57cf6bf-ghfwm 1/1 Running 0 30s\npod/nginx-deployment-54f57cf6bf-rswwk 1/1 Running 0 30s\n\nNAME DESIRED CURRENT READY AGE\nreplicaset.apps/nginx-deployment-54f57cf6bf 3 3 3 30s\n\nNAME READY UP-TO-DATE AVAILABLE AGE\ndeployment.apps/nginx-deployment 3/3 3 3 30s\n```\n\n### 14.3 이미지 업데이트\n\n- 기본 방식\n\n```{yaml}\nkubectl --record deployment.apps/nginx-deployment set image deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1\n```\n\n- 단축 방식\n\n```{bash}\nkubectl set image deployment/nginx-deployment nginx=nginx:1.9.1 --record\n```\n\n- yaml 파일 수정(.spec.template.spec.containers[0].image 변경)\n\n```{bash}\nkubectl edit deployment.v1.apps/nginx-deployment\n```\n\n- 롤백\n\n```shell\nkubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.7.9 --record=true\n```\n\n### 14.4 Deployment ScaleOut\n\n```{bash}\nkubectl edit deploy goapp-deployment\n\nkubectl scale deploy nginx-deployment\ngoapp-deployment-5857594fbb-2hhnv 1/1 Running 0 32m\ngoapp-deployment-5857594fbb-6s9lx 1/1 Running 0 6s\ngoapp-deployment-5857594fbb-7nqsg 1/1 Running 0 32m\ngoapp-deployment-5857594fbb-9b28s 1/1 Running 0 32m\n```\n\n### 14.4 deployment 확인 하기\n\n- 롤아웃 확인\n\n```{bash}\nkubectl rollout status deployment.v1.apps/nginx-deployment\n```\n\n- deployment 상세 확인\n\n```{bash}\nkubectl describe deploy nginx-deployment\n```\n\n### [[Exercise #6]]\n\n1.\n\n## 5. 서비스 (Service)\n\n### 5.1 ClusterIP\n\n#### 5.1.0 nodes app 생성\n\n```{javascript}\nconst http = require('http');\nconst os = require('os');\n\nconsole.log(\"Kubia server starting...\");\n\nvar handler = function(request, response) {\n console.log(\"Received request from \" + request.connection.remoteAddress);\n response.writeHead(200);\n response.end(\"You've hit \" + os.hostname() + \"\\n\");\n};\n\nvar www = http.createServer(handler);\nwww.listen(8080);\n```\n\n#### 5.1.1. pod 생성\n\n```{yaml}\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n name: nodeapp-deploy\nspec:\n replicas: 3\n selector:\n matchLabels:\n app: nodeapp-pod\n template:\n metadata:\n labels:\n app: nodeapp-pod\n spec:\n containers:\n - name: nodeapp-container\n image: dangtong/nodeapp\n ports:\n - containerPort: 8080\n```\n\n#### 5.1.2 yaml을 통한 ClusterIP 생성\n\n```{yaml}\napiVersion: v1\nkind: Service\nmetadata:\n name: nodeapp-service\nspec:\n ports:\n - port: 80\n targetPort: 8080\n selector:\n app: nodeapp-pod\n```\n\n#### 5.1.3 서비스 상태 확인\n\n```{bash}\nkubectl get po,deploy,svc\n\nNAME READY STATUS RESTARTS AGE\npod/nodeapp-deployment-55688d9d4b-8pzsk 1/1 Running 0 2m45s\npod/nodeapp-deployment-55688d9d4b-pslvb 1/1 Running 0 2m46s\npod/nodeapp-deployment-55688d9d4b-whbk8 1/1 Running 0 2m46s\n\nNAME READY UP-TO-DATE AVAILABLE AGE\ndeployment.apps/nodeapp-deployment 3/3 3 3 2m46s\n\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\nnodeapp-service ClusterIP 10.101.249.42 <none> 80/TCP 78s\n```\n\n#### 5.1.4 서비스 확인\n\n```{bash}\ncurl http://10.101.249.42 #여러번 수행 하기\n\nYou've hit nodeapp-deployment-55688d9d4b-8pzsk\n```\n\n#### 5.1.5 원격 Pod에서 curl 명령 수행하기\n\n```{bash}\nkubectl exec nodeapp-deployment-55688d9d4b-8pzsk -- curl -s http://10.101.249.42\n\nYou've hit nodeapp-deployment-55688d9d4b-whbk8\n```\n\n> .더블 대시는 kubectl 명령의의 종료를 가르킴\n\n#### 5.1.6 서비스 삭제\n\n```{bash}\nkubectl delete svc nodeapp-service\n```\n\n### 5.2 NodePort\n\n#### 5.2.1 yaml 을 이용한 NodePort 생성 (GCP 에서 수행 하기)\n\n```{yaml}\napiVersion: v1\nkind: Service\nmetadata:\n name: node-nodeport\nspec:\n type: NodePort\n ports:\n - port: 80\n targetPort: 8080\n nodePort: 30123\n selector:\n app: node\n```\n\n#### 5.2.2 NodePort 조회\n\n```{bash}\nkubectl get po,rs,svc\n\nNAME READY STATUS RESTARTS AGE\npod/nodeapp-deployment-55688d9d4b-8pzsk 1/1 Running 0 145m\npod/nodeapp-deployment-55688d9d4b-pslvb 1/1 Running 0 145m\npod/nodeapp-deployment-55688d9d4b-whbk8 1/1 Running 0 145m\n\nNAME DESIRED CURRENT READY AGE\nreplicaset.apps/nodeapp-deployment-55688d9d4b 3 3 3 145m\n\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\nservice/kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 10d\nservice/nodeapp-nodeport NodePort 10.108.30.68 <none> 80:30123/TCP 4m14s\n```\n\n#### 5.2.3 NodePort 를 통한 서비스 접속 확인(여러번 수행)\n\n```{bash}\n$ curl http://localhost:30123\nYou've hit nodeapp-deployment-55688d9d4b-pslvb\n\n$ curl http://localhost:30123\nYou've hit nodeapp-deployment-55688d9d4b-whbk8\n\n$ curl http://localhost:30123\nYou've hit nodeapp-deployment-55688d9d4b-pslvb\n\n```\n\n#### 5.2.4 NodePort 삭제\n\n```{bash}\nkubectl delete svc nodeapp-nodeport\n```\n\n### 5.3 LoadBalancer (GCP 에서 수행)\n\n#### 5.3.1 yaml 파일로 deployment 생성\n\n```{bash}\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n name: nodeapp-deployment\n labels:\n app: nodeapp\nspec:\n replicas: 3\n selector:\n matchLabels:\n app: nodeapp-pod\n template:\n metadata:\n labels:\n app: nodeapp-pod\n spec:\n containers:\n - name: nodeapp-container\n image: dangtong/nodeapp\n ports:\n - containerPort: 8080\n```\n\n#### 5.3.2 서비스 확인\n\n```{bash}\n$ kubectl get po,rs,deploy\n\nNAME READY STATUS RESTARTS AGE\npod/nodeapp-deployment-7d58f5d487-7hphx 1/1 Running 0 20m\npod/nodeapp-deployment-7d58f5d487-d74rp 1/1 Running 0 20m\npod/nodeapp-deployment-7d58f5d487-r8hq8 1/1 Running 0 20m\nNAME DESIRED CURRENT READY AGE\nreplicaset.extensions/nodeapp-deployment-7d58f5d487 3 3 3 20m\nNAME READY UP-TO-DATE AVAILABLE AGE\ndeployment.extensions/nodeapp-deployment 3/3 3 3 20m\n```\n\n```{bash}\nkubectl get po -o wide\n\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES\nnodeapp-deployment-7d58f5d487-7hphx 1/1 Running 0 21m 10.32.2.10 gke-gke1-default-pool-ad44d907-cq8j\nnodeapp-deployment-7d58f5d487-d74rp 1/1 Running 0 21m 10.32.2.12 gke-gke1-default-pool-ad44d907-cq8j\nnodeapp-deployment-7d58f5d487-r8hq8 1/1 Running 0 21m 10.32.2.11 gke-gke1-default-pool-ad44d907-cq8j\n```\n\n#### 5.3.2 nodeapp 접속 해보기\n\n```{bash}\n$ kubectl exec nodeapp-deployment-7d58f5d487-7hphx -- curl -s http://10.32.2.10:8080\n또는\n$ kubectl exec -it nodeapp-deployment-7d58f5d487-7hphx bash\n\n$ curl http://10.32.2.10:8080\nYou've hit nodeapp-deployment-7d58f5d487-7hphx\n```\n\n#### 5.3.3 yaml 파일을 이용해 LoadBalancer 생성\n\n```{yaml}\napiVersion: v1\nkind: Service\nmetadata:\n name: nodeapp-lb\nspec:\n type: LoadBalancer\n ports:\n - port: 80\n targetPort: 8080\n selector:\n app: nodeapp-pod\n```\n\n#### 5.3.5 LoadBalancer 생성 확인\n\n```{bash}\nkubectl get svc\n\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\nkubernetes ClusterIP 10.36.0.1 <none> 443/TCP 7d21h\nnodeapp-lb LoadBalancer 10.36.14.234 <pending> 80:31237/TCP 33s\n```\n\n현재 pending 상태임 20초 정도 지나면\n\n```{bash}\nkubectl get svc\n\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\nkubernetes ClusterIP 10.36.0.1 <none> 443/TCP 7d21h\nnodeapp-lb LoadBalancer 10.36.14.234 35.221.179.171 80:31237/TCP 45s\n```\n\n#### 5.3.6 서비스 확인\n\n```{bash}\ncurl http://35.221.179.171\n\nYou've hit nodeapp-deployment-7d58f5d487-r8hq8\n```\n\n### 5.4 Ingress (GCP 에서 수행)\n\n#### 5.4.1 Deployment 생성\n\n- nginx / goapp deployment 생성\n\n```{yaml}\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n name: nginx-deployment\n labels:\n app: nginx\nspec:\n replicas: 3\n selector:\n matchLabels:\n app: nginx\n template:\n metadata:\n labels:\n app: nginx\n spec:\n containers:\n - name: nginx-container\n image: nginx:1.7.9\n ports:\n - containerPort: 80\n---\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n name: goapp-deployment\n labels:\n app: goapp\nspec:\n replicas: 3\n selector:\n matchLabels:\n app: goapp\n template:\n metadata:\n labels:\n app: goapp\n spec:\n containers:\n - name: goapp-container\n image: dangtong/goapp\n ports:\n - containerPort: 8080\n```\n\n#### 5.4.2 Service 생성\n\n```{yaml}\napiVersion: v1\nkind: Service\nmetadata:\n name: nginx-lb\nspec:\n type: LoadBalancer\n ports:\n - port: 80\n targetPort: 80\n selector:\n app: nginx\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n name: goapp-lb\nspec:\n type: LoadBalancer\n ports:\n - port: 80\n targetPort: 8080\n selector:\n app: goapp\n```\n\n#### 5.4.3 Ingress 생성\n\n```{yaml}\napiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n name: nginx-goapp-ingress\nspec:\n tls:\n - hosts:\n - nginx.acorn.com\n - goapp.acorn.com\n secretName: acorn-secret\n rules:\n - host: nginx.acorn.com\n http:\n paths:\n - path: /\n backend:\n serviceName: nginx-lb\n servicePort: 80\n - host: goapp.acorn.com\n http:\n paths:\n - path: /\n backend:\n serviceName: goapp-lb\n servicePort: 80\n```\n\n#### 5.4.4 Ingress 조회\n\n```{bash}\nkubectl get ingress\n\nNAME HOSTS ADDRESS PORTS AGE\nnginx-goapp-ingress nginx.acorn.com,goapp.acorn.com 80, 443 15s\n```\n\n> Ingress 가 완전히 생성되기 까지 시간이 걸립니다. 2~5분 소요\n\n다시 조회 합니다\n\n```{bash}\nkubectl get ingress\n\nNAME HOSTS ADDRESS PORTS AGE\nnginx-goapp-ingress nginx.acorn.com,goapp.acorn.com 35.227.227.127 80, 443 13m\n```\n\n#### 5.4.5 /etc/hosts 파일 수정\n\n```{bash}\nsudo vi /etc/hosts\n\n35.227.227.127 nginx.acorn.com goapp.acorn.com\n```\n\n#### 5.4.6 서비스 확인\n\n```{bash}\n$ curl http://goapp.acorn.com\nhostname: goapp-deployment-d7564689f-6rrzw\n\n$ curl http://nginx.acorn.com\n<!DOCTYPE html>\n<html>\n<head>\n<title>Welcome to nginx!</title>\n<style>\n body {\n width: 35em;\n margin: 0 auto;\n font-family: Tahoma, Verdana, Arial, sans-serif;\n }\n</style>\n</head>\n<body>\n\n```\n\n#### 5.4.7 HTTPS 서비스 (TLS OffLoad)\n\n- 인증서 생성 및 인증서 secret 등록\n\n```{bash}\nopenssl genrsa -out server.key 2048\n\nopenssl req -new -x509 -key server.key -out server.cert -days 360 -subj /CN=nginx.acorn.com\n\nkubectl create secret tls acorn-secret --cert=server.cert --key=server.key\n```\n\n- 테스트\n\n```{bash}\n$ curl -k https://nginx.acorn.com\n\n$ curl -k https://goapp.acorn.com\n```\n\n## 7.Volums\n\n### 7.1 EmptyDir (GCP 에서 수행)\n\n#### 7.1.1 Docker 이미지 만들기\n\n아래와 같이 폴더를 만들고 ./fortune/docimg 폴더로 이동합니다.\n\n```{bash}\n$ mkdir -p ./fortune/docimg\n$ mkdir -p ./fortune/kubetmp\n\n```\n\n아래와 같이 docker 이미지를 작성하기 위해 bash 로 Application을 작성 합니다.\n\n파일명 : fortuneloop.sh\n\n```{bash}\n#!/bin/bash\ntrap \"exit\" SIGINT\nmkdir /var/htdocs\nwhile :\ndo\n echo $(date) Writing fortune to /var/htdocs/index.html\n /usr/games/fortune > /var/htdocs/index.html\n sleep 10\ndone\n```\n\nDockerfile 을 작성 합니다.\n\n```{dockerfile}\nFROM ubuntu:latest\nRUN apt-get update; apt-get -y install fortune\nADD fortuneloop.sh /bin/fortuneloop.sh\nENTRYPOINT /bin/fortuneloop.sh\n```\n\nDcoker 이미지를 만듭니다.\n\n```{bash}\n$ docker build -t dangtong/fortune .\n```\n\nDocker 이미지를 Docker Hub 에 push 합니다.\n\n```{bash}\n$ docker login\n$ docker push dangtong/fortune\n```\n\n#### 7.1.2 Deployment 작성\n\nfortune APP을 적용하기 위해 Deployment 를 작성 합니다.\n\n```{bash}\ncd ../ktmp/\nvi fortune-deploy.yaml\n```\n\n```{yaml}\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n name: fortune-deployment\n labels:\n app: fortune\nspec:\n replicas: 3\n selector:\n matchLabels:\n app: fortune\n template:\n metadata:\n labels:\n app: fortune\n spec:\n containers:\n - image: dangtong/fortune\n name: html-generator\n volumeMounts:\n - name: html\n mountPath: /var/htdocs\n - image: nginx:alpine\n name: web-server\n volumeMounts:\n - name: html\n mountPath: /usr/share/nginx/html\n readOnly: true\n ports:\n - containerPort: 80\n protocol: TCP\n volumes:\n - name: html\n emptyDir: {}\n```\n\n> html 볼륨을 html-generator 및 web-seerver 컨테이너에 모두 마운트 하였습니다.\n>\n> html 볼륨에는 /var/htdocs 및 /usr/share/nginx/html 이름 으로 서로 따른 컨테이너에서 바라 보게 됩니다.\n>\n> 다만, web-server 컨테이너는 읽기 전용(reeadOnly) 으로만 접근 하도록 설정 하였습니다.\n\n> emptDir 을 디스크가 아닌 메모리에 생성 할 수도 있으며, 이를 위해서는 아래와 같이 설정을 바꾸어 주면 됩니다.\n>\n> emptyDir:\n>\n> ​ medium: Memory\n\n#### 7.1.3 LoadBalancer 작성\n\n```{bash}\nvi fortune-lb.yaml\n```\n\n```{yaml}\napiVersion: v1\nkind: Service\nmetadata:\n name: fortune-lb\nspec:\n selector:\n app: fortune\n ports:\n - port: 80\n targetPort: 80\n type: LoadBalancer\n externalIPs:\n - 192.168.56.108\n```\n\n#### 7.1.4 Deployment 및 Loadbalancer 생성\n\n```{bash}\n$ kubectl apply -f ./fortune-deploy.yaml\n$ kubectl apply -f ./fortune-lb.yaml\n```\n\n#### 7.1.5. 서비스 확인\n\n```{bash}\ncurl http://192.168.56.108\n```\n\n### 7.2 Git EmptyDir\n\n#### 7.2.1 웹서비스용 Git 리포지토리 생성\n\nAppendix3 . Git 계정 생성 및 Sync 참조\n\n#### 7.2.2 Deployment 용 yaml 파일 작성\n\n```{bash}\n$ cd ./gitvolume/kubetmp\n$ vi gitvolume-deploy.yaml\n```\n\n```{yaml}\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n name: gitvolume-deployment\n labels:\n app: nginx\nspec:\n replicas: 3\n selector:\n matchLabels:\n app: nginx\n template:\n metadata:\n labels:\n app: nginx\n spec:\n containers:\n - image: nginx:alpine\n name: web-server\n volumeMounts:\n - name: html\n mountPath: /usr/share/nginx/html\n readOnly: true\n ports:\n - containerPort: 80\n protocol: TCP\n volumes:\n - name: html\n gitRepo:\n repository: https://github.com/dangtong76/k8s-web.git\n revision: master\n directory: .\n\n```\n\n#### 7.2.3 Deployment 생성\n\n```{bash}\n$ kubectl apply -f ./gitvolume-deploy.yaml\n```\n\n### 7.3 GCE Persisteent DISK 사용하기\n\n#### 7.3.1. Persistent DISK 생성\n\n- 리전/존 확인\n\n```{bash}\n$ gcloud container clusters list\n```\n\n- Disk 생성\n\n```{bash}\n$ gcloud compute disks create --size=16GiB --zone asia-northeast1-b mongodb\n# 삭제\n# gcloud compute disks delete mongodb --zone asia-northeast1-b\n```\n\n#### 7.3.2 Pod 생성을 위한 yaml 파일 작성\n\n- 파일명 : gce-pv.yaml\n\n```{yaml}\napiVersion: v1\nkind: Pod\nmetadata:\n name: mongodb\nspec:\n volumes:\n - name: mongodb-data\n gcePersistentDisk:\n pdName: mongodb\n fsType: ext4\n containers:\n - image: mongo\n name: mongodb\n volumeMounts:\n - name: mongodb-data\n mountPath: /data/db\n ports:\n - containerPort: 27017\n protocol: TCP\n```\n\n- Pod 생성\n\n```{bash}\n$ kubectl apply -f ./gce-pv.yaml\n\n$ kubectl get po\n\nNAME READY STATUS RESTARTS AGE\nmongodb 1/1 Running 0 8m42s\n```\n\n- Disk 확인\n\n```{bash}\n$ kubectl describe pod mongodb\n\n...(중략)\n\nVolumes:\n mongodb-data:\n Type: GCEPersistentDisk (a Persistent Disk resource in Google Compute Engine)\n PDName: mongodb # 디스크이름\n FSType: ext4\n Partition: 0\n ReadOnly: false\n default-token-dgkd5:\n Type: Secret (a volume populated by a Secret)\n SecretName: default-token-dgkd5\n Optional: false\n\n...(중략)\n\n```\n\n#### 7.3.3 Mongodb 접속 및 데이터 Insert\n\n- 접속\n\n```{bash}\nkubectl exec -it mongodb mongo\n```\n\n- 데이터 Insert\n\n```{bash}\n> use mystore\n> db.foo.insert({\"first-name\" : \"dangtong\"})\n\n> db.foo.find()\n{ \"_id\" : ObjectId(\"5f9c4127caf2e6464e18331c\"), \"first-name\" : \"dangtong\" }\n\n> exit\n```\n\n#### 7.3.4 MongoDB Pod 재시작\n\n- MongoDB 중단\n\n```{bash}\n$ kubectl delete pod mongodb\n```\n\n- MongoDB Pod 재생성\n\n```{bash}\n$ kubectl apply -f ./gce-pv.yaml\n```\n\n- 기존에 Insert 한 데이터 확인\n\n```{bash}\n$ kubectl exec -it mongodb mongo\n\n> use mystore\n\n> db.foo.find()\n{ \"_id\" : ObjectId(\"5e9684134384860bc207b1f9\"), \"first-name\" : \"dangtong\" }\n```\n\n#### 7.3.5 Pod 삭제\n\n```{bash}\n$ kubectl delete po mongodb\n```\n\n### 7.4 PersistentVolume 및 PersistentVolumeClaim\n\n#### 7.4.1 PersistentVolume 생성\n\ngce-pv2.yaml 로 작성\n\n```{yaml}\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n name: mongodb-pv\nspec:\n capacity:\n storage: 1Gi\n accessModes:\n - ReadWriteOnce\n - ReadOnlyMany\n persistentVolumeReclaimPolicy: Retain\n gcePersistentDisk:\n pdName: mongodb\n fsType: ext4\n```\n\n```{bash}\nkubectl apply -f ./gce-pv2.yaml\n```\n\n```{bash}\nkubectl get pv\n```\n\n#### 7.4.2 PersistentVolumeClaim 생성\n\ngce-pvc.yaml 로 작성\n\n```{yaml}\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n name: mongodb-pvc\nspec:\n resources:\n request:\n storage: 1Gi\n accessModes:\n - ReadWriteOnce\n storageClassName: \"\"\n```\n\n```{bash}\nkubectl apply -f ./gce-pvc.yaml\n```\n\n```{bash}\nkubectl get pvc\n```\n\n#### 7.4.3 PV, PVC 를 이용한 Pod 생성\n\ngce-pod.yaml 파일 생성\n\n```{yaml}\napiVersion: v1\nkind: Pod\nmetadata:\n name: mongodb\nspec:\n containers:\n - image: mongo\n name: mongodb\n volumeMounts:\n - name: mongodb-data\n mountPath: /data/db\n - Ports:\n - containerPort: 27017\n protocol: TCP\n volumes:\n - name: mongodb-data\n persistentVolumeClaim:\n claimName: mongdodb-pvc\n```\n\n```bash\n$ kubectl apply -f ./gce-pod.yaml\n```\n\n```{bash}\n$ kubectl get po,pv,pvc\n```\n\n#### 7.4.4 Mongodb 접속 및 데이터 확인\n\n```{bash}\n$ kubectl exec -it mongodb mongo\n\n> use mystore\n\n> db.foo.find()\n\n```\n\n### 7.5 Persistent Volume 의 동적 할당\n\n#### 7.5.1 StorageClass 를 이용해 스토리지 유형 정의\n\n- gce-sclass.yaml\n- 존환인 : **gcloud** container clusters list\n\n```{yaml}\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n name: fast\nprovisioner: kubernetes.io/gce-pd\nparameters:\n type: pd-ssd\n zone: asia-northeast1-b #클러스터를 만든 지역으로 설정 해야함\n```\n\n```{bash}\n$ kubectl apply -f ./gce-sclass.yaml\n```\n\n#### 7.5.2 PVC 생성\n\n- gce-pvc-sclass.yaml\n\n```{yaml}\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n name: mongodb-pvc\nspec:\n storageClassName: fast\n resources:\n requests:\n storage: 100Mi\n accessModes:\n - ReadWriteOnce\n```\n\n```{bash}\n$ kubectl apply -f ./gce-pvc-sclass.yaml\n```\n\n#### 7.5.3 PV 및 PVC 확인\n\n- pvc 확인\n\n```{bash}\n$ kubectl get pvc mongdb-pvc\n\n```\n\n- pv 확인\n\n```{bash}\n$ kubectl get pv\n```\n\n#### 7.5.4 PVC 를 이용한 POD 생성\n\n파일명 : gce-pod.yaml 파일 생성\n\n```{yaml}\napiVersion: v1\nkind: Pod\nmetadata:\n name: mongodb\nspec:\n containers:\n - image: mongo\n name: mongodb\n volumeMounts:\n - name: mongodb-data\n mountPath: /data/db\n - Ports:\n - containerPort: 27017\n protocol: TCP\n volumes:\n - name: mongodb-data\n persistentVolumeClaim:\n claimName: mongdodb-pvc\n```\n\n## 8. ConfigMap\n\n#### 8.1 도커에서 매개변수 전달\n\n##### 8.1.1 디렉토리 생성 및 소스 코드 작성\n\n```{bash}\nmkdir -p ./configmap/docimg/indocker\nmkdir -p ./configmap/kubetmp\n\ncd ./configmap/docimg/indocker\nvi fortuneloop.sh\n```\n\n```{bash}\n#!/bin/bash\ntrap \"exit\" SIGINT\nINTERVAL=$1\necho \"Configured to generate neew fortune every \" $INTERVAL \" seconds\"\nmkdir /var/htdocs\nwhile :\ndo\n echo $(date) Writing fortune to /var/htdocs/index.html\n /usr/games/fortune > /var/htdocs/index.html\n sleep $INTERVAL\ndone\n```\n\n```{bash}\nchmod 755 fortuneloop.sh\n```\n\n##### 8.1.2 Docker 이미지 생성\n\n```{bash}\n$ vi dockerfile\n```\n\n```{dockerfile}\nFROM ubuntu:latest\nRUN apt-get update; apt-get -y install fortune\nADD fortuneloop.sh /bin/fortuneloop.sh\nENTRYPOINT [\"/bin/fortuneloop.sh\"]\nCMD [\"10\"] # args가 없으면 10초\n```\n\n```{bash}\n$ docker build -t dangtong/fortune:args .\n$ docker push dangtong/fortune:args\n```\n\n> 테스트를 위해 다음과 같이 수행 가능\n>\n> $ docker run -it dangtong/fortune:args # 기본 10초 수행\n>\n> $ docker run -it dangtong/fortune:args 15 # 15초로 매개변수 전달\n\n##### 8.1.3 Pod생성\n\n파일명 : config-fortune-pod.yaml\n\n```{bash}\ncd ../../kubetmp\nvi config-fortune-indocker-pod.yaml\n```\n\n```{yaml}\napiVersion: v1\nkind: Pod\nmetadata:\n name: fortune5s\nspec:\n containers:\n - image: dangtong/fortune:args\n args: [\"5\"]\n name: html-generator\n volumeMounts:\n - name: html\n mountPath: /var/htdocs\n - image: nginx:alpine\n name: web-server\n volumeMounts:\n - name: html\n mountPath: /usr/share/nginx/html\n readOnly: true\n ports:\n - containerPort: 80\n protocol: TCP\n volumes:\n - name: html\n emptyDir: {}\n```\n\n```{bash}\nkubectl apply -f ./config-fortune-indockeer-pod.yaml\n```\n\n#### 8.2 Yaml 파일을 통한 매개변수 전달\n\n##### 8.2.1 fortuneloop.sh 작성\n\n```{bash}\ncd ../\nmkdir -p ./docimg/inyaml\ncd ./docimg/inyaml\nvi fortuneloop.sh\n```\n\n```{bash}\n#!/bin/bash\ntrap \"exit\" SIGINT\necho \"Configured to generate neew fortune every \" $INTERVAL \" seconds\"\nmkdir /var/htdocs\nwhile :\ndo\n echo $(date) Writing fortune to /var/htdocs/index.html\n /usr/games/fortune > /var/htdocs/index.html\n sleep $INTERVAL\ndone\n```\n\n##### 8.2.2 Dockerfile 작성 및 build\n\n```{bash}\n$ vi dockerfile\n```\n\n```{dockerfile}\nFROM ubuntu:latest\nRUN apt-get update; apt-get -y install fortune\nADD fortuneloop.sh /bin/fortuneloop.sh\nENTRYPOINT [\"/bin/fortuneloop.sh\"]\nCMD [\"10\"] # args가 없으면 10초\n```\n\n```{bash}\n$ docker build -t dangtong/fortune:env .\n$ docker push dangtong/fortune:env\n```\n\n##### 8.2.2 Pod 생성및 매개변수 전달을 위한 yaml 파일 작성\n\n```{bash}\ncd ../../kubetmp\nvi config-fortune-inyaml-pod.yaml\n```\n\n```{yaml}\napiVersion: v1\nkind: Pod\nmetadata:\n name: fortune30s\nspec:\n containers:\n - image: dangtong/fortune:env\n env:\n - name: INTERVAL\n value: \"30\"\n name: html-generator\n volumeMounts:\n - name: html\n mountPath: /var/htdocs\n - image: nginx:alpine\n name: web-server\n volumeMounts:\n - name: html\n mountPath: /usr/share/nginx/html\n readOnly: true\n ports:\n - containerPort: 80\n protocol: TCP\n volumes:\n - name: html\n emptyDir: {}\n```\n\n#### 8.3 ConfigMap 을 통한 설정\n\n##### 8.3.1 ConfigMap 생성 및 확인\n\n- configMap 생성\n\n```{bash}\n$ kubectl create configmap fortune-config --from-literal=sleep-interval=7\n```\n\n> ConfigMap 생성시 이름은 영문자,숫자, 대시, 밑줄, 점 만 포함 할 수 있습니다.\n>\n> 만약 여러개의 매개변수를 저장 할려면 --from-literal=sleep-interval=5 --from-literal=sleep-count=10 와 같이 from-literal 부분을 여러번 반복해서 입력 하면 됩니다.\n\n- configMap 확인\n\n```{bash}\n$ kubectl get cm fortune-config\n\nNAME DATA AGE\nfortune-config 1 15s\n\n$ kubectl get configmap fortune-config. -o yaml\n\napiVersion: v1\ndata:\n sleep-interval: \"7\"\nkind: ConfigMap\nmetadata:\n creationTimestamp: \"2020-04-16T09:09:33Z\"\n name: fortune-config\n namespace: default\n resourceVersion: \"1044269\"\n selfLink: /api/v1/namespaces/default/configmaps/fortune-config\n uid: 85723e0a-1959-4ace-9365-47c101ebef82\n```\n\n##### 8.3.2 ConfigMap을 환경변수로 전달한는 yaml 파일 작성\n\n- Yaml 파일 생성\n\n```{bash}\nvi config-fortune-mapenv-pod.yaml\n```\n\n```{yaml}\napiVersion: v1\nkind: Pod\nmetadata:\n name: fortune7s\nspec:\n containers:\n - image: dangtong/fortune:env\n env:\n - name: INTERVAL\n valueFrom:\n configMapKeyRef:\n name: fortune-config\n key: sleep-interval\n name: html-generator\n volumeMounts:\n - name: html\n mountPath: /var/htdocs\n - image: nginx:alpine\n name: web-server\n volumeMounts:\n - name: html\n mountPath: /usr/share/nginx/html\n readOnly: true\n ports:\n - containerPort: 80\n protocol: TCP\n volumes:\n - name: html\n emptyDir: {}\n```\n\n##### 8.3.3 Pod 생성 및 확인\n\n- Pod 생성\n\n```{bash}\n$ kubectl create -f ./config-fortune-mapenv-pod.yaml\n```\n\n- Pod 생성 확인\n\n```{bash}\n$ kubectl get po, cm\n\n$ kubectl describe cm\n\nName: fortune-config\nNamespace: default\nLabels: <none>\nAnnotations: <none>\n\nData\n====\nsleep-interval:\n----\n7\nEvents: <none>\n```\n\n- configMap 삭제\n\n```{bash}\n$ kubectl delete configmap fortune-config\n```\n\n#### 8.4 ConfigMap Volume 사용 (파일숨김-vm에서 수행)\n\n##### 8.4.1 ConfigMap 생성\n\n```{bash}\nmkdir config-dir\ncd config-dir\nvi custom-nginx-config.conf\n```\n\n파일명 : custom-nginx-config.conf\n\n```{conf}\nserver {\n\tlisten\t\t\t\t8080;\n\tserver_name\t\twww.acron.com;\n\n\tgzip on;\n\tgzip_types text/plain application/xml;\n\tlocation / {\n\t\troot\t/usr/share/nginx/html;\n\t\tindex\tindex.html index.htm;\n\t}\n}\n```\n\n```{bash}\n$ kubectl create configmap fortune-config --from-file=config-dir\n```\n\n##### 8.4.2 configMap volume 이용 Pod 생성\n\n- Yaml 파일 작성 : config-fortune-mapvol-pod.yaml\n\n```{yaml}\napiVersion: v1\nkind: Pod\nmetadata:\n name: nginx-configvol\nspec:\n containers:\n - image: nginx:1.7.9\n name: web-server\n volumeMounts:\n - name: ls\n mountPath: /etc/nginx/conf.d\n readOnly: true\n ports:\n - containerPort: 8080\n protocol: TCP\n volumes:\n - name: config\n configMap:\n name: fortune-config\n```\n\n> 서버에 접속해서 디렉토리 구조를 한번 보는것이 좋습니다.\n>\n> kubectl exec -it nginx-pod bash\n\n```{bash}\n$ kubectl apply -f ./config-fortune-mapvol-pod.yaml\n```\n\n##### 8.4.3 ConfigMap Volume 참조 확인\n\n```{bash}\n$ kubectl get pod -o wide\n\nAME READY STATUS RESTARTS AGE IP NODE\nnginx-configvol 1/1 Running 0 9m25s 10.32.0.2 worker01.acorn.com\n```\n\n- Response 에 압축(gzip)을 사용 하는지 확인\n\n```{bash}\n$ curl -H \"Accept-Encoding: gzip\" -I 10.32.0.2:8080\n```\n\n- 마운트된 configMap 볼륨 내용확인\n\n```{bash}\n$ kubectl exec nginx-configvol -c web-server ls /etc/nginx/conf.d\n\nnginx-config.conf\nsleep-interval\n\n$ kubectl exec -it nginx-configvol sh\n```\n\n##### 8.4.4 ConfigMap 동적 변경\n\n- 사전 테스트\n\n```{bash}\n$ curl -H \"Accept-Encoding: gzip\" -I 10.32.0.2:8080\n\nHTTP/1.1 200 OK\nServer: nginx/1.17.9\nDate: Fri, 17 Apr 2020 06:10:32 GMT\nContent-Type: text/html\nLast-Modified: Tue, 03 Mar 2020 14:32:47 GMT\nConnection: keep-alive\nETag: W/\"5e5e6a8f-264\"\nContent-Encoding: gzip\n```\n\n- configMap 변경\n\n```{bash}\n$ kubectl edit cm fortune-config\n\n\n```\n\n**gzip on** 부분을 **gzip off ** 로 변경 합니다.\n\n```{bash}\napiVersion: v1\ndata:\n nginx-config.conf: \"server {\\n listen\\t80;\\n server_name\\tnginx.acorn.com;\\n\\n\n \\ gzip off;\\n gzip_types text/plain application/xml;\\n location / {\\n root\\t/usr/share/nginx/html;\\n\n \\ index\\tindex.html index.htm;\\n } \\n}\\n\\n\\n\"\n nginx-ssl-config.conf: '##Nginx SSL Config'\n sleep-interval: |\n 25\nkind: ConfigMap\nmetadata:\n creationTimestamp: \"2020-04-16T15:58:42Z\"\n name: fortune-config\n namespace: default\n resourceVersion: \"1115758\"\n selfLink: /api/v1/namespaces/default/configmaps/fortune-config\n uid: 182302d8-f30f-4045-9615-36e24b185ecb\n```\n\n- 변경후 테스트\n\n```{bash}\n$ curl -H \"Accept-Encoding: gzip\" -I 10.32.0.2:8080\n\nHTTP/1.1 200 OK\nServer: nginx/1.17.9\nDate: Fri, 17 Apr 2020 06:10:32 GMT\nContent-Type: text/html\nLast-Modified: Tue, 03 Mar 2020 14:32:47 GMT\nConnection: keep-alive\nETag: W/\"5e5e6a8f-264\"\nContent-Encoding: gzip\n```\n\n- reload 로 변경 사항 컨테이너에 알리기\n\n```{bash}\n$ kubectl exec nginx-configvol -c web-server -- nginx -s reload\n```\n\n- 최종 테스트\n\n```{bash}\n$ curl -H \"Accept-Encoding: gzip\" -I 10.32.0.2:8080\n\nHTTP/1.1 200 OK\nServer: nginx/1.17.9\nDate: Fri, 17 Apr 2020 06:10:32 GMT\nContent-Type: text/html\nLast-Modified: Tue, 03 Mar 2020 14:32:47 GMT\nConnection: keep-alive\nETag: W/\"5e5e6a8f-264\"\n```\n\n#### 8.5 ConfigMap Volume(파일 추가)\n\n##### 8.5.1 configMap volume 이용 Pod 생성\n\n- Yaml 파일 작성 : config-fortune-mapvol-pod2.yaml\n\n```{yaml}\napiVersion: v1\nkind: Pod\nmetadata:\n name: nginx-configvol\nspec:\n containers:\n - image: nginx:1.7.9\n name: web-server\n volumeMounts:\n - name: config\n mountPath: /etc/nginx/conf.d/default.conf\n subPath: nginx-config.conf # 주의 : configmap 의 key 와 파일명이 일치 해야합니다.\n readOnly: true\n ports:\n - containerPort: 8080\n protocol: TCP\n volumes:\n - name: config\n configMap:\n name: fortune-config\n defaultMode: 0660\n```\n\n> nginx 1.7.9 이상 버전, 예를 들면 nginx:latest 로 하면 /etc/nginx/conf.d 폴더내에 default.conf 파일만 존재 합니다. Example_cat tssl.conf 파일은 없습니다. 테스트를 위해서 nginx:1.7.9 버전으로 설정 한것입니다.\n\n```{bash}\n$ kubectl apply -f ./config-fortune-mapvol-pod.yaml\n```\n\n##### 8.5.2 서비스 및 ConfiMap 확인\n\n- 서비스 확인\n\n```{bash}\n$ curl -H \"Accept-Encoding: gzip\" -I 10.32.0.2:8080\n```\n\n- configMap 확인\n\n```{bash}\n$ kubectl exec nginx-configvol -c web-server ls /etc/nginx/conf.d\n```\n\n##### 8.5.3 ConfigMap 추가\n\n- configMap 추가\n\n```{bash}\n$ kubectl edit cm fortune-config\n```\n\n아래와 같이 nginx-ssl-config.conf 키값을 추가합니다.\n\n```{bash}\napiVersion: v1\ndata:\n nginx-config.conf: \"server {\\n listen\\t80;\\n server_name\\tnginx.acorn.com;\\n\\n\n \\ gzip on;\\n gzip_types text/plain application/xml;\\n location / {\\n root\\t/usr/share/nginx/html;\\n\n \\ index\\tindex.html index.htm;\\n } \\n}\\n\\n\\n\"\n nginx-ssl-config.conf: \"\"##Nginx SSL Config\" # 이부분이 추가됨\n sleep-interval: |\n 25\nkind: ConfigMap\nmetadata:\n creationTimestamp: \"2020-04-16T15:58:42Z\"\n name: fortune-config\n namespace: default\n resourceVersion: \"1098337\"\n selfLink: /api/v1/namespaces/default/configmaps/fortune-config\n uid: 182302d8-f30f-4045-9615-36e24b185ecb\n```\n\n##### 8.5.4 ConfigMap 추가된 Pod 생성\n\n- 설정 파일 추가 하기위해 yaml 파일 수정\n\n파일명 : config-fortune-mapvol-pod3.yaml\n\n```{yaml}\nkind: Pod\nmetadata:\n name: nginx-configvol\nspec:\n containers:\n - image: nginx:1.7.9\n name: web-server\n volumeMounts:\n - name: config #default.conf 파일 교체\n mountPath: /etc/nginx/conf.d/default.conf\n subPath: nginx-config.conf\n readOnly: true\n - name: config #example_ssl.conf 파일 교체\n mountPath: /etc/nginx/conf.d/example_ssl.conf\n subPath: nginx-ssl-config.conf\n readOnly: true\n ports:\n - containerPort: 8080\n protocol: TCP\n volumes:\n - name: config\n configMap:\n name: fortune-config\n defaultMode: 0660\n```\n\n```{bash}\n$ kubectl apply -f ./ config-fortune-mapvol-pod3.yaml\n```\n\n##### 8.5.6 추가된 ConfigMap 확인\n\n- 서비스 확인\n\n```{bash}\n$ curl http://10.32.0.4\n```\n\n- configMap 확인\n\n```{bash}\n$ kubectl exec -it nginx-configvol bash\n\n$ cd /etc/nginx/conf.d\n$ ls -al\n\n```\n\n## 9. Secret\n\n```{bash}\nmkdir -p ./secret/cert\nmkdir -p ./secret/config\nmkdir -p ./secret/kubetmp\n```\n\n### 9.1 Secret 생성 (fortune-https)\n\n```{bash}\ncd ./secret/cert\n```\n\n```{bash}\nopenssl genrsa -out https.key 2048\nopenssl req -new -x509 -key https.key -out https.cert -days 360 -subj /CN=*.acron.com\n```\n\n```{bash}\nkubectl create secret generic fortune-https --from-file=https.key --from-file=https.cert\n```\n\n### 9.2 SSL 용 niginx 설정 생성(fortune-config)\n\n```{bash}\ncd ./secret/config\nvi custom-nginx-config.conf\n```\n\n```{bash}\nserver {\n\tlisten\t\t\t\t8080;\n listen\t\t\t\t443 ssl;\n\tserver_name\t\twww.acron.com;\n\tssl_certificate\t\tcerts/https.cert;\n\tssl_certificate_key\tcerts/https.key;\n\tssl_protocols\t\tTLSv1 TLSv1.1 TLSv1.2;\n\tssl_ciphers\t\tHIGH:!aNULL:!MD5;\n\tgzip on;\n\tgzip_types text/plain application/xml;\n\tlocation / {\n\t\troot\t/usr/share/nginx/html;\n\t\tindex\tindex.html index.htm;\n\t}\n}\n```\n\n```{bash}\nvi sleep-interval\n7\n```\n\n```{bash}\nkubectl create cm fortune-config --from-file=./config\n```\n\n### 9.3 POD 생성\n\n- Pod 생성 : 8.3.2 의 yaml 파일 참조\n- 파일명 : secret-pod.yaml\n\n```{yaml}\napiVersion: v1\nkind: Pod\nmetadata:\n name: fortune-https\nspec:\n containers:\n - image: dangtong/fortune:env\n env:\n - name: INTERVAL\n valueFrom:\n configMapKeyRef:\n name: fortune-config\n key: sleep-interval\n name: html-generator\n volumeMounts:\n - name: html\n mountPath: /var/htdocs\n - image: nginx:alpine\n name: web-server\n volumeMounts:\n - name: html\n mountPath: /usr/share/nginx/html\n readOnly: true\n - name: config # 추가\n mountPath: /etc/nginx/conf.d\n readOnly: true\n - name: certs # 추가\n mountPath: /etc/nginx/certs/\n readOnly: true\n ports:\n - containerPort: 80\n - containerPort: 443 # 추가\n volumes:\n - name: html\n emptyDir: {}\n - name: config # 추가\n configMap:\n name: fortune-config\n items:\n - key: custom-nginx-config.conf\n path: https.conf\n - name: certs #추가\n secret:\n secretName: fortune-https\n```\n\n```{bash}\nkubectl apply -f ./secret-pod.yaml\n```\n\n### 9.4 서비스 확인\n\n```{bash}\nkubectl port-forward fortune-https 8443:443 &\n```\n\n```{bash}\ncurl https://localhsot:8443 -k\ncurl https://localhost:8443 -k -v\n```\n\n### [[Exercise #7]]\n\n#### 1. Mysql 구성하기\n\n##### 1.1 서비스 구성\n\n파일명 : mysql-svc.yaml\n\n```{yaml}\napiVersion: v1\nkind: Service\nmetadata:\n name: wordpress-mysql\n labels:\n app: wordpress\nspec:\n ports:\n - port: 3306\n selector:\n app: wordpress\n tier: mysql\n clusterIP: None\n```\n\n##### 1.2 볼륨 구성\n\n파일명 : mysql-pvc.yaml\n\n```{yaml}\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n name: mysql-pv-claim\n labels:\n app: wordpress\nspec:\n accessModes:\n - ReadWriteOnce\n resources:\n requests:\n storage: 20Gi\n```\n\n##### 1.3 Pod 구성\n\n파일명 : mysql-deploy.yaml\n\n```{yaml}\napiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2\nkind: Deployment\nmetadata:\n name: wordpress-mysql\n labels:\n app: wordpress\nspec:\n selector:\n matchLabels:\n app: wordpress\n tier: mysql\n strategy:\n type: Recreate\n template:\n metadata:\n labels:\n app: wordpress\n tier: mysql\n spec:\n containers:\n - image: mysql:5.6\n name: mysql\n env:\n - name: MYSQL_ROOT_PASSWORD\n valueFrom:\n secretKeyRef:\n name: mysql-pass\n key: password\n ports:\n - containerPort: 3306\n name: mysql\n volumeMounts:\n - name: mysql-persistent-storage\n mountPath: /var/lib/mysql\n volumes:\n - name: mysql-persistent-storage\n persistentVolumeClaim:\n claimName: mysql-pv-claim\n```\n\n```{bash}\nkubectl apply -f\n```\n\n#### 2. WordPress 서비스 구성\n\n##### 2.1 LoadBalancer 구성\n\n```{yaml}\napiVersion: v1\nkind: Service\nmetadata:\n name: wordpress\n labels:\n app: wordpress\nspec:\n ports:\n - port: 80\n selector:\n app: wordpress\n tier: frontend\n type: LoadBalancer\n```\n\n##### 2.2 PVC 구성\n\n```{yaml}\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n name: wp-pv-claim\n labels:\n app: wordpress\nspec:\n accessModes:\n - ReadWriteOnce\n resources:\n requests:\n storage: 20Gi\n```\n\n##### 2.3 WordPress 구성\n\n```{yaml}\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n name: wordpress\n labels:\n app: wordpress\nspec:\n selector:\n matchLabels:\n app: wordpress\n tier: frontend\n strategy:\n type: Recreate\n template:\n metadata:\n labels:\n app: wordpress\n tier: frontend\n spec:\n containers:\n - image: wordpress:4.8-apache\n name: wordpress\n env:\n - name: WORDPRESS_DB_HOST\n value: wordpress-mysql\n - name: WORDPRESS_DB_PASSWORD\n valueFrom:\n secretKeyRef:\n name: mysql-pass\n key: password\n ports:\n - containerPort: 80\n name: wordpress\n volumeMounts:\n - name: wordpress-persistent-storage\n mountPath: /var/www/html\n volumes:\n - name: wordpress-persistent-storage\n persistentVolumeClaim:\n claimName: wp-pv-claim\n```\n\n## 10. StatefullSet (GCP 수행)\n\n### 10.1 애플리케이션 이미지 작성\n\n#### 10.1.1 app.js 작성\n\n```{javascript}\nconst http = require('http');\nconst os = require('os');\nconst fs = require('fs');\n\nconst dataFile = \"/var/data/kubia.txt\";\nconst port = 8080;\n\n// 파일 존재 유/무 검사\nfunction fileExists(file) {\n try {\n fs.statSync(file);\n return true;\n } catch (e) {\n return false;\n }\n}\n\nvar handler = function(request, response) {\n// POST 요청일 경우 BODY에 있는 내용을 파일에 기록 함\n if (request.method == 'POST') {\n var file = fs.createWriteStream(dataFile);\n file.on('open', function (fd) {\n request.pipe(file);\n console.log(\"New data has been received and stored.\");\n response.writeHead(200);\n response.end(\"Data stored on pod \" + os.hostname() + \"\\n\");\n });\n// GET 요청일 경우 호스트명과 파일에 기록된 내용을 반환 함\n } else {\n var data = fileExists(dataFile) ? fs.readFileSync(dataFile, 'utf8') : \"No data posted yet\";\n response.writeHead(200);\n response.write(\"You've hit \" + os.hostname() + \"\\n\");\n response.end(\"Data stored on this pod: \" + data + \"\\n\");\n }\n};\n\nvar www = http.createServer(handler);\nwww.listen(port);\n```\n\n#### 10.1.2 Docker 이미지 만들기\n\n- Dockerfile 작성\n\n```{dockerfile}\nFROM node:7\nADD app.js /app.js\nENTRYPOINT [\"node\", \"app.js\"]\n```\n\n- Docker 이미지 build 및 push\n\n```{bash}\n$ docker build dangtong/nodejs:sfs .\n$ docker login\n$ docker push dangtong/nodejs:sfs\n```\n\n### 10.2 PVC 생성\n\n```{yaml}\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n name: sc-standard-retain\nprovisioner: kubernetes.io/gce-pd\nreclaimPolicy: Retain\nparameters:\n type: pd-ssd\n zone: asia-northeast1-c\n```\n\n### 10.3 서비스 및 Pod 생성\n\n#### 10.3.1 로드밸런서 서비스 생성\n\n```{yaml}\napiVersion: v1\nkind: Service\nmetadata:\n name: nodesjs-sfs-lb\nspec:\n type: LoadBalancer\n ports:\n - port: 80\n targetPort: 8080\n selector:\n app: nodejs-sfs\n```\n\n#### 10.3.2 Pod 생성\n\n```{yaml}\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n name: nodejs-sfs\nspec:\n selector:\n matchLabels:\n app: nodejs-sfs\n serviceName: nodejs-sfs\n replicas: 2\n template:\n metadata:\n labels:\n app: nodejs-sfs\n spec:\n containers:\n - name: nodejs-sfs\n image: dangtong/nodejs:sfs\n ports:\n - name: http\n containerPort: 8080\n volumeMounts:\n - name: data\n mountPath: /var/data\n volumeClaimTemplates:\n - metadata:\n name: data\n spec:\n resources:\n requests:\n storage: 1Mi\n accessModes:\n - ReadWriteOnce\n storageClassName: sc-standard-retain\n```\n\n```{bash}\nkubectl apply -f nodejs-sfs.yaml\n```\n\n```{bash}\nkubectl get svc\n\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\nservice/kubernetes ClusterIP 10.65.0.1 <none> 443/TCP 7h43m\nservice/nodesjs-sfs-lb LoadBalancer 10.65.12.243 34.85.38.158 80:32280/TCP 120m\n\n```\n\n### 10.4 서비스 테스트\n\n- 데이터 조회\n\n```{bash}\ncurl http://34.85.38.158\n```\n\n- 데이터 입력\n\n```{bash}\ncurl -X POST -d \"hi, my name is dangtong-1\" 34.85.38.158\ncurl -X POST -d \"hi, my name is dangtong-2\" 34.85.38.158\ncurl -X POST -d \"hi, my name is dangtong-3\" 34.85.38.158\ncurl -X POST -d \"hi, my name is dangtong-4\" 34.85.38.158\n```\n\n> 데이터 입력을 반복하에 두개 노드 모드에 데이터를 모두 저장 합니다. 양쪽 노드에 어떤 데이터가 입력 되었는지 기억 하고 다음 단계로 넘어 갑니다.\n\n### 10.5 노드 삭제 및 데이터 보존 확인\n\n- 노드 삭제 및 자동 재생성\n\n```{bash}\nkubectl delete pod nodejs-sfs-0\n```\n\n노드를 삭제 한뒤 노드가 재생성 될때 까지 기다립니다.\n\n- 데이터 보존 확인\n\n```{bash}\ncurl http://34.85.38.158\n```\n\n> 노드가 삭제 되었다 재생성 되도 기존 디스크를 그대로 유지하는 것을 볼 수 있습니다. ReclaimPolicy 를 Retain 으로 했기 때문 입니다.\n\n## 11. 리소스 제어\n\n### 11.1 부하 발생용 애플리 케이션 작성\n\n#### 11.1.1 PHP 애플리 케이션 작성\n\n파일명 : index.php\n\n```{php}\n<?php\n $x = 0.0001;\n for ($i = 0; $i <= 1000000; $i++) {\n $x += sqrt($x);\n }\n echo \"OK!\";\n?>\n```\n\n#### 11.1.2 도커 이미지 빌드\n\n```{dockerfile}\nFROM php:5-apache\nADD index.php /var/www/html/index.php\nRUN chmod a+rx index.php\n```\n\n```{bash}\ndocker build -t dangtong/php-apache .\ndocker login\ndocker push dangtong/php-apache\n```\n\n### 11.2 포드 및 서비스 만들기\n\n#### 12.2.1 Deployment 로 Pod 새성\n\n파일명 : php-apache-deploy.yaml\n\n```{yaml}\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n name: php-apache-dp\nspec:\n selector:\n matchLabels:\n app: php-apache\n replicas: 1\n template:\n metadata:\n labels:\n app: php-apache\n spec:\n containers:\n - name: php-apache\n image: dangtong/php-apache\n ports:\n - containerPort: 80\n resources:\n limits:\n cpu: 500m\n requests:\n cpu: 200m\n```\n\n#### 12.2.2 로드밸런서 서비스 작성\n\n파일명 : php-apache-svc.yaml\n\n```{yaml}\napiVersion: v1\nkind: Service\nmetadata:\n name: php-apache-lb\nspec:\n type: LoadBalancer\n ports:\n - port: 80\n targetPort: 80\n selector:\n app: php-apache\n```\n\n```{bash}\nkubectl apply -f ./php-apache-deploy.yaml\nkubectl apply -f ./php-apache-svc.yaml\n```\n\n### [[연습 문제]]\n\n아래 요구 사항에 맞는 deploy 를 구현 하세요\n\n1. Deploy name : nginx\n2. image : nginx\n3. cpu 200m\n4. 메모리 : 300Mi\n5. Port : 80\n\n### 12.3 HPA 리소스 생성\n\n#### 12.3.1 HPA 리소스 생성\n\n```{bash}\nkubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=5\n```\n\n#### 12.3.2 HPA 리소스 생성 확인\n\n```{bash}\nkubectl get hpa\n```\n\n### 12.4 Jmeter 설치 및 구성\n\n#### 12.4.1 Jmeter 설치를 위00000해 필요한 것들\n\n- JDK 1.8 이상 설치 [오라클 java SE jdk 다운로드](https://www.oracle.com/java/technologies/javase-downloads.html)\n- Jmeter 다운로드 [Jmeter 다운로드](https://jmeter.apache.org/download_jmeter.cgi)\n- Jmeter 플러그인 다운로드 [Jmeter-plugin 다운로드](https://jmeter-plugins.org/install/Install/)\n - Plugins-manager.jar 다운로드 하여 jmeter 내에 lib/ext 밑에 복사 합니다.\n\n#### 12.4.2 Jmeter 를 통한 부하 발생\n\n![jmeter](../img/jmeter.png)\n\n#### 12.4.3 부하 발생후 Pod 모니터링\n\n```{bash}\n$ kubectl get hpa\n\n$ kubectl top pods\n\nNAME CPU(cores) MEMORY(bytes)\nnodejs-sfs-0 0m 7Mi\nnodejs-sfs-1 0m 7Mi\nphp-apache-6997577bfc-27r95 1m 9Mi\n\n\n$ kubectl exec -it nodejs-sfs-0 top\n\nTasks: 2 total, 1 running, 1 sleeping, 0 stopped, 0 zombie\n%Cpu(s): 4.0 us, 1.0 sy, 0.0 ni, 95.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st\nKiB Mem: 3786676 total, 3217936 used, 568740 free, 109732 buffers\nKiB Swap: 0 total, 0 used, 0 free. 2264392 cached Mem\n PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND\n 1 root 20 0 813604 25872 19256 S 0.0 0.7 0:00.17 node\n 11 root 20 0 21924 2408 2084 R 0.0 0.1 0:00.00 top\n```\n\n### [[Exercise]]\n\n이미지를 nginx 를 생성하고 HPA 를 적용하세요\n\n- Max : 8\n- Min : 2\n- CPU 사용량이 40% 가 되면 스케일링 되게 하세요\n\n## 13. Kubernetes DashBoard 설치\n\n### 13.1 Dashboard 설치\n\n참조 URL : https://kubernetes.io/ko/docs/tasks/access-application-cluster/web-ui-dashboard/\n\n```{bash}\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0/aio/deploy/recommended.yaml\n```\n\n### 13.2 DashBoard 인증서 생성\n\n```{bash}\nmkdir -p ./kubeSrc/dashboard/certs\nmkdir -p ./kubeSrc/dashboard/yaml\n\ncd ./kubeSrc/dashboard/certs\n```\n\n#### 13.2.1 개인키 생성\n\n```{bash}\nopenssl genrsa -des3 -out dashboard-private.key 2048\n\nGenerating RSA private key, 2048 bit long modulus (2 primes)\n.....................................................................................+++++\n...........................................+++++\ne is 65537 (0x010001)\nEnter pass phrase for dashboard-private.key:\nVerifying - Enter pass phrase for dashboard-private.key:\n\n\n\n# openssl rsa --noout -text -in dashboard-private.key\n```\n\n#### 13.2.1 공개키 생성\n\n```{bash}\nopenssl rsa -in dashboard-private.key -out dashboard-public.key\n```\n\n#### 13.2.2 CSR 생성\n\n```{bash}\nopenssl req -new -key dashboard-public.key -out dashboard.csr\n\nYou are about to be asked to enter information that will be incorporated\ninto your certificate request.\nWhat you are about to enter is what is called a Distinguished Name or a DN.\nThere are quite a few fields but you can leave some blank\nFor some fields there will be a default value,\nIf you enter '.', the field will be left blank.\n-----\nCountry Name (2 letter code) [AU]:KR\nState or Province Name (full name) [Some-State]:Seoul\nLocality Name (eg, city) []:Guro-Gu\nOrganization Name (eg, company) [Internet Widgits Pty Ltd]:acorn\nOrganizational Unit Name (eg, section) []:edu\nCommon Name (e.g. server FQDN or YOUR name) []:*.acorn.com\nEmail Address []:dangtong@gmail.com\n\nPlease enter the following 'extra' attributes\nto be sent with your certificate request\nA challenge password []:admin123\nAn optional company name []:acorn\n```\n\n#### 13.2.3 인증서 생성\n\n```{bash}\nopenssl x509 -req -sha256 -days 3650 -in dashboard.csr -signkey dashboard-public.key -out kubernetes-dashboard.crt\n```\n\n### 13.3 DashBoard 생성\n\n#### 13.3.1 네임스페이스 및 Secret 생성\n\n- 네임스페이스 생성\n\n```{bash}\nkubectl create namespace kubernetes-dashboard\n```\n\n- Secret 생성\n\n```{bash}\nkubectl create secret generic kubernetes-dashboard-certs --from-file=$HOME/kubeSrc/dashboard/certs -n kubernetes-dashboard\n```\n\n- Secret 확인\n\n```{bahs}\nkubectl get secret -n kubernetes-dashboard-certs -n kubernetes-dashboard\n```\n\n#### 13.3.2 DashBoard Deployment\n\n```{bash}\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0/aio/deploy/recommended.yaml\n```\n\n#### 13.3.3 ClusterIP 를 NodePort 방식으로 변경\n\n```{bash}\nkubectl edit service kubernetes-dashboard -n kubernetes-dashboard\n```\n\n```{yaml}\n...\nports:\n - nodePort: 30812 # 이부분 추가\n port: 443\n protocol: TCP\n targetPort: 8443\n selector:\n k8s-app: kubernetes-dashboard\n sessionAffinity: None\n type: NodePort # 이부분 변경\n\n```\n\n#### 13.3.4 서비스 확인\n\n```{bash}\nkubectl get service -n kubernetes-dashboard\n```\n\n#### 13.2.\n\n#### 13.2 NodePort 서비스\n\n```{yaml}\nspec:\n clusterIP: 10.103.46.146\n ports:\n - port: 443\n protocol: TCP\n targetPort: 8443\n nodePort: 30124\n selector:\n k8s-app: kubernetes-dashboard\n sessionAffinity: None\n type: NodePort\nstatus:\n loadBalancer: {}\n```\n\n### 13.2 Client 인증서 만들기\n\n- kubectl 의 key 복사\n\n```{bash}\ngrep 'client-key-data' ~/.kube/config | head -n 1 | awk '{print $2}' | base64 -d >> kubecfg.key\n```\n\n- 인증서 생성\n\n```{bash}\n\n# CSR 생성\nopenssl req -new -key kubecfg.key -out kubecfg.csr -subj \"/CN=admin-user\"\n\n# 인증서 생성\nsudo openssl x509 -req -in kubecfg.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out kubecfg.crt -days 500\n```\n\n- 브라우저에서 사용 가능한 PKCS#12 양식으로 변환 합니다\n\n```{bash}\nopenssl pkcs12 -export -clcerts -inkey kubecfg.key -in kubecfg.crt -out kubecfg.p12 -name \"admin-user\"\n```\n\n- CA 인증서를 복사합니다.\n\n```{bash}\ncp /etc/kubernetes/pki/ca.crt .\n```\n\n```{bash}\nkubeadmin@kmaster:~/kubeSrc/dashboard$ ls\nca.crt kubecfg.crt kubecfg.csr kubecfg.key kubecfg.p12\n```\n\n- Sftp 로 서버에 접속해서 kubecfg.crt / kubecfg.p12 / ca.crt 파일을 다운로드 받습니다.\n\n### 13.3 인증서\n\n#### 13.3.1 윈도우 인증서 Import\n\n- 윈도우 Root CA 인증서 Import\n\n```{cmd}\nC:\\Windows\\system32>certutil.exe -addstore \"Root\" C:\\Users\\dangtong\\Documents\\ca.crt\nRoot \"신뢰할 수 있는 루트 인증 기관\"\n서명이 공개 키와 일치합니다.\n\"kubernetes\" 인증서가 저장소에 추가되었습니다.\nCertUtil: -addstore 명령이 성공적으로 완료되었습니다.\n```\n\n- PKCS#12 인증서 Imort\n\n```{cmd}\nC:\\Windows\\system32>certutil.exe -p admin123 -user -importPFX\n```\n\n![cert_capture](../img/cert_capture.PNG)\n\n```{cmd}\n\nC:\\Users\\dangtong\\Documents\\kubecfg.p12\n\"kubernetes-admin\" 인증서가 저장소에 추가되었습니다.\n\nCertUtil: -importPFX 명령이 성공적으로 완료되었습니다.\n```\n\n#### 13.3.2 OSX 인증서 Import\n\n- Root CA 인증서 Import\n\n```{bash}\nsecurity add-trusted-cert -r trustRoot -k \"$HOME/Library/Keychains/login.keychain\" /Users/dangtong/kube-dashboard/ca.crt\n```\n\n- PKCS#12 인증서 Import\n\n```{bash}\nsecurity import /Users/dangtong/kube-dashboard/kubecfg.p12 -k \"$HOME/Library/Keychains/login.keychain\" -P admin123\n```\n\n### 13.4 서비스 어카운트 및 롤생성\n\n#### 13.4.1 서비스 어카운트 생성\n\n파일명 : admin-user.yaml\n\n```{yaml}\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n name: admin-user\n namespace: kubernetes-dashboard\n```\n\n#### 13.4.2 롤생성\n\n파일명 : admin-user-role.yaml\n\n```{yaml}\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n name: admin-user-role-binding\nroleRef:\n apiGroup: rbac.authorization.k8s.io\n kind: ClusterRole\n name: cluster-admin\nsubjects:\n- kind: ServiceAccount\n name: admin-user\n namespace: kubernetes-dashboard\n```\n\n```{bash}\nkubectl apply -f ./admin-user.yaml\nkubectl apply -f ./admin-user-role.yaml\n```\n\n#### 13.4.3 인증 토큰 조회\n\n아래 명령을 수행해서 인증 토큰을 복사 합니다.\n\n```{bash}\nkubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk '{print $1}')\n\nName: admin-user-token-28l6n\nNamespace: kubernetes-dashboard\nLabels: <none>\nAnnotations: kubernetes.io/service-account.name: admin-user\n kubernetes.io/service-account.uid: d3f6b3d6-63f3-4483-88f0-dc8e6f37ffd8\n\nType: kubernetes.io/service-account-token\n\nData\n====\nca.crt: 1025 bytes\nnamespace: 20 bytes\ntoken: eyJhbGciOiJSUzI1NiIsImtpZCI6InEwaS1COEtFcjNwd0RBbE1KUHpaNTZuZlBlSmY4a1Nld1FZYjhIam5ZV2cifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLTI4bDZuIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJkM2Y2YjNkNi02M2YzLTQ0ODMtODhmMC1kYzhlNmYzN2ZmZDgiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6YWRtaW4tdXNlciJ9.JB1hGeIxJyU-0VbOmMGcp0b6B758nqGAXhgBFOj9eZMj73h7BNizO4aEiDMsJgH3tvtXRxChUHIMFT0kBeX6i7U-3GYvS_Uw7XNREYdhrYl8PVoPcqcXi7tL1tTrCEj-Rxy7HxyHXGGwb6wJYO11BgzuwCLJWjm-i-G3N3yrzi8KQ7MjWKVPisrxgPna_dKO6LgrCiq6oVO14FFVbwB6IqdiH8jpHrH2GSIKjFCAAziHSoHBLbc6qv5_9hle5CaO6LZxTlZCt4H7drWnUUyVmjz1sqkUZg08EVfewVzZCQXPig6Rj3DTGbFrzg1Zk3h3EBJq4VhjnCYj1ePNDw_-eg\n```\n\n### 13.5 DashBoard 접속\n\n- 접속 URL\n\nhttps://192.168.56.111:6443/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/\n\n![dashboard_login](../img/dashboard_login.png)\n\n<kbd>토큰</kbd> 을 선택하고 복사한 토큰을 **토큰입력** 란에 붙여넣고 **로그인** 합니다.\n\n### 13.6 삭제\n\n```{bash}\nkubectl --namespace kube-system delete deployment,service kubernetes-dashboard\n```\n\n## 14. 계정 및 인증\n\n### 14.1 User Account 및 RBAC 사용\n\n#### 14.1.1 유저 생성\n\n```{bash}\n# root 로 수행\nadduser devuser\nsu - devuser\n\n# devuser 로 수행\nmkdir .cert\nmkdir .kube\n```\n\n#### 14.1.2 유저 인증서 생성(root 로 수행)\n\n- 인증서 생성\n\n```{bash}\ncd ~\nmkdir devuser-cert\ncd devuser-cert\n\n# 키생성\nopenssl genrsa -out devuser.key 2048\n\n# CSR 생성\nopenssl req -new -key devuser.key -out devuser.csr -subj \"/CN=devuser/O=devuser\"\n\n# 인증서 생성\nopenssl x509 -req -in devuser.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out devuser.crt -days 500\n```\n\n- 인증서 복사\n\n```{bash}\ncp devuser.crt /home/devuser/.cert/\ncp devuser.key /home/devuser/.cert/\nchown -R devuser:devuser /home/devuser/.cert\n```\n\n#### 14.1.3 kubectl 로 config 파일 만들기(devuser 로 수행)\n\n- API 서버 접속 및 CA 인증서 설정\n\n```{bash}\ncd ~/.kube\n\nkubectl config --kubeconfig=config set-cluster devuser-cluster --server=https://192.168.56.111:6443 --certificate-authority=/etc/kubernetes/pki/ca.crt\n```\n\n```{bash}\ncat ~/.kube/config\n```\n\n- 사용자 접속 정보 (인증서 정보 설정)\n\n```{bash}\nkubectl config --kubeconfig=config set-credentials devuser --client-certificate=/home/devuser/.cert/devuser.crt --client-key=/home/devuser/.cert/devuser.key\n```\n\n- 컨텍스트 설정\n\n```{bash}\nkubectl config --kubeconfig=config set-context devuser-context --cluster=devuser-cluster --namespace=dev --user=devuser\n```\n\n```{bash}\ncat ~/.kube/config\n```\n\n- 테스트\n\n```{bash}\nkubectl get pod\n\nThe connection to the server localhost:8080 was refused - did you specify the right host or port?\n\nkubectl --context=devuser-context get po\n\nError from server (Forbidden): pods is forbidden: User \"devuser\" cannot list resource \"pods\" in API group \"\" in the namespace \"dev\"\n```\n\n> 메시지가 왜 다른지 생각 해봅시다. config 를 열어서 current-context: \"devuser-context\" 로 수정한 후 다시 수행 합니다.\n\n#### 14.1.4 네임스페이스 생성 (root 로 수행)\n\n```{bash}\nkubectl create namespace dev\n```\n\n#### 14.1.5 롤생성 (root 로 수행)\n\n파일명 : dev-role.yaml\n\n```{yaml}\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n namespace: dev\n name: dev-role\nrules:\n- apiGroups: [\"\", \"extensions\", \"apps\"]\n resources: [\"deployments\", \"replicasets\", \"pods\"]\n verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n```\n\n```{bash}\nkubectl apply -f ./dev-role.yaml\n```\n\n| Verb | 설명 |\n| ----------------- | ------------------------- |\n| create | 리소스 생성 |\n| get | 리소스 조회 |\n| list | 여러건 리소스 동시 조회 |\n| update | 리소스 전체 내용 업데이트 |\n| patch | 리소스 일부 내용 변경 |\n| delete | 단일 리소스 삭제 |\n| Delete collection | 여러 리소스 삭제 |\n\n> resource 뿐만 아니라 resourceNames 를 지정해서 특정 Pod 나 리소스에 대한 권한 으로 제한 할 수도 있음\n\n#### 14.1.6 롤바인딩 생성 (root 로 수행)\n\n파일명 : dev-role-bind.yaml\n\n```{yaml}\nkind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n name: dev-role-binding\n namespace: dev\nsubjects:\n- kind: User\n name: devuser\n apiGroup: \"\"\nroleRef:\n kind: Role\n name: dev-role\n apiGroup: \"\"\n```\n\n```{bash}\nkubectl apply -f ./dev-role-bind.yaml\n```\n\n#### 14.1.7 테스트 Pod 생성 및 테스트 (devuser 로 수행)\n\n```{bash}\n# 사용 가능한 context 확인\nkubectl config get-contexts\n\n# context로 전환\nkubectl config use-context devuser-context\n\n# 현재 사용중인 context 확인\nkubectl config current-context\n```\n\n```{bash}\nkubectl --context=devuser-context run --generator=run-pod/v1 nginx --image=nginx --port=80 --dry-run -o yaml > nginx-pod.yaml\n```\n\n```{bash}\nkubectl apply -f ./nginx-pod.yaml\n\nkubectl get pod -o wide\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES\nnginx 1/1 Running 0 2m39s 10.40.0.8 worker01.acorn.com <none> <none>\n\n\ncurl http://10.40.0.8\n```\n\n### 14.2 Service Account 및 RBAC\n\n#### 14.2.1 Service Account 생성\n\n- Service Account 생성\n\n```{bash}\nkubectl create sa apiuser\n\n# kubectl create sa apiuser --dry-run -o yaml\n\nkubectl get sa\n\nkubectl get sa --all-namespaces\n```\n\n- 토큰 Secret 생성\n\n```{yaml}\napiVersion: v1\nkind: Secret\nmetadata:\n name: apiuser-secret\n annotations:\n kubernetes.io/service-account.name: apiuser\ntype: kubernetes.io/service-account-token\n```\n\n```{bash}\nkubectl describe secrets/apiuser-secret\n```\n\n#### 14.2.2 롤 생성\n\n- 롤 생성\n\n```{yaml}\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n name: read-role\n namespace: default\nrules:\n- apiGroups: [\"\"]\n resources: [\"pods\"]\n verbs: [\"get\", \"list\"]\n```\n\n#### 14.2.3 롤 바인딩\n\n```{bash}\nkind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n name: read-role-binding\n namespace: default\nsubjects:\n- kind: ServiceAccount\n name: apiuser\n apiGroup: \"\"\nroleRef:\n kind: Role\n name: read-role\n apiGroup: kube\n```\n\n#### 14.2.4 토큰 인코딩 및 서비스 테스트\n\n- 토큰 인코딩\n\n```{bash}\nkubectl get secret apiuser-secret -o yaml\n\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n creationTimestamp: \"2020-04-30T19:48:15Z\"\n name: apiuser\n namespace: default\n resourceVersion: \"1715742\"\n selfLink: /api/v1/namespaces/default/serviceaccounts/apiuser\n uid: 3b658e4a-ec4f-4eda-b790-ba74d0607973\nsecrets:\n- name: apiuser-token-llvcb # 토큰\n```\n\n```{bash}\nkubectl get secrets apiuser-token-llvcb -o json | jq -Mr '.data.token' | base64 -d\n```\n\n- Pod 리스트 조회\n\n```{bash}\ncurl -k https://192.168.56.111:6443/api/v1/namespaces/default/pods/ -H \"Authorization: Bearer eyJhbGciOiJSUzI1NiIsImtpZCI6InEwaS1COEtFcjNwd0RBbE1KUHpaNTZuZlBlSmY4a1Nld1FZYjhIam5ZV2cifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJkZWZhdWx0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZWNyZXQubmFtZSI6ImFwaXVzZXItdG9rZW4tbGx2Y2IiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiYXBpdXNlciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjNiNjU4ZTRhLWVjNGYtNGVkYS1iNzkwLWJhNzRkMDYwNzk3MyIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDpkZWZhdWx0OmFwaXVzZXIifQ.qVfF3Tt9fAI6uC8CfyiuSBYnYU8z8sLQIRt3sH0B3zgpcToxPY9aAuoADmg-ULUQJBJjiBgbhWxy1ujpJwKy-jLb-0-MqIype2Z58dlNCOupaWnFDzYMJr9XLL33L6KD7SSVTp22CP89KGj_TxDdOrLj6jQi07WGBBqsliCPu5xy1p6SoiOdl-FxWpHqJxfhgtpVX1ntPA_DN6H_CiFPvvKoaWAy76HzH79aMbdmtR4NDpKYoCo1vbNmnWuQ2571lL4einBKkHj8bi0zeBa1cKvuqTUHftGV4KDYQ0nsX1R7Ispk3XNuMLgx7Lxl6idDUxfDkeRElZraMo3FgMYN0w\"\n```\n\n- 특정 Pod 조회\n\n```{bash}\ncurl -k https://192.168.56.111:6443/api/v1/namespaces/default/pods/goapp-deployment-5857594fbb-46ckf -H \"Authorization: Bearer eyJhbGciOiJSUzI1NiIsImtpZCI6InEwaS1COEtFcjNwd0RBbE1KUHpaNTZuZlBlSmY4a1Nld1FZYjhIam5ZV2cifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJkZWZhdWx0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZWNyZXQubmFtZSI6ImFwaXVzZXItdG9rZW4tbGx2Y2IiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiYXBpdXNlciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjNiNjU4ZTRhLWVjNGYtNGVkYS1iNzkwLWJhNzRkMDYwNzk3MyIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDpkZWZhdWx0OmFwaXVzZXIifQ.qVfF3Tt9fAI6uC8CfyiuSBYnYU8z8sLQIRt3sH0B3zgpcToxPY9aAuoADmg-ULUQJBJjiBgbhWxy1ujpJwKy-jLb-0-MqIype2Z58dlNCOupaWnFDzYMJr9XLL33L6KD7SSVTp22CP89KGj_TxDdOrLj6jQi07WGBBqsliCPu5xy1p6SoiOdl-FxWpHqJxfhgtpVX1ntPA_DN6H_CiFPvvKoaWAy76HzH79aMbdmtR4NDpKYoCo1vbNmnWuQ2571lL4einBKkHj8bi0zeBa1cKvuqTUHftGV4KDYQ0nsX1R7Ispk3XNuMLgx7Lxl6idDUxfDkeRElZraMo3FgMYN0w\"\n```\n\n### 14.3 클러스터롤 과 집계 클러스터롤\n\n#### 14.3.1 클러스터롤 생성\n\n```{bash}\nvi read-clusterrole.yaml\n```\n\n```{yaml}\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n name: read-cluster-role\nrules:\n- apiGroups: [\"\"]\n resources: [\"pods\"]\n verbs: [\"get\", \"list\"]\n```\n\n#### 14.2.3 Aggregation 클러스터룰 생성\n\n- 생성\n\n```{bash}\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n name: agg-cluster-role\naggregationRule:\n clusterRoleSelectors:\n - matchLabels:\n kubernetes.io/bootstrapping: rbac-defaults\nrules: []\n```\n\n- 확인\n\n```{bash}\nkubectl get clusterrole cluster-admin -o yaml\n\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n annotations:\n rbac.authorization.kubernetes.io/autoupdate: \"true\"\n creationTimestamp: \"2020-04-30T06:02:28Z\"\n labels:\n kubernetes.io/bootstrapping: rbac-defaults\n name: cluster-admin\n resourceVersion: \"38\"\n selfLink: /apis/rbac.authorization.k8s.io/v1/clusterroles/cluster-admin\n```\n\n#### 14.2.3 롤바인딩\n\n- 테스트용 유저 생성\n\n```{yaml}\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n name: myuser\n namespace: default\n```\n\n- 클러스터롤 바인딩\n\n```{yaml}\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n name: read-cluster-role-binding\nsubjects:\n- kind: ServiceAccount\n name: myuser\n namespace: default\n apiGroup: \"\"\nroleRef:\n kind: ClusterRole\n name: read-cluster-role # 미리 만든 클러스터롤을 유저에 바인딩 합니다\n apiGroup: rbac.authorization.k8s.io\n```\n\n- Aggregation 클러스터 롤 바인딩\n\n```{yaml}\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n name: agg-cluster-role-binding\nsubjects:\n- kind: ServiceAccount\n name: myuser\n namespace: default\n apiGroup: \"\"\nroleRef:\n kind: ClusterRole\n name: agg-cluster-role # 미리 만든 클러스터롤을 유저에 바인딩 합니다\n apiGroup: rbac.authorization.k8s.io\n```\n\n## 15. 테인트(Taint) 와 톨러레이션(Tolerations)\n\n- tain : 노드마다 설정 가능 하며, 설정한 노드에는 Pod 가 스케줄 되지 않음\n- Toleration: taint를 무시 할 수 있음\n- Taint 에는 3가지 종류가 있음\n\n| Taint | 설명 |\n| ---------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| NoSchedule | toleration이 없으면 pod이 스케쥴되지 않음, 기존 실행되던 pod에는 적용 안됨 |\n| PreferNoSchedule | toleration이 없으면 pod을 스케줄링안하려고 하지만 필수는 아님, 클러스터내에 자원이 부족하거나 하면 taint가 걸려있는 노드에서도 pod이 스케줄링될 수 있음 |\n| NoExecute | toleration이 없으면 pod이 스케줄되지 않으며 기존에 실행되던 pod도 toleration이 없으면 종료시킴. |\n\n### 15.1 노드에 Taint 설정하기\n\n#### 15.1.1 Taint 설정\n\n```{bash}\nkubectl taint node worker01.acorn.com key=value1:NoSchedule\n```\n\n#### 15.1.2 Taint 조회\n\n```{bash}\nkubectl describe node worker01.acorn.com\n\nnode/worker01.acorn.com tainted\nroot@master:~# kubectl describe node worker01.acorn.com\nName: worker01.acorn.com\nRoles: <none>\nLabels: beta.kubernetes.io/arch=amd64\n beta.kubernetes.io/os=linux\n disk=ssd\n kubernetes.io/arch=amd64\n kubernetes.io/hostname=worker01.acorn.com\n kubernetes.io/os=linux\nAnnotations: kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n node.alpha.kubernetes.io/ttl: 0\n volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp: Wed, 18 Mar 2020 15:48:26 +0000\nTaints: key=value1:NoSchedule\nUnschedulable: false\nLease:\n HolderIdentity: worker01.acorn.com\n```\n\n### 15.2 DaemonSet 생성\n\n#### 15.2.1 Yaml 파일 작성\n\n파일명 : goapp-daemon.yaml\n\n```{yaml}\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n name: goapp-damonset\nspec:\n selector:\n matchLabels:\n app: goapp-pod\n template:\n metadata:\n labels:\n app: goapp-pod\n spec:\n containers:\n - name: goapp-container\n image: dangtong/goapp\n```\n\n```{bash}\nkubectl apply -f ./goapp-daemon.yaml\n```\n\n#### 15.2.2 DaemonSet 생성 확인\n\n```{bash}\nkubectl get po -o wide\n\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES\ngoapp-damonset-bmwfq 1/1 Running 0 18s 10.38.0.3 worker02.acorn.com <none> <none>\n```\n\n> Master 노드와 worker01 에는 스케줄링 되지 않았습니다.\n\n- master 노드의 taint 확인\n\n```{bash}\nkubectl describe node master.acorn.com | grep -i taint\n\nTaints: node-role.kubernetes.io/master:NoSchedule\n```\n\n- worker01 노드의 Taint 확인\n\n```{bash}\nkubectl describe node worker01.acorn.com | grep -i taint\n\nTaints: key=value1:NoSchedule\n```\n\n- DaemonSet 삭제\n\n```{bash}\nkubectl delete ds goapp-damonset\n```\n\n### 15.2.3 Toleration 을 적용한 DaemonSet 생성\n\n- Yaml 파일 작성 : goal-daemon-toler.yaml\n\n```{yaml}\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n name: goapp-damonset\nspec:\n selector:\n matchLabels:\n app: goapp-pod\n template:\n metadata:\n labels:\n app: goapp-pod\n spec:\n tolerations:\n - key: key\n operator: Equal\n value: value1\n effect: NoSchedule\n containers:\n - name: goapp-container\n image: dangtong/goapp\n```\n\n```{bash}\nkubectl apply -f ./goapp-daemon-toler.yaml\n```\n\n- DaemonSet 생성 확인\n\n```{bash}\nkubectl get po -o wide\n\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES\ngoapp-damonset-74klq 1/1 Running 0 35s 10.38.0.3 worker02.acorn.com <none> <none>\ngoapp-damonset-dr4xz 1/1 Running 0 35s 10.40.0.2 worker01.acorn.com <none> <none>\n```\n\n> Pod 가 Taint 를 무시하고 worker01 에도 생성 된것을 확인 할 수 있습니다.\n\n- 다음 테스트를 위해 DaemonSet 삭제\n\n```{bash}\nkubectl delete ds goapp-damonset\n```\n\n- Mater 노드에도 DaemonSet 생성을 위해 Yaml 파일 수정\n\n```{bash}\nkubectl describe no master.acorn.com | grep -i taint\n\nTaints: node-role.kubernetes.io/master:NoSchedule\n```\n\n> master 노드의 Taint 에는 key 와 effect 만 존재함\n\n- Master 노드에 스케줄링이 가능 하도록 Yaml 파일 작성 : goapp-damon-toler-all.yaml\n\n```{yaml}\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n name: goapp-damonset\nspec:\n selector:\n matchLabels:\n app: goapp-pod\n template:\n metadata:\n labels:\n app: goapp-pod\n spec:\n tolerations:\n - key: key\n operator: Equal\n value: value1\n effect: NoSchedule\n - key: node-role.kubernetes.io/master\n operator: Exists\n effect: NoSchedule\n containers:\n - name: goapp-container\n image: dangtong/goapp\n```\n\n```{bash}\nkubectl apply -f ./goapp-daemon-toler-all.yaml\n```\n\n- 다음 테스트를 위해 DaemonSet 삭제\n\n```{bash}\nkubectl delete ds goapp-daemonset\n```\n\n### 15.2.4 untaint 명령으로 노드의 Taint 해지하고 스케줄링 하기\n\n- Untaint 설정 하기\n\n```{bash}\nkubectl describe no worker01.acorn.com | grep -i taint\n\nTaints: key=value1:NoSchedule\n```\n\n```{bash}\nkubectl taint nodes --all key-\n```\n\n> 키값 뒤에 \"-\" 를 붙여 taint 를 해지 합니다. (untaint)\n\n- daemonSet yaml 파일 재수행\n\n```{bash}\nkubectl apply -f ./goapp-daemonset.yaml\n```\n\n- 확인\n\n```{bash}\nkubectl get po -o wide\n\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES\ngoapp-damonset-lj2z7 1/1 Running 0 14s 10.40.0.2 worker01.acorn.com <none> <none>\ngoapp-damonset-vhlq2 1/1 Running 0 15s 10.38.0.3 worker02.acorn.com <none> <none>\n```\n\n## 16. 노드 패치및 업그레이드를 위한 Cordon 과 Drain 사용하기\n\n### 16.1 Cordon 사용하기\n\n```{bash}\nkubectl get nodes\n\nNAME STATUS ROLES AGE VERSION\ngke-cluster-1-default-pool-20e07d73-4ksw Ready <none> 28h v1.14.10-gke.27\ngke-cluster-1-default-pool-20e07d73-6mr8 Ready <none> 28h v1.14.10-gke.27\ngke-cluster-1-default-pool-20e07d73-8q3g Ready <none> 28h v1.14.10-gke.27\n```\n\n- cordon 설정\n\n```{bash}\nkubectl cordon gke-cluster-1-default-pool-20e07d73-6mr8\n```\n\n```{bash}\nkubectl get nodes\n\nNAME STATUS ROLES AGE VERSION\ngke-cluster-1-default-pool-20e07d73-4ksw Ready <none> 28h v1.14.10-gke.27\ngke-cluster-1-default-pool-20e07d73-6mr8 Ready,SchedulingDisabled <none> 28h v1.14.10-gke.27\ngke-cluster-1-default-pool-20e07d73-8q3g Ready <none> 28h v1.14.10-gke.27\n```\n\n- 실제로 스케줄링 되지 않는지 확인해보기\n\n```{bash}\nkubectl run nginx --image=nginx:1.7.8 --replicas=4 --port=80\n```\n\n- 스케줄링 확인\n\n```{bash}\nkubectl get po -o wide\n\nNAME READY STATUS RESTARTS AGE IP NODE\n NOMINATED NODE READINESS GATES\nnginx-84569d7db5-cgf95 1/1 Running 0 9s 10.4.0.17 gke-cluster-1-default-pool-20e07d73-8q3g\n <none> <none>\nnginx-84569d7db5-d7cgg 1/1 Running 0 8s 10.4.1.8 gke-cluster-1-default-pool-20e07d73-4ksw\n <none> <none>\nnginx-84569d7db5-gnbnq 1/1 Running 0 9s 10.4.1.9 gke-cluster-1-default-pool-20e07d73-4ksw\n <none> <none>\nnginx-84569d7db5-xqn7b 1/1 Running 0 9s 10.4.0.16 gke-cluster-1-default-pool-20e07d73-8q3g\n <none> <none>\n```\n\n- uncodon 설정\n\n```{bash}\nkubectl uncordon gke-cluster-1-default-pool-20e07d73-6mr8\n```\n\n```{bash}\nkubectl get nodes\n```\n\n### 16.2 Drain 사용하기\n\n- Drain 설정\n\n```{bash}\nkubeclt get po -o wide\n\nNAME READY STATUS RESTARTS AGE IP NODE\n NOMINATED NODE READINESS GATES\nnginx-84569d7db5-cgf95 1/1 Running 0 3m44s 10.4.0.17 gke-cluster-1-default-pool-20e07d73-8q\n3g <none> <none>\nnginx-84569d7db5-d7cgg 1/1 Running 0 3m43s 10.4.1.8 gke-cluster-1-default-pool-20e07d73-4k\nsw <none> <none>\nnginx-84569d7db5-gnbnq 1/1 Running 0 3m44s 10.4.1.9 gke-cluster-1-default-pool-20e07d73-4k\nsw <none> <none>\nnginx-84569d7db5-xqn7b 1/1 Running 0 3m44s 10.4.0.16 gke-cluster-1-default-pool-20e07d73-8q\n3g <none> <none>\n```\n\n- Pod 가 존재 하는 노드를 drain 모드로 설정하기\n\n```{bash}\nkubectl drain gke-cluster-1-default-pool-20e07d73-8q3g\n\nerror: unable to drain node \"gke-cluster-1-default-pool-20e07d73-8q3g\", aborting command...\nThere are pending nodes to be drained:\n gke-cluster-1-default-pool-20e07d73-8q3g\nerror: cannot delete DaemonSet-managed Pods (use --ignore-daemonsets to ignore): kube-system/fluentd-gcp-v3.1.1-\nt6mnn, kube-system/prometheus-to-sd-96fdn\n```\n\n- daemonset 이 존재 하는 노드일 경우 옵션 추가 해서 drain 시킴\n\n```{bash}\nkubectl drain gke-cluster-1-default-pool-20e07d73-8q3g --ignore-daemonsets\n```\n\n- drian 확인\n\n```{bash}\nkubectl get po -o wide\n\nNAME READY STATUS RESTARTS AGE IP NODE\n NOMINATED NODE READINESS GATES\nnginx-84569d7db5-8qrd2 1/1 Running 0 59s 10.4.2.7 gke-cluster-1-default-pool-20e07d73-6mr\n8 <none> <none>\nnginx-84569d7db5-d7cgg 1/1 Running 0 8m20s 10.4.1.8 gke-cluster-1-default-pool-20e07d73-4ks\nw <none> <none>\nnginx-84569d7db5-gnbnq 1/1 Running 0 8m21s 10.4.1.9 gke-cluster-1-default-pool-20e07d73-4ks\nw <none> <none>\nnginx-84569d7db5-s6xsm 1/1 Running 0 59s 10.4.2.9 gke-cluster-1-default-pool-20e07d73-6mr\n8 <none> <none>\n```\n\n> --delete-local-data --force 등의 추가 옵션 있음\n\n- uncordon\n\n```{bash}\nkubectl drain gke-cluster-1-default-pool-20e07d73-8q3g\n```\n\n## 17. Helm 차트 구성 및 사용(GCP 에서 수행)\n\n### 17.1 Helm 차트 다운로드 및 설치\n\n- 다운로드\n\n```{bash}\ncurl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3\n\nchmod 700 get_helm.sh\n\n./get_helm.sh\n\nDownloading https://get.helm.sh/helm-v3.2.0-linux-amd64.tar.gz\nPreparing to install helm into /usr/local/bin\nhelm installed into /usr/local/bin/helm\n```\n\n- 버전 확인\n\n```{bash}\nhelm version\n\nversion.BuildInfo{Version:\"v3.2.0\", GitCommit:\"e11b7ce3b12db2941e90399e874513fbd24bcb71\", GitTreeState:\"clean\", GoVersion:\"go1.13.10\"}\n```\n\n- helm 차트 리포지토리 추가\n\n```{bash}\nhelm repo add stable https://kubernetes-charts.storage.googleapis.com/\n```\n\n- 리포지토리 업데이트\n\n```{bash}\nhelm repo update\n\nHang tight while we grab the latest from your chart repositories...\n...Successfully got an update from the \"stable\" chart repository\nUpdate Complete. ⎈ Happy Helming!⎈\n```\n\n### 17.2 mysql Helm 차트 다운로드 및 구성\n\n- mysql helm 검색\n\n```{bash}\nhelm search repo stable/mysql\n\nNAME \tCHART VERSION\tAPP VERSION\tDESCRIPTION\nstable/mysql \t1.6.3 \t5.7.28 \tFast, reliable, scalable, and easy to use open-...\nstable/mysqldump\t2.6.0 \t2.4.1 \tA Helm chart to help backup MySQL databases usi...\n```\n\n- 피키지 메타 정보 보기\n\n```{bash}\nhelm show chart stable/mysql\n\napiVersion: v1\nappVersion: 5.7.28\ndescription: Fast, reliable, scalable, and easy to use open-source relational database\n system.\nhome: https://www.mysql.com/\nicon: https://www.mysql.com/common/logos/logo-mysql-170x115.png\nkeywords:\n- mysql\n- database\n- sql\nmaintainers:\n- email: o.with@sportradar.com\n name: olemarkus\n- email: viglesias@google.com\n name: viglesiasce\nname: mysql\nsources:\n- https://github.com/kubernetes/charts\n- https://github.com/docker-library/mysql\nversion: 1.6.3\n```\n\n- mysql helm 차트 설치 및 Deployment\n\n```{bash}\nhelm install stable/mysql --generate-name\n\nAME: mysql-1588321002\nLAST DEPLOYED: Fri May 1 08:16:55 2020\nNAMESPACE: default\nSTATUS: deployed\nREVISION: 1\nNOTES:\nMySQL can be accessed via port 3306 on the following DNS name from within your cluster:\nmysql-1588321002.default.svc.cluster.local\n\nTo get your root password run:\n\n MYSQL_ROOT_PASSWORD=$(kubectl get secret --namespace default mysql-1588321701 -o jsonpath=\"{.data.mysql-root-password}\" | base64 --decode; echo)\n\nTo connect to your database:\n\n1. Run an Ubuntu pod that you can use as a client:\n\n kubectl run -i --tty ubuntu --image=ubuntu:16.04 --restart=Never -- bash -il\n\n2. Install the mysql client:\n\n $ apt-get update && apt-get install mysql-client -y\n\n3. Connect using the mysql cli, then provide your password:\n $ mysql -h mysql-1588321701 -p\n\nTo connect to your database directly from outside the K8s cluster:\n MYSQL_HOST=127.0.0.1\n MYSQL_PORT=3306\n\n # Execute the following command to route the connection:\n kubectl port-forward svc/mysql-1588321002 3306\n\n mysql -h ${MYSQL_HOST} -P${MYSQL_PORT} -u root -p${MYSQL_ROOT_PASSWORD}\n```\n\n```{bash}\nhelm ls\n\nNAME NAMESPACE REVISION UPDATED STATUS C\nHART APP VERSION\nmysql-1588321701 default 1 2020-05-01 17:28:25.322363879 +0900 +09 deployed m\nysql-1.6.3 5.7.28\n```\n\n- helm 차스 uninstall\n\n```{bash}\nheml list\n\nNAME NAMESPACE REVISION UPDATED STATUS C\nHART APP VERSION\nmysql-1588321701 default 1 2020-05-01 17:28:25.322363879 +0900 +09 deployed m\nysql-1.6.3 5.7.28\n\n\nhelm uninstall mysql-1588321701\nrelease \"mysql-1588321701\" uninstalled\n```\n\n## Istio 구성 하기\n\n## 20. 최종 연습문제\n\n### 20.1 PHP GuestBook with Redis\n\n#### 20.1.1 과제 개요\n\n- 레디스 마스터 구성\n- 레디스 슬레이브 구성\n- Guestbook 프론트앤드 구성\n- 프로트앤드 애플리케이션 서비스로 노출 시키기\n- 삭제\n\n#### 20.1.2 레디스 마스터 Deployment 로 구성\n\n| 항목 | 값 |\n| ---------------------------------- | ----------------------------------------- |\n| 파일명 | redis-master-deployment.yaml |\n| Deployment name | redis-master |\n| Deployment Label | app: redis |\n| deployment Selector / pod metadata | app: redis / role: master / tier: backend |\n| replica | 1 |\n| Image | k8s.gcr.io/redis:e2e |\n| Port | 6379 |\n\n> kubectl logs -f POD-NAME\n\n#### 20.1.3 레디스 마스터 서비스 구성\n\n| 항목 | 값 |\n| ----------------- | ----------------------------------------- |\n| Type | ClusterIP |\n| Service 이름 | redis-master |\n| Service Label | app: redis / role: master / tier: backend |\n| port / targetPort | 6379 / 6379 |\n| selector | app: redis / role: master / tier: backend |\n\n#### 20.1.4 레디스 슬레이브 Deployment 구성\n\n| 항목 | 값 |\n| ------------------------- | ------------------------------------------------ |\n| 파일명 | redis-slave-deployment.yaml |\n| Deployment Name | redis-slave |\n| Deployment Label | app: redis |\n| Deployment matchLabel | app: redis / role: slave / tier: backend |\n| Replicas : 2 | |\n| Pod Label | app: redis / role: slave / tier: backend |\n| Container name | slave |\n| Image | gcr.io/google_samples/gb-redisslave:v3 |\n| 환경변수 : GET_HOSTS_FROM | 마스터 노드의 주소로 지정 하되 value=dns 로 설정 |\n| containerPort | 6379 |\n\n- 아래와 같이 소스 코드를 보면 GET_HOSTS_FROM 에는 master 의 주소가 들어가야함\n\n```{php}\n $host = 'redis-master';\n if (getenv('GET_HOSTS_FROM') == 'env') {\n $host = getenv('REDIS_MASTER_SERVICE_HOST');\n }\n```\n\n#### 20.1.5 레디스 슬레이브 서비스 구성\n\n| 항목 | 값 |\n| ----------------- | ----------------------------------------- |\n| Type | ClusterIP |\n| Service 이름 | redis-slave |\n| Service Label | app: redis / role: slave / tier: backend |\n| port / targetPort | 6379 / 6379 |\n| selector | app: redis / role: slaver / tier: backend |\n\n#### 20.1.6 GuestBook 애플리케이션 Deployment 생성\n\n| 항목 | 값 |\n| ------------------------- | ------------------------------------------------ |\n| 파일명 | frontend-deployment.yaml |\n| Deployment Name | frontend |\n| Deployment Label | app: guestbook |\n| Deployment matchLabel | app: guestbook / tier: frontend |\n| Replicas : 3 | |\n| Pod Label | app: guestbook / tier: frontend |\n| Container name | php-redis |\n| Image | gcr.io/google-samples/gb-frontend:v4 |\n| 환경변수 : GET_HOSTS_FROM | 마스터 노드의 주소로 지정 하되 value=dns 로 설정 |\n| containerPort | 80 |\n\n#### 20.1.7 GuestBook 애플리케이션 LoadBalancer 서비스 구성\n\n| 항목 | 값 |\n| ------------- | ------------------------------- |\n| Service name | frontend |\n| service Label | app: guestbook / tier: frontend |\n| Type | LoadBalancer |\n| Port | 80 |\n| selector | app: guestbook / tier: frontend |\n\n#### 20.1.8 FrontEnd 앱 스케일링 해보기\n\nreplica 를 5개로 스케일링 해보기\n\n## 21. Kata 연습 문제\n\n####\n\n#### 1. 단일 Pod 생성\n\nprodnamespace 라는 이름으로 네임스페이스를 만들고 해당 네임스페이스 내에 nginx 단일 Pod 를 생성하세요 (명령어로)\n\n```{bash}\nkubectl create namespace prodnamespace\nkubectl run nginx --image=nginx -n prodnamespace\n```\n\n#### 2. 명령어 이용 다중 Pod 생성\n\nnginx:1.7.9 이미지로 복제본이 2개이고 컨테이너 포트가 80으로 개방된 nginx 라는 이름의 Deployment 를 생성 하세요\n\n```{bash}\nkubectl run nginx-deployment --image=nginx:1.7.8 --replicas=2 --port=80\n```\n\n##### 2.1 하나의 Pod 를 선택해서 yaml 파일을 출력하세요\n\n```{bash}\nkubectl get po\n\nkubectl get po nginx-8bfd472d32-gjzp8 -o yaml\n```\n\n##### 2.2 nginx 이미지를 1.7.9 로 업데이트 하고, 업데이트 내용의 이력을 남기세요 (--record)\n\n```{bash}\nkubectl set image deploy nginx-deployment nginx-deployment=nginx:1.7.9 --record\n\n혹은\n\nkubectl edit deploy nginx-deloyment\n```\n\n##### 2.3 nginx 1.7.9 에서 에러가 발생 했다고 가정하고 rollback 하세요\n\n```{bash}\nkubectl rollout undo deployment/nginx-deployment\n```\n\n##### 2.4 rollout 히스토리를 확인 하세요\n\n```{bash}\nkubectl rollout history deployment/nginx-deployment\n```\n\n##### 2.5 rivision 번호를 이용해 1.7.9 로 rollout undo 하세요\n\n```{bash}\nkubectl rollout undo deployment/nginx-deployment --to-revision=2\n```\n\n##### 2.6 nginx Pod 에 app=v1 이라는 라벨을 입력 하세요\n\n```{bash}\nkubectl label deploy nginx-deployment app=v1\n```\n\n#### 3. BGD(Blue Green Deployment) 구현하기\n\n##### 3.1 nginx 앱을 로드밸런싱 해줄 Loadbalancer 를 구현 하세요\n\n```{bash}\napiVersion: v1\nkind: Service\nmetadata:\n name: nginx-lb\nspec:\n selector:\n app: v1\n ports:\n - protocol: TCP\n port: 80\n targetPort: 80\n type: LoadBalancer\n```\n\n##### 3.2 nginx 의 Loadbalancer External-IP 를 확인하고 curl 명령어로 테스트 해보세요\n\n```{bash}\nkubectl get svc\n\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\nkubernetes ClusterIP 10.8.0.1 <none> 443/TCP 30h\nnginx-lb LoadBalancer 10.8.7.22 35.184.195.100 80:30833/TCP 38s\n```\n\n```{bash}\ncurl http://35.184.195.100\n```\n\n# Appendix\n\n## Appendix 0. VirtualBox 이미지 구성\n\n### 1. VirtualBox 다운로드 및 설치\n\n다운로드 : [https://www.virtualbox.org/wiki/Downloads](https://www.virtualbox.org/wiki/Downloads)\n\n![virtualbox-down](/kubernetes/img/virtualbox-down-3549200.png)\n\n### 2. 가상 이미지 가져오기\n\n- 구글 드라이버 URL\n\nhttps://drive.google.com/open?id=1qAv-FyIWbQVIxNn3MKfjIwbVdvo4rxVl\n\n### 3. 가상 이미지 가져오기\n\n버추얼 박스 실행 후에 <kbd> 파일 </kbd> > <kbd>가상이미지 가져오기</kbd> 클릭\n\n![vbox-choose-image](../../sas_book/img/vbox-choose-image.png)\n\n### 4. VM 설정hisotyr\n\nvm 이름, CPU 개수, MAC 주소 정책 을 아래와 같이 수정 합니다.\n\n![vbox-config](/kubernetes/img/vbox-config.png)\n\n### 5. VM 복제\n\n오른쪽마우스 -> 복제 클릭\n\n![vbox-copy](/kubernetes/img/vbox-copy.png)\n\nVM이름 및 MAC주소정책 변경 후 <kbd> 복제 </kbd> 클릭\n\n![vbox-copy-config](/kubernetes/img/vbox-copy-config.png)\n\n동일한 방법으로 worker02 VM 또 생성 합니다. 최종적으로 아래와 같이 3개의 VM 이 보이면 됩니다.\n\n![vbox-overall](/kubernetes/img/vbox-overall.png)\n\n복제된 vm 에 접속하여 /etc/netplan/00-installer-config.yaml 파일을 수정 합니다.\n\n```{txt}\nnetwork:\n ethernets:\n enp0s3:\n dhcp4: no\n addresses: [10.0.2.17/24] ## IP 수정 (VM 마다 하나씩 IP 증가)\n gateway4: 10.0.2.2\n nameservers:\n addresses: [8.8.8.8, 8.8.4.4]\n enp0s8:\n dhcp4: no\n addresses: [192.168.56.110/24] ## IP 수정 (VM 마다 하나씩 IP 증가)\n version: 2\n```\n\n수정 후에는 netplan 명령어로 변경된 IP 로 적용\n\n```{bash}\nnetplan apply\n```\n\n## Appendix 1. 쿠버네티스 설치\n\n### 1.설치 사전 작업\n\n#### 1.1 Nftable disable\n\n```{bash}\nsudo update-alternatives --set iptables /usr/sbin/iptables-legacy\nsudo update-alternatives --set ip6tables /usr/sbin/ip6tables-legacy\nsudo update-alternatives --set arptables /usr/sbin/arptables-legacy\nsudo update-alternatives --set ebtables /usr/sbin/ebtables-legacy\n```\n\n#### 1.2 호스트명 변경\n\n```{bash}\n# hostnamectl set-hostname [FQDN-HOST-NAME] --static\n# 마스터 노드에서 수행\nhostnamectl set-hostname kmaster\nhostnamectl set-hostname kmaster.acorn.com --static\n\n\n# 첫번째 Worker 노드에서 수행\nhostnamectl set-hostname kworker01\nhostnamectl set-hostname kworker01.acorn.com --static\n\n# 두번째 Worker 노드에서 수행\nhostnamectl set-hostname kworker02\nhostnamectl set-hostname kworker02.acorn.com --static\n```\n\n#### 1.3 각노드에 호스트 파일 등록\n\n모든노드의 /etc/hosts 파일에 아래와 같이 등록 되어 있을것\n\n```{bash}\n192.168.56.111 kmaster.acorn.com kmaster\n192.168.56.112 kworker01.acorn.com kworker01\n192.168.56.113 kworker02.acorn.com kworker02\n```\n\n#### 1.4 방화벽 점검\n\n##### 1.4.1 Control Plane 노드\n\n| Protocol | Direction | Port Range | Purpose | Used By |\n| :------- | :-------- | :--------- | :---------------------- | :------------------- |\n| TCP | Inbound | 6443\\* | Kubernetes API server | All |\n| TCP | Inbound | 2379-2380 | etcd server client API | kube-apiserver, etcd |\n| TCP | Inbound | 10250 | Kubelet API | Self, Control plane |\n| TCP | Inbound | 10251 | kube-scheduler | Self |\n| TCP | Inbound | 10252 | kube-controller-manager | Self |\n\n##### 1.4.2 worker 노드\n\n| Protocol | Direction | Port Range | Purpose | Used By |\n| :------- | :-------- | :---------- | :-------------------- | :------------------ |\n| TCP | Inbound | 10250 | Kubelet API | Self, Control plane |\n| TCP | Inbound | 30000-32767 | NodePort Services\\*\\* | All |\n\n### 2. Runtime 설치\n\n#### 2.1 도커 설치 (all nodes)\n\n```{bash}\nsudo apt update\nsudo apt install docker.io\n```\n\n#### 2.2 kubernetes 설치 (all nodes)\n\n설치 스크립트 [클릭](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#before-you-begin)\n\n```{bash}\nsudo apt-get update && sudo apt-get install -y apt-transport-https curl\ncurl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\ncat <<EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list\ndeb https://apt.kubernetes.io/ kubernetes-xenial main\nEOF\nsudo apt-get update\nsudo apt-get install -y kubelet kubeadm kubectl\nsudo apt-mark hold kubelet kubeadm kubectl\n```\n\n### 3. Post Installation\n\n#### 3.1 SWAP 기능 해제(all nodes)\n\n```{bash}\nsudo swapoff -a # 현재 일시적용\nsudo sed -i '/swap/s/^/#/' /etc/fstab # 재가동 후에도 swapoff 할려면 수행 해야함\n```\n\n#### 3.2 도커 시스템서비스 등록 하기 (all nodes)\n\n도커 데몬을 system 서비스에 등록하지 않으면 kubernetes 설치시에 warning 발생 하기 때문에 아래와 같이 등록해줌\n\n```{bash}\nsudo vi /etc/docker/daemon.json\n```\n\n아래와 같이 입력 후 저장 합니다.\n\n```{json}\n{\n \"exec-opts\": [\"native.cgroupdriver=systemd\"],\n \"log-driver\": \"json-file\",\n \"log-opts\": {\n \"max-size\": \"100m\"\n },\n \"storage-driver\": \"overlay2\"\n}\n```\n\n```{bash}\n\nsudo mkdir -p /etc/systemd/system/docker.service.d\n\n# Restart docker.\nsudo systemctl enable docker.service\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n```\n\n#### 3.3 kubeadm을 사용하여 마스터 설정 (master node)\n\n네트워크 인터페이스가 여러개일 경우 가장 우선 순위가 가장 높은 인터페이스가 자동 선정 되기 때문에 '--apiserver-advertise-address' 옵션을 사용해서 ip 혹은 인터페이스 명을 지정해야 합니다.\n\n```{bash}\nsudo kubeadm init --pod-network-cidr=192.168.0.0/16 --service-cidr 10.96.0.0/12 --apiserver-advertise-address=192.168.56.111\n\n# kubeadmin init 시에 여러 가지 옵션들\n# --pod-network-cidr=192.168.0.0/16\n# --control-plane-endpoint=192.168.56.111\n# --apiserver-cert-extra-sans=192.168.56.111\n# --service-cidr 10.96.0.0/12\n# --service-dns-domain \"k8s\"\n# --apiserver-advertise-address __YOUR_IP_HERE___\n\n# 잘못 설치한 경우 master 및 worker 노드에 수행 하면 모든 설정을 초기화함\n# kubeadm reset cleanup-node\n```\n\n### 4. 워커 노드 등록\n\n#### 4.1 워커 노드 등록 (worker node only)\n\n> 반듯이 kubeadm init 을 통해 나온 로그에 표시된 ip 와 token 으로 worker 노드에서만 수행\n\n```{bash}\nsudo kubeadm join 192.168.56.111:6443 --token dro5or.x9ujk49k0aadiz8s \\\n --discovery-token-ca-cert-hash sha256:b6372f30c5733a5c88d0a6b6095efbf4cb495329cbcd19df33e7a894a96ec53d\n```\n\n#### 4.2 마스터 노드 kube client 설정 (master node)\n\n```{bash}\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n#### 4.3 클러스터 상태 확인(master node)\n\n결과가 모두 not ready 로 나옴 (시간이 좀 걸림)\n\n```{bash}\nkubectl get nodes\n```\n\n#### 4.4 네트워크 어플리케이션 설치(master node)\n\n네트워크 툴 설치 후에는 모든 노드가 ready 로 나와야 함\n\n```{bash}\nkubectl apply -f \"https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\\n')\"\n\nkubectl get nodes\n```\n\n#### 4.5 kubectl 명령어 자동완성 패키지 설치(master node)\n\n```{bash}\n# 자동 완성을 bash 셸에 영구적으로 추가한다\necho \"# k8s auto completion and alias\" >> ~/.bashrc\necho \"source <(kubectl completion bash)\" >> ~/.bashrc\necho \"alias k=kubectl\" >> ~/.bashrc\necho \"complete -F __start_kubectl k\" >> ~/.bashrc\n```\n\n### 5. etcd 설치(master node)\n\n기본적으로 내장 etcd 가 있지만, etcd-io 의 릴리즈로 설치 합니다.\n\n다운로드 url : [클릭](https://github.com/etcd-io/etcd/releases)\n\n```{bash}\nwget https://github.com/etcd-io/etcd/releases/download/v3.3.18/etcd-v3.3.18-linux-amd64.tar.gz\ntar -xf etcd-v3.3.18-linux-amd64.tar.gz\ncd etcd-v3.3.18-linux-amd64\n\nsudo ETCDCTL_API=3 ./etcdctl --endpoints 127.0.0.1:2379 \\\n--cacert /etc/kubernetes/pki/etcd/ca.crt \\\n--cert /etc/kubernetes/pki/etcd/server.crt \\\n--key /etc/kubernetes/pki/etcd/server.key \\\nget / --prefix --keys-only\n```\n\n## Appendix 2. 구글 GKE 사용하기\n\n#### 1. 회원가입\n\n- $300 무료 크레딧 제공\n- 신용카드 필요 (한도를 넘으도 자동 과금 안됨)\n- http://cloud.google.com 에서 회원 가입\n\n#### 2. 프로젝트 생성\n\n- <kbd>프로젝트 선택</kbd> 을 클릭 합니다.\n\n![프로젝트 선택](/kubernetes/img/GKE-project-int.png)\n\n- <kbd>새 프로젝트</kbd> 를 클릭 합니다.\n\n![](/kubernetes/img/GKE-project-choose.png)\n\n- 프로젝트 이름에 원하는 값을 입력하고 <kbd>만들기</kbd> 클릭\n\n![GKE-new-project](/kubernetes/img/GKE-new-project.png)\n\n#### 3. 쿠버네티스 클러스터 생성\n\n- 홈메뉴 에서 <kbd> Kubernetes Engine </kbd> 클릭\n\n![GKE-ngine-enter](/kubernetes/img/GKE-ngine-enter.png)\n\n- 프로젝트를 선택하기 위해 <kbd> 프로젝트 선택</kbd> 클릭\n\n![GKE-choose-project-for-create-cluster](/kubernetes/img/GKE-choose-project-for-create-cluster.png)\n\n- 팝업창이 뜨면 프로젝트 gke-first 를 선택하고 <kbd> 열기 </kbd> 클릭\n\n![GKE-open-project](/kubernetes/img/GKE-open-project.png)\n\n- 1분정도 기다린 후에 <kbd> 클러스터 만들기 </kbd> 클릭\n\n![](/kubernetes/img/GKE-create-cluster.png)\n\n- 클러스터 기본사항 에서 영역을 \"asia-east1-a\" 로 선택 한후, <kbd> 만들기</kbd> 클릭\n\n![GKE-create-cluster-1](/kubernetes/img/GKE-create-cluster-1.png)\n\n- 아래와 같이 k8s 클러스터를 생성 중인 화면이 나오면 정상 적으로 진행이 된 것입니다.\n\n![GKE-cluster-complete](/kubernetes/img/GKE-cluster-complete.png)\n\n#### 4. 쿠버네티스 클러스터 접속 테스트\n\n- GKE 클러스터가 생성되면 <kbd> 연결 </kbd> 클릭\n\n![GKE-cluster-connect-1](/kubernetes/img/GKE-cluster-connect-1.png)\n\n- 팝업창이 뜨면 <kbd> Cloud Shell에서 실행 </kbd> 클릭\n\n![GKE-cluster-connect-2](/kubernetes/img/GKE-cluster-connect-2.png)\n\n## Appendix 4. Google Cloud SDK 설치 하기\n\n### 1. GCloud SDK 다운로드\n\n![cloud_sdk_1](/kubernetes/img/cloud_sdk_1.png)\n\n### 2. Cloud SDK 설치\n\n![cloud_sdk_2](/kubernetes/img/cloud_sdk_2.png)\n\n### 3. 로컬 머신에서 Cloud Shell 연결 명령어 복사\n\n![](../img/cloud_sdk_3.png)\n\n![cloud_sdk_4](/kubernetes/img/cloud_sdk_4.png)\n\n### 4. 로컬 CMD 또는 SHELL 에서 연결 하기\n\n웹에서 복사한 내용을 그대로 붙여놓고 실행\n\n![cloud_sdk_5](/kubernetes/img/cloud_sdk_5.png)\n\n## Appendix 3. Git 계정 생성 및 Sync\n\n### 1.Git 계정생성\n\nwww.github.com 에서 계정 생성\n\n### 2. Git 리포지토리 생성\n\n- GitHub.com 에 자신의 계정으로 로그인하여 아래 화면과 같이 리포지토리 생성\n\n![](/kubernetes/img/git_repo_create.png)\n\n- 리포지토리 이름을 아래와 같이 입력하고. 생성 합니다. (Repository name : k8s-web)\n\n![git_repo_create_spec](/kubernetes/img/git_repo_create_spec.png)\n\n### 3. 소스 파일 작성\n\n```{bash}\n$ mkdir -p ./gitvolumn/html\n$ mkdir -p ./gitvolumn/kubetmp\n$ cd ./gitvolumn/html\n$ vi index.html\n```\n\nindex.html 이름으로 아래 페이지를 작성 합니다.\n\n```{html}\n<!DOCTYPE html>\n<html>\n<body>\n\n<h1>K8s Landing Page</h1>\n\n<p>Hello Kubernetes !!!</p>\n\n</body>\n</html>\n\n```\n\n### 4. Git 리포지토리 생성 및 초기화\n\n```{bash}\n$ git init\n$ git add .\n$ git commit -a -m \"first commit\"\n\n$ git remote add origin https://github.com/<계정명>/k8s-web.git\n$ git remote -v\n$ git push origin master\n\n$ git status\n\n```\n\n## Appendix 4. Persist Volume 서비스를 위한 Ceph 설치\n\n### 1. Ceph 설치(worker01, worker02)\n\n```{bash}\n$ apt-cache search ceph\n\n$ apt install ceph\n\n\n```\n",
    "dir": "/kubernetes/",
    "name": "Learning-kubernetes.md",
    "path": "kubernetes/Learning-kubernetes.md",
    "url": "/kubernetes/Learning-kubernetes.html"
  },
  {
    "layout": "default",
    "title": "Spotfire Analyst 데이터 시각화 첫걸음",
    "content": "# Spotfire Analyst 데이터 시각화 첫걸음\n\n본 고재는 Spotfire 10.10.2 기준으로 2020년 12월 에 작성 되었습니다.\n\n작성자 : 변현창 bhyuncha@tibco.com\n\n[toc]\n\n## 1.시작하기\n\n### 1.1 Spotfire 접속하기\n\n### 1.2 화면 둘러보기\n\n#### 시작 화면\n![Image of Yaktocat](/spotfireBasic/img/sfUserGuide/start-1.png)\n\n## 2. 데이터 로딩\n\n### 데이터를 로딩하는 3가지 방법\n\n- Drag & Drop : 내 컴퓨터에 있는 파일을 Spotfire 영역 내로 끌어당겨 데이터를 로드 합니다.\n- <kbd>File</kbd>  → <kbd>Open</kbd> : 메뉴 바를 통해 데이터를 로드 합니다.\n- Clipborad : 엑셀 이나 메모장의 데이터를 클립보드에 복사 ( <kbd>Ctrl + C</kbd> ) 하여 데이터를 로드하는 방법\n\n## 3. 시각화 기본\n\n### 3.1 Table Chart\n\n#### 3.1.1 데이터 로딩\n\ndataSet 폴더에서 OrderDetails.xls 파일을 로딩 합니다.\n\n#### 3.1.2 차트생성\n\n시각화에서 테이블 아이콘을 드래그 해서 옮겨 놓습니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-table-1.png)\n\n#### 3.1.3 컬럼순서 변경 및 소팅\n\n**CUSTOMERID** (컬럼명) 을 클릭 하면 팝업 창이 뜨고 <kbd>Move First</kbd> 를 클릭해서 컬럼을 가장 앞쪽으로 이동 시킵니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-table-2.png)\n\n#### 3.1.4 정렬하기\n\n**CUSTOMERID** 를 누르면 팝업 창이 뜨게되고 오름차순 정렬 아이콘을 클릭 합니다. 컬럼이름 옆에 세모아이콘으로 오름차순 혹은 내림차순 정렬인지 확인 할 수 있습니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-table-3.png)\n\n#### 3.1.5 컬럼 헤더 크기 조정\n\n**Properties(속성)** 에서 <kbd>Appearance</kbd> 항목에서 **Header row height** 항목에 **3**을 입력 합니다\n\n![](/spotfireBasic/img/sfUserGuide/vis-table-4.png)\n\n컬럼 헤더의 높이를 조정 하면 컬럼의 수가 많을 때 한화면에 많은 컬럼을 볼수 있도록 해주는 효과가 있습니다. 아래 그림과 같이 컬럼 이름이 2~3개 행으로 나뉘어 컬럼이 좁아지게 됩니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-table-5.png)\n\n#### 3.1.6 열고정\n\n![](/spotfireBasic/img/sfUserGuide/vis-table-6.png)\n#### 3.1.7 테이블에 이미지 사용하기\n\n**Properties(속성창)** 에서 <kbd>Columns</kbd> → <kbd>Selected columns</kbd> 에서 **CUSTOMER GENDER** 를 선택 합니다. **Renderer** 에서 <kbd>image from URL</kbd> 을 선택 하면 팝업 창이 뜨게 됩니다.\n\n이미지 파일이 존재하는 폴더를 경로에 입력합니다. 중요한것은 파일의 이름이 **CUSTOMER GENDER** 의 값 과 이름이 동일해야 합니다. 따라서 파일명은 **{$}** 로 변수 처리 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-table-7.png)\n\nAllowed URIs 에 허용된 URI 가 없는 것을 확인 할 수 있습니다. 보안상의 이유로 허용된 URI 를 등록(whitelist) 해야 이미지 ACCESS 가 가능합니다. 아래는 Administrator 가 접근 가능한 URI 리스트(whitelist) 를 설정 하는 방법 입니다. 일반 적으로 기업내에 HTTP 로 접근 가능한 디렉토리를 서비스하고 해당 장소에 모든 이미지를 올려 두면 좋습니다.\n\n- Administrator의 Whitelist 설정 방법 : <kbd>Tools</kbd>→<kbd>Administration manager</kbd> 를 클릭해서 관리자 화면으로 들어갑니다.\n- <kbd>Perference</kbd> 탭에서 URI 를 허용할 그룹을 선택 합니다. (화면에서는 Everyone 그룹)\n- <kbd>Applications</kbd>→<kbd>Application Preference</kbd>→<kbd>Whitelist Allowed URIs</kbd> 에 허용하는 URI 를 \",\" 를 구분자로 하여 여러개를 입력 할수 있습니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-table-8.png)\n\n![](/spotfireBasic/img/sfUserGuide/vis-table-9.png)\n\n> 기본적으로 Spotfire Desktop 은 서버 로그인이 필요 없기 때문에 <Spotfire 설치 폴더>/modules/Spotfire DXP Forms\\_\\* 디렉토리 밑의 Desktop_Preference_WhitelistForSecuritySensitiveUris 셋팅에 Value 에 허용할 URI 리스트를 입력하면 됩니다. (재 시작 필요)\n\n```{xml}\n[....]\n <setting name=\"Desktop_Preference_WhitelistForSecuritySensitiveUris\" serializeAs=\"String\">\n아래 Value 항목에 ',' 을 기준으로 여러 개를 입력하면 됩니다. <value>http://example.com/some/very/special/deep/path/,http://*.example2.com/,http://*.example3.com/some/\npath/</value>\n </setting>\n </Spotfire.Dxp.Application.Properties.Settings>\n </applicationSettings>\n <startup><supportedRuntime version=\"v4.0\"\nsku=\".NETFramework,Version=v4.5\"/></startup>\n</configuration>\n```\n\n#### 3.1.8 결과 화면\n\n![](/spotfireBasic/img/sfUserGuide/vis-table-10.png)\n\n### 3.2 Bar Chart (막대 그래프)\n\n#### 3.2.1 데이터 로딩\n\ndataSet 폴더에서 OrderDetails.xls 파일을 로딩 합니다.\n\n#### 3.2.1 검색으로 부터 그래프 그리기\n\n화면 우측 상단의 검색 아이콘을 클릭 하거나 <kbd>Ctrl </kbd>+<kbd>F</kbd> 를 누르게 되면 아래와 같이 검색 화면이 보이게 됩니다. Spotfire 에서는 변수, 그래프, 페이지, 테이블 등 다양한 영역에 대해 검색을 동시에 진행하고 결과를 바로 보엽 줍니다.\n\n- 변수명인 **Product Category 2** 를 입력합니다.\n- 검색 결과로 나온 (View Row Count per RRODUCT CATEGORY 2) 그래프를 선택 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-bar-1.png)\n\n#### 3.2.2 Stacked Bar Chart (누적 막대그래프) 만들기\n\n- **Data in Analysis** 에서 **ORDER STATUS** 를 오른쪽 시각화 영역으로 아래 그림과 같이 Drag and Drop 을 수행 합니다.\n- **Colored by ORDER STATUS**를 선택 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-bar-2.gif)\n\n#### 3.2.3 Horizontal Bar Chart (수평막대차트) 만들기\n\n시각화 영역에서 오른쪽 마우스 버튼을 클릭 한뒤 <kbd>**Horizontal Bars**</kbd> 및 <kbd>**Side-by-Side Bars**</kbd>를 클릭 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-bar-3.png)\n\n#### 3.2.4 100% Stacked Bar Chart 만들기\n\n- 신규 페이지를 추가로 생성 합니다.\n- **Data in Analysis** 에서 **ORDER AMOUNT** 와 **PRODUCT CATEGORY 2** 를 선택 하면 그래프 추천 항목에서 **View ORDER AMOUNT per PRODUCT CATEGORY 2** 시각화를 선택 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-bar-4.png)\n\n- 오늘쪽 상단의 범래(Legend) 에서 **Color by** 의 **None** 을 클릭하게 한뒤 **ORDER STATUS** 를 클릭 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-bar-6.png)\n\n- 마우스 오른쪽 버튼을 클릭해서 **100% Stacked Bars** 를 클릭 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-bar-7.png)\n\n-\n\n![](/spotfireBasic/img/sfUserGuide/vis-bar-8.png)\n\n#### 3.2.5 Histogram 차트\n\n- 신규 페이지를 하나 더 생성 합니다.\n- **시각화 메뉴**에서 **Bar Chart ** 를 드래그 해서 현재 페이지에 Drop 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-bar-9.png)\n\n- X축 인자에 **QUANTITY** 를 선택 하게 되면, 막대 그래프가 얇게 변하게 됩니다.\n- Y축 인자로 **ORDER AMOUNT** 를 선택 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-bar-10.png)\n\n-\n\n![](/spotfireBasic/img/sfUserGuide/vis-bar-11.png)\n\n- X축의 **QUANTITY** 에 있는 슬라이드 막대를 클릭 하면 BINNING 개수를 조정 할수 있습니다.\n- X축의 **QUANTITY** 를 오른쪽 마우스 클릭해서 **Number of Bins** 를 클릭해서 직접 개수를 입력 할 수도 있습니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-bar-112.png)\n\n### 3.3 Line Chart (선 그래프)\n\n#### 3.3.1 데이터 로딩\n\ndataSet 폴더에서 **Seoul-Air.csv** 파일을 로딩 합니다. <br>아래 표는 데이터셋에 포함된 변수에 대한 설명 입니다.\n\n| 변수명 | 설명 |\n| ------ | ----------- |\n| CO | 일산화탄소 |\n| NO2 | 이산화 질소 |\n| O3 | 오존 |\n| SO2 | 아황산가스 |\n| PM10 | 미세먼저 |\n| PM2.5 | 초미세먼지 |\n\n#### 3.3.2 그래프 생성\n\n![](/spotfireBasic/img/sfUserGuide/vis-line-1.png)\n\n#### 3.3.3 다변량 선 그래프\n\n- 하나의 차트에 여러가지 선을 그리기 위해 **CO**, **PM2.5**, **PM10** 세 변수를 선택 하여 드래그 한다음 아래 화면과 같이 **Y축** 인자로 DROP 합니다.\n- 집계가 기본이 SUM 이기 때문에 **AVG** 로 모두 바꿔 줍니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-line-2.png)\n\n#### 3.3.4 멀티축 설정\n\n- 일산화탄소인 **CO** 의 변화량을 확인하기 힘들다는 것을 알수 있습니다.\n- **Y** 측에 대고 오른쪽 마우스를 클릭하면 Scale 3가지 옵션중 **Dual Scale** 을 선택 합니다.\n- **Y** 축에 있는 **CO2** 를 드래그 해서 우측에 새로생긴 **Y축** 으로 옮겨서 Drop 합니다.\n\n> 멀티축을 사용하는 것은 값의 범위(Range) 가 서로 다른 변수들의 트랜드를 보기 위해 사용 합니다. 멀티 축을 사용하면 같은 축으로 그렸을때 보이지 않던 트랜드가 확실 뚜렷하게 보입니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-line-3.png)\n\n- **Properties**(속성) 의 **Y-axis** 항목에서도 멀티축에 대한 정보를 수정및 조회 할 수 있습니다.\n\n#### 3.3.5 패널 별 선그래프\n\n- 미세먼지를 측정 한 장소별로 보기 위해 **Properties(속성)** 창을 엽니다.\n- <kbd>Trellis</kbd> → <kbd>Panels</kbd> 항목에서 **Split by** 항목에 **Address** 를 선택합니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-line-4.png)\n\nFiscalYearOffSet 추가\n\n### 3.4 Scatter Plot (산점도)\n\n#### 3.4.1 데이터 로딩\n\ndataSet 폴더에서 **Apt-price-2019-songpa.csv** 파일을 로딩 합니다.\n\n#### 3.4.2 그래프 생성\n\n- **시각화 메뉴** 에서 **Scatter Plot** 을 드래그 해서 시각화 화면에 DROP 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-scatter-1.png)\n\n- X축을 **deal_ymd** (Year >> Quater >> Month >> Day of Month) 로 설정 하세요\n- Y축을 **price_by_area** 로 설정하세요\n\n![](/spotfireBasic/img/sfUserGuide/vis-scatter-2.png)\n\n#### 3.4.3 점의 크기 조정 및 Jittering\n\n- X축에 마우스 왼쪽을 클릭하여 점의 크기와 Jittering 을 수행 합니다.\n- Y축에 마우스 왼쪽을 클릭하여 Jittering 을 수행 합니다.\n- Jittering 은 겹쳐진 점이 보이게 하기 위해 Random 값으로 일정하게 분산 시키는 효과를 가집니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-scatter-3.png)\n\n> 산점도에서 겹쳐진 점을 보이게 하는 방법은 크게 Jittering 과 투명도를 높이는 두가지 방법이 있습니다. 투명도의 경우에는 완전히 겹쳐진 점에 대해서는 좀더 색깔이 진해 지는 형태로 데이터가 많이 몰려 있는걸을 확인 할 수 있습니다.\n\n#### 3.4.4 점의 모양 / 크기 / 투명도 변경\n\n- **Properties(속성)** 창에서 <kbd>Appearance</kbd> → <kbd>Transparency</kbd> 에서 적당한 투명도로 조정 합니다.\n- **Properties(속성)** 창에서 <kbd>Size</kbd> → <kbd>Sized by</kbd> 에 **size** 를 선택 합니다.\n- **Properties(속성)** 창에서 <kbd>Shape</kbd> → <kbd>Shape definition</kbd> 에서 정사각형으로 선택 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-scatter-4.png)\n\n- 결과 화면 : 이전보다 훨씬 명확하게 트랜드를 구분 할수 있습니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-scatter-5.png)\n\n#### 3.4.5 패널 추가 및 회귀선\n\n- **Properties(속성)** 에서 <kbd>Trellis</kbd> → <kbd>Panels</kbd> 에서 **apt_name** 을 선택 합니다.\n- <kbd>Lines & Curves</kbd> → <kbd>Add</kbd> → <kbd>Straight Line Fit...</kbd> 을 클릭해서 팝업창이 뜨면 <kbd>OK</kbd> 클릭\n- <kbd>Lines & Curves</kbd> → <kbd>Label and Tooltip </kbd> 클릭후 팝업창이 뜨면 **R^2 of the regression(r2)** 를 선택 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-scatter-6.png)\n\n- 결과 화면 : R^2 값은 모델의 설명력을 표현합니다. 회귀선을 그렸을때 회귀선이 얼마나 주어진 데이터를 잘 설명하는지에 대한 척도 입니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-scatter-7.png)\n\n## 4. Marking & Filtering\n\n#### 4.1 Marking(마킹)\n\n#### 4.1.1 데이터 로딩\n\ndataSet 폴더에서 **Mark-Filter-Export.dxp** 파일을 로딩 합니다. 로딩 하게 되면 아래와 같은 화면이 보입니다.\n\n- 막대 차트의 일부를 선택 하게 되면 오른쪽 **Table 차트** 에 마킹된 값만 하이라이트 됩니다.\n\n![](/spotfireBasic/img/sfUserGuide/Mark-Filter-1.png)\n\n#### 4.1.3 새로운 Marking 만들기\n\n- <kbd>File</kbd>→<kbd>Document properties</kbd> 를 클릭 합니다.\n- **Document Properties** 에서 <kbd>Marking</kbd> → <kbd>New</kbd> 를 클릭 합니다.\n- 아래와 같이 색상을 선택한 다음 **myMarking** 을 입력하고 <kbd>OK</kbd>\n\n![](/spotfireBasic/img/sfUserGuide/Mark-Filter-2.png)\n\n#### 4.1.4 새로운 Marking 적용하기\n\n- **Bar Chart** 의 **Properties(속성)** 창을 엽니다\n- <kbd>Data</kbd> → <kbd>Marking</kbd> 에서 **myMarking** 을 선택 합니다.\n- <kbd>Legend</kbd> 의 **Display the following legend items** 에서 **Marking** 을 선택 합니다.\n- <kbd>Appearance</kbd> 에서 **Use separate color for marked items** 를 체크 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/Mark-Filter-3.png)\n\n- 이제 막대 그래프의 영역을 선택 하면 초록색으로 바뀌지만 , 테이블 차트의 데이터가 Highlight 되지 않습니다.\n- 막대그래프의 빈공간을 클릭 하면 마킹이 해지 됩니다.\n\n![](/spotfireBasic/img/sfUserGuide/Mark-Filter-4.png)\n\n#### 4.1.5 Table 차트에 신규 마킹을 이용해 데이터 제한하기\n\n- 테이블 차트의 **Properties(속성)** 화면으로 이동 합니다.\n- <kbd>Data</kbd> 항목에서 **Marking** 을 Bar Chart 에서 설정한 **myMarking** 으로 변경 합니다.\n- <kbd>Data</kbd> 항목에서 **Data limiting** 에서 myMarking 을 체크 합니다.\n- <kbd>Data</kbd> 항목에서 **If no item are marked in the master visulaization, show:** 항목에서 **All data** 를 선택 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/Mark-Filter-5.png)\n\n- 이제 Bar Chart 에서 선택한 데이터가 없으면, 모든 데이터를 보여주고, 데이터를 Marking 하면 Marking 한 데이터에 대해서만 필터하여 데이터를 보여 줍니다.\n\n![](/spotfireBasic/img/sfUserGuide/Mark-Filter-6.png)\n\n#### 4.1.6 데이터에 필터 적용하기\n\n- **데이터 메뉴** 에서 **Total Amount of Purchases** 를 클릭 하면 오른쪽에 **깔때기** 아이콘을 클릭 해서 슬라이드 바를 조정 해서 필터링을 적용 할수 있습니다.\n- 변수에 적용된 필터는 **데이터 메뉴** 하단에 **Clear selections** 항목에 표시 되어 현재 데이터 레벨에서 적용된 필터를 한눈에 확인 할수 있고, 삭제도 할 수 있습니다.\n\n![](/spotfireBasic/img/sfUserGuide/Mark-Filter-7.png)\n\n- **X** 버튼을 눌러서 필터를 해지 합니다.\n\n#### 4.1.7 필터 패널 사용하기\n\n- 필터 패널을 사용하기 위해서는 오른쪽 상단의 필터 바로가기 버튼을 클릭 합니다.\n- 필터 패널에서 **Store Location** 을 찾아 오른쪽 마우스 버튼을 클릭 합니다.\n- **Filter Type** 을 **Radio Button Filter** 로 변경 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/Mark-Filter-8.png)\n\n- 패널 필터를 조정 하면서 두번째 페이지의 데이터가 어덯게 필터링 되는지 확인 해봅니다.\n\n#### 4.1.8 신규 패널 만들기\n\n![](/spotfireBasic/img/sfUserGuide/Mark-Filter-9.png)\n\n## 5. 파일 저장 하기\n\n### 5.1 DXP 파일 저장 하기\n\n- 현재 열고 있는 Mark-Filter-Export.dxp 파일을 저장 해보겠습니다.\n- <kbd>File</kbd>→<kbd>Save as</kbd> 를 클릭 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/Mark-Filter-9.png)\n\n### 5.2 Spotfire 의 문서 구조 이해\n\n![](/spotfireBasic/img/sfUserGuide/Mark-Filter-10.png)\n\n## 6. 시각화 2편\n\n### 6.1 Parallel Coordinate Plot (평행 좌표)\n\n> tutorialFiles/iris.csv 파일을 엽니다.\n>\n> iris 데이터셋은 아래와 같은 항목을 가지고 있습니다.\n\n| 항목 | 의미 |\n| ------------ | ------------- |\n| Petal.Length | 꽃잎의 길이 |\n| Petal.Width | 꽃잎의 폭 |\n| Sepal.Length | 꽃받침의 길이 |\n| Sepal.Width | 꽃받침의 폭 |\n\n#### 6.1.1 파일불러오기\n\n<kbd>File</kbd> → <kbd>Open</kbd> → <kbd>Browse local file </kbd> 을 선택하여 **SfDataSet** 디렉토리의 iris.csv 파일을 불러 옵니다.\n\n#### 6.1.2 Parallel Coordinate Plot 그리기\n\n- 시각화에서 <kbd>Parallel coordinate plot</kbd> 을 드래그 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-corr-1.png)\n\n- X축의 에 마우스를 올리고 **회색** 으로 변하면 <kbd>왼쪽 마우스 버튼</kbd>를 클릭 합니다. <kbd>select columns</kbd> 를 클릭 하면 차트에 사용 할 컬럼을 선택 할 수 있습니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-corr-2.png)\n\n- 결과 화면\n\n![](/spotfireBasic/img/sfUserGuide/vis-corr-3.png)\n\n#### 6.1.3 집계 적용하기\n\n- 다시 **Properties(속성)** 에서 <kbd>Line By</kbd> 를 클릭 한뒤, 항목을 **Species** 를 선택 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-corr-4.png)\n\n- 아래와 같이 붓꽃의 종류별로 단일 선으로 표시 됩니다. 기본은 **SUM** 함수를 이용해 모두를 더한 값이 표시 됩니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-corr-5.png)\n\n- 붓꽃 각각의 넓이와 길이를 평균으로 표시 하기 위해 **Properties(속성)** 창을 다시 열어 <kbd>Columns</kbd> 항목을 클릭하고 **Aggregation** 함수를 **Sum** 에서 **Average** 로 변경 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-corr-6.png)\n\n### 6.2 Box Plot (상자 도표)\n\n#### 6.2.1 파일 불러오기\n\n<kbd>File</kbd> → <kbd>Open</kbd> → <kbd>Browse local file </kbd> 을 선택하여 **dataSet** 디렉토리의 **ItemDetails.txt** 파일을 불러 옵니다.\n\n#### 6.2.2 BoxPlot 그리기\n\n-\n\n![](/spotfireBasic/img/sfUserGuide/vis-box-1.png)\n\n#### 6.2.3 참조점을 추가\n\n- **Properties(속성)** 창 에서 **Reference Points** 를 선택한뒤 Avg(평균), Min(최소값), Max(최대값) 을 선택하고 Min, Max 의 경우 **Line** 항목을 2중선으로 설정 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-box-2.png)\n\n#### 6.2.4 참조 정보 추가\n\n- 시각화 화면에 <kbd> 오른쪽 마우스 버튼</kbd> → <kbd>Statistics Table</kbd> 을 선택하면 아래와 같이 참조 정보를 추가 및 해지 할 수 있습니다. 참조 정보는 X축 밑에 표 형태로 출력이 됩니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-box-3.png)\n\n#### 6.2.4 데이터 분포 표시하기\n\n**Properties(속성)** 창에서 **Apperance** 를 선택 한뒤 **Show distribution** 을 체크 합니다. 아래 그림과 같이 BoxPlot 에서 전체적인 데이터 분포를 보여 주는 그래프가 완성 되었습니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-box-4.png)\n\n### 6.3 KPI 차트\n\n#### 6.3.1 데이터 불러오기\n\n- 새로운 페이지를 만들고 **KPI 차트** 라고 이름을 붙여 봅니다.\n- <kbd>File</kbd> →<kbd>Open</kbd> →<kbd>Browse local file</kbd> 을 클릭해서 **OrdersDetails.xls** 를 불러 옵니다.\n\n#### 6.3.2 차트 생성\n\n- **시각화 메뉴** 에서 **KPI Chart** 를 드래그 해서 시각화 영역으로 Drop 합니다.\n\n <img src=\"./img/sfUserGuide/vis-kpi-1.png)\n\n#### 6.3.3 KPI 설청하기\n\n- **Properties(속성)** 창으로 이동 합니다.\n- **KPIs** 항목을 클릭 하고 <kbd>Settings</kbd> 를 클릭 하게 되면 KPI Setting 팝업창이 뜹니다.\n- Value(y-axis)에는 **Sum(ORDER_AMOUNT)** 를 선택 합니다.\n- **Show time in tile** 를 선택 합니다.(체크박스)\n- **Tile by** 항목 에서는 **ORDER_STATUS**\n- Comparative value 의 항목은 Sum(QUANTITY) 로 선택 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-kpi-2.png)\n\n- **Colors ** 항목 에서 <kbd> Add Point</kbd> 를 클릭해서 중간 색상 지점을 추가 합니다.\n- 중간 지점의 색상을 적당한 색상으로 바꾸고 리스트박스 를 클릭해서 Average 값으로 설정 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-kpi-3.png)\n\n- **Appearance** 항목에서 **Show scale** 및 **Include Origin** 을 체크 합니다.\n- 라디오 버튼에서 **Multiple scales** 를 선택 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-kpi-4.png)\n\n- 최종 화면\n\n![](/spotfireBasic/img/sfUserGuide/vis-kpi-5.png)\n\n## 7. 관계형 테이블 및 변환\n\n</ 병합에 사용되는 데이터셋에 관해 간략하게 요약 해보면 아래와 같습니다. 실습 대상이 되는 데이터는 Olist 라는 브라질 온라인 쇼핑몰의 실제 데이터 입니다.\n\n> 출처 : https://www.kaggle.com/olistbr/brazilian-ecommerce\n\n| 파일명 | 내용 |\n| ------------------------------------- | ---------------------------------------- |\n| olist_orders_1Q.csv | 1분기 고객 주문 데이터 |\n| olist_orders_1Q.csv | 2분기 고객 주문 데이터 |\n| olist_orders_3Q.csv | 3분기 고객 주문 데이터 |\n| olist_order_items_dataset.csv | 고객이 주문한 ITEM 데이터 |\n| olist_customers_dataset.csv | 고객정보 |\n| olist_order_payments_dataset.csv | 고객구매시 지불 정보 |\n| olist_order_reviews_dataset.csv | 고객 구매 상품에 대한 리뷰 |\n| product_category_name_translation.csv | 상품 카타고리에 대한 영어 메뉴 번역 정보 |\n\n### 4.1 데이터 자동 병합 하기\n\n#### 4.1.1 데이터 불러오기\n\n우선, 3개 파일을 Spotfire <kbd>File</kbd> → <kbd> Open</kbd> → <kbd>Browse local file</kbd> 을 통해 불러 옵니다.<br>대상파일 : olist_orders_1Q.csv, olist_orders_2Q.csv, olist_orders_3Q.csv, olist_order_items_dataset.csv (4개)\n\n![](/spotfireBasic/img/sfUserGuide/wrang-merge-1.png)\n\n#### 4.1.2 데이터셋 검사 및 Import\n\n아래와 같이 각각의 데이터셋 마다 검증하고 필요 할경우 변환할 수 있는 인터페이스를 제공 합니다. 4개의 파일에 대해 모두 <kbd>OK</kbd> 를 클릭 해서 데이터를 Import 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/wrang-merge-2.png)\n\n#### 4.1.3 데이터 추천 병합 하기\n\n기본적으로 Spotfire 는 데이터의 모양을 보고 데이터를 열 또는 행으로 결합 할지 아니면 각각의 독립된 데이터셋으로 Import 할지를 추천 해줍니다.\n\n![](/spotfireBasic/img/sfUserGuide/wrang-merge-3.png)\n\n- Olist_order_items_dataset 에 대해 <kbd>Add as new data table</kbd> → <kbd> Add as columns to </kbd> 를 클릭 합니다.\n- <kbd>설정(톱니바퀴)</kbd> 버튼을 누르면 팝업 창이 뜨게됩니다.\n- 컬럼으로 병합 (조인) 하는 것이기 때문에 **Match Columns** 항목을 통해 **조인 키**를 설정해야 합니다.\n- Spotfire 가 조인키를 데이터 형태를 보고 추천한 데로 진행합니다. <kbd>OK</kbd> 클릭 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/wrang-merge-4.png)\n\n- 데이터 Spotfire 가 Import 하는 과정에서 몇가지 경고 사항이 나타 납니다. 'NA' 라는 문자열이 날짜 데이터 타입의 형식에 맞지 않아 Spotfire 는 **'NA' 를 공백으로 처리** 하지만, 경고 메시지를 남기는 겁니다.\n\n![](/spotfireBasic/img/sfUserGuide/wrang-merge-5.png)\n\n- 데이터 Import 가 완료되면 Data Canvas 가 구동되게 됩니다.\n\n![](/spotfireBasic/img/sfUserGuide/wrang-merge-6.png)\n\n## 8. Column Operation\n\n### 8.1 Column Add (컬럼 추가하기)\n\n#### 8.1.1 데이터 로딩\n\n- dataSet 폴더에서 **OfficeSupplies.txt** 파일을 엽니다\n\n#### 8.1.2 Table Chart 추가\n\n![](/spotfireBasic/img/sfUserGuide/image-20201220201508183.png)\n\n#### 8.1.3 일부 컬럼 만 표시 하기\n\n-\n\n![](/spotfireBasic/img/sfUserGuide/image-20201220201712540.png)\n\n#### 8.1.4 Over 함수를 이용한 표현식 만들기\n\n- 아래 화면과 같이 표현식을 완성 합니다.\n\n ```{php}\n Sum([Sales]) OVER [Market Segment]\n ```\n\n![](/spotfireBasic/img/sfUserGuide/image-20201220201952426.png)\n\n- 최종 결과\n\n![](/spotfireBasic/img/sfUserGuide/image-20201220222034037.png)\n\n### 8.2 OVER in Custom Expression\n\n#### 8.2.1 새로운 페이지 추가\n\n- 새로운 페이지를 추가하고 **Bar Chart** 를 생성 합니다.\n\n#### 8.2.2 사용자 정의 표현식 생성\n\n- X축을 클릭\n\n![](/spotfireBasic/img/sfUserGuide/Over-1.png)\n\n- **Y축** 을 클릭 해서 **Edit expression** 부분에 아래와 같은 표현식을 입력 합니다.\n\n```{php}\nSum([Sales]) / Sum([Sales]) OVER ALL([Axis.X])\n```\n\n![](/spotfireBasic/img/sfUserGuide/Over-2.png)\n\n#### 8.2.3 Bar Chart 속성 설정\n\n- Bar Chart 의 **Properties(속성)** 설정으로 이동하여 아래와 같이 설정 합니다\n- **Formmatting** 에서 신규로 설정한 축을 선택하고 **Category** 를 **Percentage** 로 선택하고 **Decimals** 항목을 1로 설정 합니다. 1은 소수점 첫째까지만 표기 하라는 뜻입니다.\n- **Tooltip** 항목으로 이동해서 **Show labels for** 를 **All** 로 설정하고 **Types of labels** 내의 **Bar segments** 를 체크 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/Over-3.png)\n\n- 최종 결과\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221001702987.png)\n\n## 9. 시각화 3편\n\n### 9.1 Map 차트\n\n#### 9.1.1 데이터 로딩\n\n<kbd>File</kbd> → <kbd>Open</kbd> → <kbd>Browse local file </kbd> 을 선택하여 **dataSet** 디렉토리의 **Global Data.xls** 파일을 불러 옵니다.\n\n#### 9.1.2 맵차트 그리기\n\n![](/spotfireBasic/img/sfUserGuide/vis-map-1.png)\n\n#### 9.1.3 맵차트 둘러보기\n\n- 왼쪽상단의 레이어 아이콘을 클릭 합니다.\n- 레이어 아이콘의 체크 박스를 눌러 봅니다.\n\n![](/spotfireBasic/img/sfUserGuide/vis-map-2.png)\n\n- 오른쪽 상단의 검색을 클릭 하고 **Korea** 라고 검색 합니다.\n- 오른쪽 산단의 검색을 클릭 하고 **United States** 라고 검색 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201220044549136.png)\n\n- Zoom In / Zoom Out 을 클릭 합니다\n- 메뉴 화면의 Undo 버튼을 클릭 하면 이전 검색 화면 으로 돌아 갑니다.\n\n#### 9.1.4 위치 좌표\n\n- 맵차트의 **Properties(속성)** 창을 엽니다.\n- **Layers** 항목에서 **Marker Layer** 를 선택하고 <kbd>Settings</kbd> 를 클릭 합니다.\n- Marker 레이어의 셋팅에서 **Positioning** 을 선택하고 밑으로 내려보면 **Coordinate columns** 하는 항목이 나오고 위/경도를 가지 변수(컬럼)을 지정하는 항목이 나옵니다.\n\n![](./img/sfUserGuide/vis-map-3.png\" style=\"border: 1px solid; zoom:50%;\" align=\"left\"/>\n\n### 9.3 Summary Table\n\n#### 9.3.1 데이터 로딩\n\n- dataSet 폴더에서 3-The-5-Sheet-Book.xls 를 로딩 하되 **Worksheet** 를 **TIBCO Mega Mart** 를 선택 해서 로딩 합니다.\n\n#### 9.3.2 Summary Table 그리기\n\n![](./img/sfUserGuide/image-20201221021553438.png)\n\n#### 9.3.3 Properties 설정\n\n- Summary Table 의 **Properties(속성)** 설정 창으로 이동 합니다.\n- **Columns** 탭에서 **Store Number, Customer age, Departments shopped** 컬럼을 삭제 합니다.\n- **Columns** 탭에서 **Total Amount of Purchases** 컬럼를 추가 합니다.\n\n![](./img/sfUserGuide/table-summary-1.png\" style=\"border: 1px solid; zoom:100%;\" align=\"left\" />\n\n#### 9.3.4 Summary 측정 항목 추가\n\n- **Properties** 창에서 **Statistical Measures** 항목으로 이동합니다.\n- **Available measures** 에서 **Outliers (Outlier Count)** 를 추가 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221022502594.png)\n\n- 최종 화면\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221022529064.png)\n\n### 9.4 Cross Table\n\n#### 9.4.1 데이터 로딩\n\ndataSet 폴더에서 **전체거래테이블.csv** 파일을 로딩 합니다.\n\n#### 9.4.2 Cross Table 그리기\n\n- 시각화 메뉴 에서 **Cross Table** 을 Drag 해서 시각화 영역으로 Drop 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221022916708.png)\n\n#### 9.4.3 수직축 에 계층 설정\n\n- <kbd> Data</kbd>→<kbd>Add Hierarchy</kbd> 를 클릭 합니다.\n- 아래와 같이 **제품 대분류**, **제품 중분류**, **제품ID** 순으로 계층을 추가 합니다.\n- 이름은 **제품계층** 으로 입력 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221025017100.png)\n\n- 수직축 컬럼을 마우스로 클릭해서 **제품 계층** 을 선택 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221025231108.png)\n\n#### 9.4.4 수평축 설정\n\n- 수평축 컬럼을 마우스로 클릭 해서 **지역** 과 **결제방법** 을 차례대로 추가 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221025610406.png)\n\n#### 9.4.5 합계 및 색상 설정\n\n- **Properties** 창으로 이동해서 **Colors** 항목으로 이동 합니다.\n- **Color mode** 를 **Gradient** 로 변경 합니다.\n- <kbd>Add Point</kbd> 를 클릭하고, 드롭박스 메뉴를 클릭 한다음 **Average** 를 선택 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221030027731.png)\n\n- **Totals** 항목으로 이동하여 **Display totals** 에 모든 항목을 선택 합니다.\n- **Appearance** 항목으로 이동하여 **Use separate color from marked items** 를 체크 해지 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/table-cross-1.png)\n\n- 최종 화면\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221030647998.png)\n\n### 9.5 Graphical Table\n\n#### 9.5.1 데이터 로딩\n\ndataSet 폴더에서 **WeightLOss12WeeksData.xls** 파일을 로딩 합니다.\n\n#### 9.5.2 Graphical Table 그리기\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221031005252.png)\n\n#### 9.5.3 스파크 라인 설정\n\n- **Properties(속성)** 창으로 이동합니다.\n- **Axes** 항목으로 이동한뒤 **Columns** 에서 이미 만들어져 있는 **Sparkline** 을 선택하고 <kbd>Settings</kbd> 를 클릭 합니다.\n- **Axes** 항목에서 **X-axis** 를 **Week** 로 설정 합니다.\n- **Axes** 항목에서 Y-axis 를 **Sum(Weight, kg)** 로 선택 합니다.\n- **Y-axis scale** 항목에서 **Multiple scales** 를 선택 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221031550344.png)\n\n> 스파크라인은 라인차트와 같습니다. 따라서 Weight loss 트랜드가 모든 사람에 대해 12주기간 동안 표시 됩니다.\n\n- Sparkline 의 **Appearance** 로 이동 합니다.\n- 아래 그림과 같이 **Starting point, End point** 모두를 체크 하고, **LIne width** 를 **2** 로 설정하고 색상을 **파란색** 으로 설정 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221033456019.png)\n\n#### 9.5.4 계산된 컬럼 추가하기\n\n- Sparkline 의 **Properties(속성)** 으로 이동 합니다.\n- **Axes** 항목에서 <kbd>Add</kbd> 버튼을 클릭해서 **Calulated Value** 를 선택해 추가 합니다.\n- **Calculated value Setting** 창에서 **Values** 항목에서 **Calculate values using** 항목을 **Weight Loss, kg** 로 선택하고 집계 함수를 **Sum** 으로 선택 합니다.\n- <kbd>Add Rule</kbd> 을 클릭해 팝업창이 나오면, **Rule type** 을 **Top** 으로 선택하고, **Value** 를 **2** 로 설정한뒤, **Color** 를 노란색으로 설정 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221034615991.png)\n\n- 동일한 방법으로 <kbd>Add Rule</kbd> 을 클릭 해서 **Rule type** 을 **Bottom** 으로 선택하고, **Value** 를 **2** 로 입력합고, **Color** 를 붉은색으로 설정합니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221034834498.png)\n\n#### 9.5.5 아이콘 컬럼 추가하기\n\n- **Properties(속성)** 창에서 Axes 항목에 <kbd> Add </kbd> 버튼을 클릭해 **ICON** 을 선택해 추가 합니다.\n- **Icon Setting** 창의 **Icon** 항목 에서 **Calculate icons using** 항목을 **Weight Loss, kg** 의 집계함수를 **Sum**을 선택 합니다.\n- 이미 설정되어 있는 Default Rule 을 편집하기 위해 **연필** 버튼을 클릭합니다.\n- 팝업창이 뜨면 **Rule type** 을 **Top** 으로 선택하고 **Value** 를 **2** 로 선택하고 , **Color** 를 연한 노랑으로 선택 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/table-graphic-1.png)\n\n- <kbd>Add Rule</kbd> 을 클릭 합니다.\n- **Rule Type** 을 **Bottom** 으로 설정하고 **Value** 를 **2** 로 설정 하고, **Shape** 에 **X** 마크를 선택 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221041025957.png)\n\n#### 9.5.6 Bullet 그래프 추가하기\n\n- **Properties(속성)** 창의 **Axes** 항목에서 <kbd> Add</kbd> 를 클릭하고 **Bullet Graph** 를 선택 합니다.\n- **Bullet graph Setting** 창에서 **Calulate values using** 항목은 **Weight Loss, kg** 을 집계함수 **Sum** 으로 설정\n- **Calculate comparative values using** 항목을 **Weekly Goal, kg** 로 설정 합니다.\n- **Color Range** 항목에서 **Show color rnage** 를 체크 합니다.\n- <kbd> Add </kbd> 버튼을 클릭해서 아래와 같이 3가지 생상을 조건과 함께 설정합니다.\n\n```{php}\nSum([Weekly Goal, kg]) * 0.75\nSum([Weekly Goal, kg]) * 1.25\n```\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221042532434.png)\n\n- 최종화면\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221043124270.png)\n\n## 10. Property Control\n\n### 10.1 축으로 Property 사용\n\n#### 10.1.1 데이터 로딩\n\n- dataSet 폴더에서 **flights.csv** 파일을 로딩 합니다.\n- **시각화 화면** 에서 **Line Chart** 를 드래그 해서 시각화 영역에 Drop 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/property-cnt-1.png)\n\n- <kbd>File</kbd>→<kbd>Document Properties</kbd> 를 클릭 합니다.\n- **Properties** 탭에서 <kbd>New</kbd> 를 클릭하면 Property 편집창이 뜹니다.\n- **Property name** 항목에 Page1X 라고 입력하고 **String **을 선택하고 <kbd>OK</kbd> 를 클릭 합니다.\n- 다시 <kbd> New </kbd> 를 클릭하고 동일방법으로 Page1Y를 입력 하고 **String** 을 선택하고 <kbd>OK</kbd> 를 클릭합니다.\n- 총 2개의 Document Property 를 만들어 습니다.\n\n![](/spotfireBasic/img/sfUserGuide/property-cnt-2.png)\n\n#### 10.1.2 Text Area 생성\n\n**시각화 메뉴** 에서 **Text area** 를 드래그 해서 시각화영역에 Drop 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/property-cnt-3.png)\n\n- 텍스트 영역의 오른쪽 상단에 편집버튼(연필모양) 을 클릭 합니다.\n- <kbd>Insert Property Control</kbd> 을 클릭 하고 **Drop-Down List** 를 클릭 합니다.\n\n- Property Control 대화 상자가 나타나면, **Document Properties** 탭에서 **Select property** 항목에서 **Page1Y** 를 선택 합니다.\n- **Set Property value through** 항목은 **Column selection** 으로 선택 합니다.\n- **Settings** 에서 <kbd>Select Columns</kbd> 를 클릭 합니다.\n- **Select Columns** 팝업창에서 <kbd>New</kbd> 를 클릭 합니다.\n- <kbd>New</kbd> 를 클릭하고, 팝업창의 Property name 항목에 **Page1Y** 라고 동일하게 적어 줍니다.\n- Data Type 은 **Boolean** 으로 하고 **Default Value** 는 **TRUE** 로 입력 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/property-cnt-4.png)\n\n- **Select Columns ** 창에서 모든 변수를 제거하고 **dep_dealy**, **arr_time** , **arr_delay** 3개만 선택 합니다\n- page1X 도 위와 동일한 방법으로 설정 하되, **month**, **day**,**carrier**, **tailnum** 4개만 선택 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/property-cnt-5.png)\n\n- 텍스트 박스 결과\n\n![](/spotfireBasic/img/sfUserGuide/image-20201220151204774.png)\n\n#### 10.1.3 축에 property 설정\n\n- **Y축** 과 **X축** 에 오른쪽 마우스 버튼을 클릭한뒤, **set from Property** 를 클릭 해서 각각의 Document Property 를 설정해줍니다.\n\n![](/spotfireBasic/img/sfUserGuide/property-cnt-6.png)\n\n- 최종화면\n\n![](/spotfireBasic/img/sfUserGuide/image-20201220160502842.png)\n\n### 10.2 Text 표현식 으로 Property 사용\n\n#### 10.2.1 데이터 로딩\n\ndataSet 폴더에서 **OfficeSupplies.txt** 파일을 로딩 합니다.\n\n#### 10.2.2 Bar Chart 그리기\n\n- 아래와 같이 Bar Chart 를 그립니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201220164516548.png)\n\n#### 10.2.3 Text 영역 설정\n\n- Text 편집(연필모양) 을 누르고, 기존에 있던 텍스트 영역에 한칸을 내려 <kbd>Insert Property Control </kbd> 을 클릭해서 **Drop-Down List** 를 하나 더 만듭니다.\n\n- **Drop-Down List** 를 더블클릭 하면 아래와 같이 **Property Control** 에서 **Document Properties** 탭에 <kbd>New</kbd> 를 클릭하여 새로운 Document Property 로 **Property Name** 을 **Value Axes** 라고 하고 **Data Type** 을 **String** 으로 해서 만듭니다.\n\n![](/spotfireBasic/img/sfUserGuide/property-cnt-7.png)\n\n- 동일한 **Property Control** 에서 **Set property value through** 를 **Expression** 으로 선택 하고 <kbd> Add </kbd> 를 클릭해서 아래와 같이 2가지의 Setting 을 추가 합니다.\n- Text 영역을 저장 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/property-cnt-8.png)\n\n- 최종 추가 모습\n\n![](/spotfireBasic/img/sfUserGuide/image-20201220170321031.png)\n\n#### 10.2.5 Expression 으로 Property 설정\n\n- **Y축** 에 ** Custom Expression** 을 클릭하게 되면 Custom Expression 창이 뜹니다.\n- 원래 있던 표현식을 지우고 **Available properties for column** 항목에서 **ValueAxes** 를 스크롤 다운해서 선택 한다음 <kbd>Insert Properties</kbd> 를 클릭 하면 자동으로 값이 들어 갑니다.\n- Expression 을 복사해서 **Display name** 에도 동일한 표현식을 넣어 줍니다.\n\n![](/spotfireBasic/img/sfUserGuide/property-cnt-9.png)\n\n- 최종 모습\n\n![](/spotfireBasic/img/sfUserGuide/image-20201220171305659.png)\n\n### 10.3 Value 로 Property 사용\n\n#### 10.3.1 새로운 페이지 추가\n\n- 새로운 페이지를 만들고 , 테이블 차트 를 추가 합니다.\n- 출발 지연율에 대한 기준을 5분으로 설정 하고 5분이 넘으면 위반 5분 이하면\n\n![](/spotfireBasic/img/sfUserGuide/image-20201220171637727.png)\n\n#### 10.3.2 테이블 차트의 컬럼 속성을 자동으로 변경\n\n- 테이블 차트에서 **Properties(속성)** 으로 이동하고 **Columns** 항목을 선택 한 다음 **Selected columns** 에서 모든 변수를 <kbd>Remove ALL </kbd> 을 클릭해서 제거 합니다.\n- **flight, dep_dealy, tailnum, carrier** 만 추가 해줍니다.\n- 하단에 있는 **Add new columns automatically** 를 체크 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/property-cnt-10.png)\n\n#### 10.3.3 Text Area 추가 및 설정\n\n- Text 영역을 추가 해줍니다.\n- 추가한 Text 영역에 **Insert Property Control** 을 클릭해서 **Slide Bar** 를 추가해 줍니다.\n- **Property Control** 창에서 <kbd>New</kbd> 를 클릭해서 **Property name** 에 **DepDelayViolated** 를 입력하고 **Data Type** 을 **Integer 으로 선택 하고, **Value** 를 **5\\*\\* 로 설정한 뒤 <kbd>OK</kbd>\n\n![](/spotfireBasic/img/sfUserGuide/property-cnt-11.png)\n\n- 동일한 Property Control 에서 **DepDelayViolated** 범위를 아래와 같이 지정 합니다.\n- **Set property value through** 항목에서 **Numerical range** 를 선택합니다.\n- **Min : 1**, **Max: 20, Value Interval: 1** 로 설정하고 **Show min and max labels** 를 체크 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201220191740336.png)\n\n#### 10.3.4 Calculated Column 추가\n\n- <kbd> Data</kbd>→<kbd>Add Calulated Column</kbd> 을 클릭 합니다.\n- **Available properties for column** 항목에서 **DepDelayViolated** 를 찾아 **Insert as Value** 로 표현식에 입력 합니다.\n- 표현식은 아래와 같습니다.\n\n```{php}\nif(([dep_delay] -DocumentProperty(\"DepDelayViolated\") > 0), \"Violated\", \"Passed\")\n```\n\n- **Column name** 은 Violoated 로 입력 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201220192206099.png)\n\n- 최종 화면\n\n![](/spotfireBasic/img/sfUserGuide/image-20201220192718119.png)\n\n## 11. 머신러닝\n\n## 12. Data Function with R\n\n### 12.1 Data Function 만들기\n\n#### 12.1.1 Data Functio 등록 하기\n\n- **Tools** 의 **Register data functions** 을 클릭 하고 , **Name** 을 **KMeansClustering** 이라 고 입력 합니다.\n\n- **Type** 을 Drop-Down List 에서 **R script - TIBCO Enterprise Runtime for R** 을 선택 합니다.\n\n- 설명란에 **나의 첫번째 데이터 함수 ** 라고 입력 합니다.\n\n- **Script** 입력 창에 아래와 같이 입력 합니다.\n\n ```{R}\n cl <- kmeans(data.frame(x,y), k)\n cl.cluster <- data.frame(cluster = cl$cluster)\n cl.centers <- data.frame(cluster=1:k, cl$centers, size=cl$size)\n ```\n\n#### 12.1.2 Input 파라메터 설정 하기\n\n- **Input Parameters** 탭을 클릭 합니다.\n- <kbd>Add</kbd> 를 클릭하고 **Input parameter name** 을 **x** 로 입력 합니다.\n- **Display name** 을 **x - axis value** 입력 합니다.\n- **Type** 은 **Column** 을 선택 합니다.\n- **Allowed data types** 에 **Integer, Real, SingleReal, Currency** 4개를 체크 한뒤 <kbd> OK </kbd> 를 클릭 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221131049624.png)\n\n- 다시 **Script** 탭으로 이동 합니다.\n- y 변수를 하이라이트 해서 오른쪽 마우스를 클릭 해서 **Input Parameter** 를 클릭 합니다.\n- **Input Parameter name** 에 **y** 를 입력 합니다.\n- **Display name** 에는 **y - axis values** 라고 입력 합니다.\n- **type** 은 **Column** 으로 하고 **Allowed data types** 는 **Integer, Real, SingleReal, Currency** 를 체크 한뒤 <kbd> OK </kbd> 를 클릭 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/df-1.png)\n\n- 동일한 방법으로 변수 k 에대해서 아래와 같이 실행 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221132639547.png)\n\n- **Input Parameter** 탭에서 최종적으로 아래와 같이 보입니다.\n\n![image-20201221132837519](/spotfireBasic/img/sfUserGuide/image-20201221132837519.png)\n\n#### 12.1.3 Ouput 파라메터 설정\n\n- **Output parameter** 탭을 선택 하고, <kbd> Add </kbd> 버튼을 클릭 합니다.\n- **Result parameter name** 을 **cl.cluster** 로 입력 합니다.\n- **Display name** 을 **Cluster assignments** 로 입력 합니다.\n- **Description** 에 **데이터 포인트에 대한 클러스터 할당 결과** 로 입력 하고, <kbd> OK </kbd> 클릭 합니다.\n\n![image-20201221133652092](/spotfireBasic/img/sfUserGuide/image-20201221133652092.png)\n\n- <kbd> Add </kbd> 를 클릭 해서 신규 Output parameter 를 추가 합니다.\n- **Result parameter name** 을 **cl.centers** 라고 입력 합니다.\n- **Display name** 을 **Cluster centers** 로 입력합니다.\n- **Description** 에는 **클러스터의 크기 및 클러스터의 좌표** 라고 입력 합니다.\n\n![image-20201221134440582](/spotfireBasic/img/sfUserGuide/image-20201221134440582.png)\n\n- Output 파라메터 부분은 최종적으로 아래와 같습니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221134557995.png)\n\n#### 12.1.4 Data Function 저장하기\n\n- <kbd> Save as</kbd> 를 클릭 합니다.\n- **Name** 을 **KMeansClustering** 으로 저장 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221135055213.png)\n\n#### 12.2 Data Function 실행 하기\n\n#### 12.2.1 Dxp 불러오기\n\n- dataSet 폴더에 Lab_W.dxp 파일을 로딩 합니다.\n- 로딩이 완료 되면 아래와 같이 Scatter Plot 이 보이게 됩니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221135849955.png)\n\n#### 12.2.2 라이브러리로 부터 Data Function 불러오기\n\n- 메뉴 **Data** →**Data function properties** 를 클릭 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221140327196.png)\n\n#### 12.2.3 Input 파라메터 편집\n\n- **Input** 탭 에서 **x - axis value** 를 마우스로 선택 합니다.\n- **nput handler** 섹션에서 **Column** 을 선택 합니다.\n- 라디오 버튼에 **Columns** 가 선택 되어 있으며, <kbd> Select Columns </kbd> 를 클릭해서 변수 **X** 추가 합니다.\n- 스크롤다운 하면 **Limit by** 섹션이 보이고 **Filtered rows** 를 **Filtering Scheme (842 rows)** 로 선택 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221165116727.png)\n\n- 동일한 **Input** 탭에서 이제 **y - axis values** 마우스로 선택 합니다.\n- **nput handler** 섹션에서 **Column** 을 선택 합니다.\n- **Column** 항목을 **Y** 로 선택 합니다.\n- **Limit by** 섹션에서 **Filtered row** 항목을 **Filtering scheme (842 rows)** 로 설정 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221165926385.png)\n\n- 동일한 **Input** 탭에서 이제 **Desired number of clusters** 를 선택 합니다.\n- **Input handler** 섹션에서 **Document property** 를 선택 합니다.\n- **Property** 섹션에서 **NoOfClusters** 를 선택 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221170324387.png)\n\n#### 12.2.4 Output 파라메터 편집\n\n- 이제 **Output** 탭으로 이동 합니다.\n- **Output parameters** 항목에 **Cluster assignments** 를 선택 합니다.\n- **Output handler** 에서 **Columns** 를 선택합니다.\n- **Map to input rows** 항목을 **x - axis value** 로 선택 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221170808188.png)\n\n- 이제 **Output Parameters** 에서 **Cluster centers** 를 선택 합니다.\n- **Output handler** 를 **Data table** 로 선택 합니다.\n- 상단의 **Refresh function automatically** 를 체크 합니다.\n- <kbd> OK </kbd> 를 클릭 합니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221171201282.png)\n\n#### 12.2.5 결과 보기\n\n- 아래와 같이 데이터 메뉴에 **Cluster** 라는 신규 변수가 생기고, 신규 데이터 셋으로 **Cluster centers** 라는 것이 만들어 졌습니다.\n\n- cluster 를 마우스로 Drag 해서 격자형 패널 아이콘에 Drop 합니다.\n\n <img src=\"./img/sfUserGuide/image-20201221171840059.png)\n\n- 아래 화면처럼 5개의 클러스터로 기존 데이터를 군집화를 만들었습니다.\n\n![](/spotfireBasic/img/sfUserGuide/image-20201221171931599.png)\n",
    "dir": "/spotfireBasic/",
    "name": "Spotfire Analyst User Guide.md",
    "path": "spotfireBasic/Spotfire Analyst User Guide.md",
    "url": "/spotfireBasic/Spotfire%20Analyst%20User%20Guide.html"
  },
  {
    "sort": 1,
    "permalink": "/kubernetes/",
    "layout": "default",
    "title": "쿠버네티스 교재",
    "content": "<h1 id=\"쿠버네티스-교재\">쿠버네티스 교재</h1>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>{% include list.liquid all=true %}\n</code></pre>  </div></div>\n\n<ul>\n <li><a href=\"/kubernetes/Learning-kubernetes.html\">Learning Kubernetes</a></li>\n</ul>\n",
    "dir": "/kubernetes/",
    "name": "README.md",
    "path": "kubernetes/README.md",
    "url": "/kubernetes/"
  },
  {
    "sort": 1,
    "permalink": "/spotfireBasic/",
    "layout": "default",
    "title": "Spotfire 교재",
    "content": "<h1 id=\"spotfire-교재\">Spotfire 교재</h1>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>{% include list.liquid all=true %}\n</code></pre>  </div></div>\n\n<ul>\n <li><a href=\"/spotfireBasic/Spotfire%20Analyst%20User%20Guide.html\">Spotfire Analyst 데이터 시각화 첫걸음</a></li>\n</ul>\n",
    "dir": "/spotfireBasic/",
    "name": "README.md",
    "path": "spotfireBasic/README.md",
    "url": "/spotfireBasic/"
  }
]
